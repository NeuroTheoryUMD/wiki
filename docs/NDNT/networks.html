<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="pdoc 14.4.0"/>
    <title>NDNT.networks API documentation</title>

    <style>/*! * Bootstrap Reboot v5.0.0 (https://getbootstrap.com/) * Copyright 2011-2021 The Bootstrap Authors * Copyright 2011-2021 Twitter, Inc. * Licensed under MIT (https://github.com/twbs/bootstrap/blob/main/LICENSE) * Forked from Normalize.css, licensed MIT (https://github.com/necolas/normalize.css/blob/master/LICENSE.md) */*,::after,::before{box-sizing:border-box}@media (prefers-reduced-motion:no-preference){:root{scroll-behavior:smooth}}body{margin:0;font-family:system-ui,-apple-system,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans","Liberation Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-size:1rem;font-weight:400;line-height:1.5;color:#212529;background-color:#fff;-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:transparent}hr{margin:1rem 0;color:inherit;background-color:currentColor;border:0;opacity:.25}hr:not([size]){height:1px}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:.5rem;font-weight:500;line-height:1.2}h1{font-size:calc(1.375rem + 1.5vw)}@media (min-width:1200px){h1{font-size:2.5rem}}h2{font-size:calc(1.325rem + .9vw)}@media (min-width:1200px){h2{font-size:2rem}}h3{font-size:calc(1.3rem + .6vw)}@media (min-width:1200px){h3{font-size:1.75rem}}h4{font-size:calc(1.275rem + .3vw)}@media (min-width:1200px){h4{font-size:1.5rem}}h5{font-size:1.25rem}h6{font-size:1rem}p{margin-top:0;margin-bottom:1rem}abbr[data-bs-original-title],abbr[title]{-webkit-text-decoration:underline dotted;text-decoration:underline dotted;cursor:help;-webkit-text-decoration-skip-ink:none;text-decoration-skip-ink:none}address{margin-bottom:1rem;font-style:normal;line-height:inherit}ol,ul{padding-left:2rem}dl,ol,ul{margin-top:0;margin-bottom:1rem}ol ol,ol ul,ul ol,ul ul{margin-bottom:0}dt{font-weight:700}dd{margin-bottom:.5rem;margin-left:0}blockquote{margin:0 0 1rem}b,strong{font-weight:bolder}small{font-size:.875em}mark{padding:.2em;background-color:#fcf8e3}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}a{color:#0d6efd;text-decoration:underline}a:hover{color:#0a58ca}a:not([href]):not([class]),a:not([href]):not([class]):hover{color:inherit;text-decoration:none}code,kbd,pre,samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;font-size:1em;direction:ltr;unicode-bidi:bidi-override}pre{display:block;margin-top:0;margin-bottom:1rem;overflow:auto;font-size:.875em}pre code{font-size:inherit;color:inherit;word-break:normal}code{font-size:.875em;color:#d63384;word-wrap:break-word}a>code{color:inherit}kbd{padding:.2rem .4rem;font-size:.875em;color:#fff;background-color:#212529;border-radius:.2rem}kbd kbd{padding:0;font-size:1em;font-weight:700}figure{margin:0 0 1rem}img,svg{vertical-align:middle}table{caption-side:bottom;border-collapse:collapse}caption{padding-top:.5rem;padding-bottom:.5rem;color:#6c757d;text-align:left}th{text-align:inherit;text-align:-webkit-match-parent}tbody,td,tfoot,th,thead,tr{border-color:inherit;border-style:solid;border-width:0}label{display:inline-block}button{border-radius:0}button:focus:not(:focus-visible){outline:0}button,input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:inherit;line-height:inherit}button,select{text-transform:none}[role=button]{cursor:pointer}select{word-wrap:normal}select:disabled{opacity:1}[list]::-webkit-calendar-picker-indicator{display:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]:not(:disabled),[type=reset]:not(:disabled),[type=submit]:not(:disabled),button:not(:disabled){cursor:pointer}::-moz-focus-inner{padding:0;border-style:none}textarea{resize:vertical}fieldset{min-width:0;padding:0;margin:0;border:0}legend{float:left;width:100%;padding:0;margin-bottom:.5rem;font-size:calc(1.275rem + .3vw);line-height:inherit}@media (min-width:1200px){legend{font-size:1.5rem}}legend+*{clear:left}::-webkit-datetime-edit-day-field,::-webkit-datetime-edit-fields-wrapper,::-webkit-datetime-edit-hour-field,::-webkit-datetime-edit-minute,::-webkit-datetime-edit-month-field,::-webkit-datetime-edit-text,::-webkit-datetime-edit-year-field{padding:0}::-webkit-inner-spin-button{height:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-color-swatch-wrapper{padding:0}::file-selector-button{font:inherit}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}output{display:inline-block}iframe{border:0}summary{display:list-item;cursor:pointer}progress{vertical-align:baseline}[hidden]{display:none!important}</style>
    <style>/*! syntax-highlighting.css */pre{line-height:125%;}span.linenos{color:inherit; background-color:transparent; padding-left:5px; padding-right:20px;}.pdoc-code .hll{background-color:#ffffcc}.pdoc-code{background:#f8f8f8;}.pdoc-code .c{color:#3D7B7B; font-style:italic}.pdoc-code .err{border:1px solid #FF0000}.pdoc-code .k{color:#008000; font-weight:bold}.pdoc-code .o{color:#666666}.pdoc-code .ch{color:#3D7B7B; font-style:italic}.pdoc-code .cm{color:#3D7B7B; font-style:italic}.pdoc-code .cp{color:#9C6500}.pdoc-code .cpf{color:#3D7B7B; font-style:italic}.pdoc-code .c1{color:#3D7B7B; font-style:italic}.pdoc-code .cs{color:#3D7B7B; font-style:italic}.pdoc-code .gd{color:#A00000}.pdoc-code .ge{font-style:italic}.pdoc-code .gr{color:#E40000}.pdoc-code .gh{color:#000080; font-weight:bold}.pdoc-code .gi{color:#008400}.pdoc-code .go{color:#717171}.pdoc-code .gp{color:#000080; font-weight:bold}.pdoc-code .gs{font-weight:bold}.pdoc-code .gu{color:#800080; font-weight:bold}.pdoc-code .gt{color:#0044DD}.pdoc-code .kc{color:#008000; font-weight:bold}.pdoc-code .kd{color:#008000; font-weight:bold}.pdoc-code .kn{color:#008000; font-weight:bold}.pdoc-code .kp{color:#008000}.pdoc-code .kr{color:#008000; font-weight:bold}.pdoc-code .kt{color:#B00040}.pdoc-code .m{color:#666666}.pdoc-code .s{color:#BA2121}.pdoc-code .na{color:#687822}.pdoc-code .nb{color:#008000}.pdoc-code .nc{color:#0000FF; font-weight:bold}.pdoc-code .no{color:#880000}.pdoc-code .nd{color:#AA22FF}.pdoc-code .ni{color:#717171; font-weight:bold}.pdoc-code .ne{color:#CB3F38; font-weight:bold}.pdoc-code .nf{color:#0000FF}.pdoc-code .nl{color:#767600}.pdoc-code .nn{color:#0000FF; font-weight:bold}.pdoc-code .nt{color:#008000; font-weight:bold}.pdoc-code .nv{color:#19177C}.pdoc-code .ow{color:#AA22FF; font-weight:bold}.pdoc-code .w{color:#bbbbbb}.pdoc-code .mb{color:#666666}.pdoc-code .mf{color:#666666}.pdoc-code .mh{color:#666666}.pdoc-code .mi{color:#666666}.pdoc-code .mo{color:#666666}.pdoc-code .sa{color:#BA2121}.pdoc-code .sb{color:#BA2121}.pdoc-code .sc{color:#BA2121}.pdoc-code .dl{color:#BA2121}.pdoc-code .sd{color:#BA2121; font-style:italic}.pdoc-code .s2{color:#BA2121}.pdoc-code .se{color:#AA5D1F; font-weight:bold}.pdoc-code .sh{color:#BA2121}.pdoc-code .si{color:#A45A77; font-weight:bold}.pdoc-code .sx{color:#008000}.pdoc-code .sr{color:#A45A77}.pdoc-code .s1{color:#BA2121}.pdoc-code .ss{color:#19177C}.pdoc-code .bp{color:#008000}.pdoc-code .fm{color:#0000FF}.pdoc-code .vc{color:#19177C}.pdoc-code .vg{color:#19177C}.pdoc-code .vi{color:#19177C}.pdoc-code .vm{color:#19177C}.pdoc-code .il{color:#666666}</style>
    <style>/*! theme.css */:root{--pdoc-background:#fff;}.pdoc{--text:#212529;--muted:#6c757d;--link:#3660a5;--link-hover:#1659c5;--code:#f8f8f8;--active:#fff598;--accent:#eee;--accent2:#c1c1c1;--nav-hover:rgba(255, 255, 255, 0.5);--name:#0066BB;--def:#008800;--annotation:#007020;}</style>
    <style>/*! layout.css */html, body{width:100%;height:100%;}html, main{scroll-behavior:smooth;}body{background-color:var(--pdoc-background);}@media (max-width:769px){#navtoggle{cursor:pointer;position:absolute;width:50px;height:40px;top:1rem;right:1rem;border-color:var(--text);color:var(--text);display:flex;opacity:0.8;z-index:999;}#navtoggle:hover{opacity:1;}#togglestate + div{display:none;}#togglestate:checked + div{display:inherit;}main, header{padding:2rem 3vw;}header + main{margin-top:-3rem;}.git-button{display:none !important;}nav input[type="search"]{max-width:77%;}nav input[type="search"]:first-child{margin-top:-6px;}nav input[type="search"]:valid ~ *{display:none !important;}}@media (min-width:770px){:root{--sidebar-width:clamp(12.5rem, 28vw, 22rem);}nav{position:fixed;overflow:auto;height:100vh;width:var(--sidebar-width);}main, header{padding:3rem 2rem 3rem calc(var(--sidebar-width) + 3rem);width:calc(54rem + var(--sidebar-width));max-width:100%;}header + main{margin-top:-4rem;}#navtoggle{display:none;}}#togglestate{position:absolute;height:0;opacity:0;}nav.pdoc{--pad:clamp(0.5rem, 2vw, 1.75rem);--indent:1.5rem;background-color:var(--accent);border-right:1px solid var(--accent2);box-shadow:0 0 20px rgba(50, 50, 50, .2) inset;padding:0 0 0 var(--pad);overflow-wrap:anywhere;scrollbar-width:thin; scrollbar-color:var(--accent2) transparent; z-index:1}nav.pdoc::-webkit-scrollbar{width:.4rem; }nav.pdoc::-webkit-scrollbar-thumb{background-color:var(--accent2); }nav.pdoc > div{padding:var(--pad) 0;}nav.pdoc .module-list-button{display:inline-flex;align-items:center;color:var(--text);border-color:var(--muted);margin-bottom:1rem;}nav.pdoc .module-list-button:hover{border-color:var(--text);}nav.pdoc input[type=search]{display:block;outline-offset:0;width:calc(100% - var(--pad));}nav.pdoc .logo{max-width:calc(100% - var(--pad));max-height:35vh;display:block;margin:0 auto 1rem;transform:translate(calc(-.5 * var(--pad)), 0);}nav.pdoc ul{list-style:none;padding-left:0;}nav.pdoc > div > ul{margin-left:calc(0px - var(--pad));}nav.pdoc li a{padding:.2rem 0 .2rem calc(var(--pad) + var(--indent));}nav.pdoc > div > ul > li > a{padding-left:var(--pad);}nav.pdoc li{transition:all 100ms;}nav.pdoc li:hover{background-color:var(--nav-hover);}nav.pdoc a, nav.pdoc a:hover{color:var(--text);}nav.pdoc a{display:block;}nav.pdoc > h2:first-of-type{margin-top:1.5rem;}nav.pdoc .class:before{content:"class ";color:var(--muted);}nav.pdoc .function:after{content:"()";color:var(--muted);}nav.pdoc footer:before{content:"";display:block;width:calc(100% - var(--pad));border-top:solid var(--accent2) 1px;margin-top:1.5rem;padding-top:.5rem;}nav.pdoc footer{font-size:small;}</style>
    <style>/*! content.css */.pdoc{color:var(--text);box-sizing:border-box;line-height:1.5;background:none;}.pdoc .pdoc-button{cursor:pointer;display:inline-block;border:solid black 1px;border-radius:2px;font-size:.75rem;padding:calc(0.5em - 1px) 1em;transition:100ms all;}.pdoc .pdoc-alert{padding:1rem 1rem 1rem calc(1.5rem + 24px);border:1px solid transparent;border-radius:.25rem;background-repeat:no-repeat;background-position:1rem center;margin-bottom:1rem;}.pdoc .pdoc-alert > *:last-child{margin-bottom:0;}.pdoc .pdoc-alert-note {color:#084298;background-color:#cfe2ff;border-color:#b6d4fe;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23084298%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8%2016A8%208%200%201%200%208%200a8%208%200%200%200%200%2016zm.93-9.412-1%204.705c-.07.34.029.533.304.533.194%200%20.487-.07.686-.246l-.088.416c-.287.346-.92.598-1.465.598-.703%200-1.002-.422-.808-1.319l.738-3.468c.064-.293.006-.399-.287-.47l-.451-.081.082-.381%202.29-.287zM8%205.5a1%201%200%201%201%200-2%201%201%200%200%201%200%202z%22/%3E%3C/svg%3E");}.pdoc .pdoc-alert-warning{color:#664d03;background-color:#fff3cd;border-color:#ffecb5;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23664d03%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8.982%201.566a1.13%201.13%200%200%200-1.96%200L.165%2013.233c-.457.778.091%201.767.98%201.767h13.713c.889%200%201.438-.99.98-1.767L8.982%201.566zM8%205c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%205.995A.905.905%200%200%201%208%205zm.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2z%22/%3E%3C/svg%3E");}.pdoc .pdoc-alert-danger{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M5.52.359A.5.5%200%200%201%206%200h4a.5.5%200%200%201%20.474.658L8.694%206H12.5a.5.5%200%200%201%20.395.807l-7%209a.5.5%200%200%201-.873-.454L6.823%209.5H3.5a.5.5%200%200%201-.48-.641l2.5-8.5z%22/%3E%3C/svg%3E");}.pdoc .visually-hidden{position:absolute !important;width:1px !important;height:1px !important;padding:0 !important;margin:-1px !important;overflow:hidden !important;clip:rect(0, 0, 0, 0) !important;white-space:nowrap !important;border:0 !important;}.pdoc h1, .pdoc h2, .pdoc h3{font-weight:300;margin:.3em 0;padding:.2em 0;}.pdoc > section:not(.module-info) h1{font-size:1.5rem;font-weight:500;}.pdoc > section:not(.module-info) h2{font-size:1.4rem;font-weight:500;}.pdoc > section:not(.module-info) h3{font-size:1.3rem;font-weight:500;}.pdoc > section:not(.module-info) h4{font-size:1.2rem;}.pdoc > section:not(.module-info) h5{font-size:1.1rem;}.pdoc a{text-decoration:none;color:var(--link);}.pdoc a:hover{color:var(--link-hover);}.pdoc blockquote{margin-left:2rem;}.pdoc pre{border-top:1px solid var(--accent2);border-bottom:1px solid var(--accent2);margin-top:0;margin-bottom:1em;padding:.5rem 0 .5rem .5rem;overflow-x:auto;background-color:var(--code);}.pdoc code{color:var(--text);padding:.2em .4em;margin:0;font-size:85%;background-color:var(--accent);border-radius:6px;}.pdoc a > code{color:inherit;}.pdoc pre > code{display:inline-block;font-size:inherit;background:none;border:none;padding:0;}.pdoc > section:not(.module-info){margin-bottom:1.5rem;}.pdoc .modulename{margin-top:0;font-weight:bold;}.pdoc .modulename a{color:var(--link);transition:100ms all;}.pdoc .git-button{float:right;border:solid var(--link) 1px;}.pdoc .git-button:hover{background-color:var(--link);color:var(--pdoc-background);}.view-source-toggle-state,.view-source-toggle-state ~ .pdoc-code{display:none;}.view-source-toggle-state:checked ~ .pdoc-code{display:block;}.view-source-button{display:inline-block;float:right;font-size:.75rem;line-height:1.5rem;color:var(--muted);padding:0 .4rem 0 1.3rem;cursor:pointer;text-indent:-2px;}.view-source-button > span{visibility:hidden;}.module-info .view-source-button{float:none;display:flex;justify-content:flex-end;margin:-1.2rem .4rem -.2rem 0;}.view-source-button::before{position:absolute;content:"View Source";display:list-item;list-style-type:disclosure-closed;}.view-source-toggle-state:checked ~ .attr .view-source-button::before,.view-source-toggle-state:checked ~ .view-source-button::before{list-style-type:disclosure-open;}.pdoc .docstring{margin-bottom:1.5rem;}.pdoc section:not(.module-info) .docstring{margin-left:clamp(0rem, 5vw - 2rem, 1rem);}.pdoc .docstring .pdoc-code{margin-left:1em;margin-right:1em;}.pdoc h1:target,.pdoc h2:target,.pdoc h3:target,.pdoc h4:target,.pdoc h5:target,.pdoc h6:target,.pdoc .pdoc-code > pre > span:target{background-color:var(--active);box-shadow:-1rem 0 0 0 var(--active);}.pdoc .pdoc-code > pre > span:target{display:block;}.pdoc div:target > .attr,.pdoc section:target > .attr,.pdoc dd:target > a{background-color:var(--active);}.pdoc *{scroll-margin:2rem;}.pdoc .pdoc-code .linenos{user-select:none;}.pdoc .attr:hover{filter:contrast(0.95);}.pdoc section, .pdoc .classattr{position:relative;}.pdoc .headerlink{--width:clamp(1rem, 3vw, 2rem);position:absolute;top:0;left:calc(0rem - var(--width));transition:all 100ms ease-in-out;opacity:0;}.pdoc .headerlink::before{content:"#";display:block;text-align:center;width:var(--width);height:2.3rem;line-height:2.3rem;font-size:1.5rem;}.pdoc .attr:hover ~ .headerlink,.pdoc *:target > .headerlink,.pdoc .headerlink:hover{opacity:1;}.pdoc .attr{display:block;margin:.5rem 0 .5rem;padding:.4rem .4rem .4rem 1rem;background-color:var(--accent);overflow-x:auto;}.pdoc .classattr{margin-left:2rem;}.pdoc .name{color:var(--name);font-weight:bold;}.pdoc .def{color:var(--def);font-weight:bold;}.pdoc .signature{background-color:transparent;}.pdoc .param, .pdoc .return-annotation{white-space:pre;}.pdoc .signature.multiline .param{display:block;}.pdoc .signature.condensed .param{display:inline-block;}.pdoc .annotation{color:var(--annotation);}.pdoc .view-value-toggle-state,.pdoc .view-value-toggle-state ~ .default_value{display:none;}.pdoc .view-value-toggle-state:checked ~ .default_value{display:inherit;}.pdoc .view-value-button{font-size:.5rem;vertical-align:middle;border-style:dashed;margin-top:-0.1rem;}.pdoc .view-value-button:hover{background:white;}.pdoc .view-value-button::before{content:"show";text-align:center;width:2.2em;display:inline-block;}.pdoc .view-value-toggle-state:checked ~ .view-value-button::before{content:"hide";}.pdoc .inherited{margin-left:2rem;}.pdoc .inherited dt{font-weight:700;}.pdoc .inherited dt, .pdoc .inherited dd{display:inline;margin-left:0;margin-bottom:.5rem;}.pdoc .inherited dd:not(:last-child):after{content:", ";}.pdoc .inherited .class:before{content:"class ";}.pdoc .inherited .function a:after{content:"()";}.pdoc .search-result .docstring{overflow:auto;max-height:25vh;}.pdoc .search-result.focused > .attr{background-color:var(--active);}.pdoc .attribution{margin-top:2rem;display:block;opacity:0.5;transition:all 200ms;filter:grayscale(100%);}.pdoc .attribution:hover{opacity:1;filter:grayscale(0%);}.pdoc .attribution img{margin-left:5px;height:35px;vertical-align:middle;width:70px;transition:all 200ms;}.pdoc table{display:block;width:max-content;max-width:100%;overflow:auto;margin-bottom:1rem;}.pdoc table th{font-weight:600;}.pdoc table th, .pdoc table td{padding:6px 13px;border:1px solid var(--accent2);}</style>
    <style>/*! custom.css */</style></head>
<body>
    <nav class="pdoc">
        <label id="navtoggle" for="togglestate" class="pdoc-button"><svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'><path stroke-linecap='round' stroke="currentColor" stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/></svg></label>
        <input id="togglestate" type="checkbox" aria-hidden="true" tabindex="-1">
        <div>            <a class="pdoc-button module-list-button" href="../NDNT.html">
<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-box-arrow-in-left" viewBox="0 0 16 16">
  <path fill-rule="evenodd" d="M10 3.5a.5.5 0 0 0-.5-.5h-8a.5.5 0 0 0-.5.5v9a.5.5 0 0 0 .5.5h8a.5.5 0 0 0 .5-.5v-2a.5.5 0 0 1 1 0v2A1.5 1.5 0 0 1 9.5 14h-8A1.5 1.5 0 0 1 0 12.5v-9A1.5 1.5 0 0 1 1.5 2h8A1.5 1.5 0 0 1 11 3.5v2a.5.5 0 0 1-1 0v-2z"/>
  <path fill-rule="evenodd" d="M4.146 8.354a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H14.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3z"/>
</svg>                &nbsp;NDNT</a>


            <input type="search" placeholder="Search..." role="searchbox" aria-label="search"
                   pattern=".+" required>



            <h2>API Documentation</h2>
                <ul class="memberlist">
            <li>
                    <a class="variable" href="#LayerTypes">LayerTypes</a>
            </li>
            <li>
                    <a class="class" href="#FFnetwork">FFnetwork</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#FFnetwork.__init__">FFnetwork</a>
                        </li>
                        <li>
                                <a class="variable" href="#FFnetwork.network_type">network_type</a>
                        </li>
                        <li>
                                <a class="variable" href="#FFnetwork.layer_list">layer_list</a>
                        </li>
                        <li>
                                <a class="variable" href="#FFnetwork.layer_types">layer_types</a>
                        </li>
                        <li>
                                <a class="variable" href="#FFnetwork.xstim_n">xstim_n</a>
                        </li>
                        <li>
                                <a class="variable" href="#FFnetwork.ffnets_in">ffnets_in</a>
                        </li>
                        <li>
                                <a class="variable" href="#FFnetwork.layers">layers</a>
                        </li>
                        <li>
                                <a class="variable" href="#FFnetwork.output_dims">output_dims</a>
                        </li>
                        <li>
                                <a class="variable" href="#FFnetwork.num_outputs">num_outputs</a>
                        </li>
                        <li>
                                <a class="function" href="#FFnetwork.determine_input_dims">determine_input_dims</a>
                        </li>
                        <li>
                                <a class="function" href="#FFnetwork.preprocess_input">preprocess_input</a>
                        </li>
                        <li>
                                <a class="function" href="#FFnetwork.forward">forward</a>
                        </li>
                        <li>
                                <a class="function" href="#FFnetwork.prepare_regularization">prepare_regularization</a>
                        </li>
                        <li>
                                <a class="function" href="#FFnetwork.compute_reg_loss">compute_reg_loss</a>
                        </li>
                        <li>
                                <a class="function" href="#FFnetwork.list_parameters">list_parameters</a>
                        </li>
                        <li>
                                <a class="function" href="#FFnetwork.set_parameters">set_parameters</a>
                        </li>
                        <li>
                                <a class="function" href="#FFnetwork.set_reg_val">set_reg_val</a>
                        </li>
                        <li>
                                <a class="function" href="#FFnetwork.plot_filters">plot_filters</a>
                        </li>
                        <li>
                                <a class="function" href="#FFnetwork.get_weights">get_weights</a>
                        </li>
                        <li>
                                <a class="function" href="#FFnetwork.ffnet_dict">ffnet_dict</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#ScaffoldNetwork">ScaffoldNetwork</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#ScaffoldNetwork.__init__">ScaffoldNetwork</a>
                        </li>
                        <li>
                                <a class="variable" href="#ScaffoldNetwork.network_type">network_type</a>
                        </li>
                        <li>
                                <a class="variable" href="#ScaffoldNetwork.num_lags_out">num_lags_out</a>
                        </li>
                        <li>
                                <a class="variable" href="#ScaffoldNetwork.spatial_dims">spatial_dims</a>
                        </li>
                        <li>
                                <a class="variable" href="#ScaffoldNetwork.filter_count">filter_count</a>
                        </li>
                        <li>
                                <a class="function" href="#ScaffoldNetwork.forward">forward</a>
                        </li>
                        <li>
                                <a class="function" href="#ScaffoldNetwork.ffnet_dict">ffnet_dict</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#ScaffoldNetwork3d">ScaffoldNetwork3d</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#ScaffoldNetwork3d.__init__">ScaffoldNetwork3d</a>
                        </li>
                        <li>
                                <a class="variable" href="#ScaffoldNetwork3d.network_type">network_type</a>
                        </li>
                        <li>
                                <a class="variable" href="#ScaffoldNetwork3d.num_lags_out">num_lags_out</a>
                        </li>
                        <li>
                                <a class="function" href="#ScaffoldNetwork3d.forward">forward</a>
                        </li>
                        <li>
                                <a class="function" href="#ScaffoldNetwork3d.ffnet_dict">ffnet_dict</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#ReadoutNetwork">ReadoutNetwork</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#ReadoutNetwork.__init__">ReadoutNetwork</a>
                        </li>
                        <li>
                                <a class="variable" href="#ReadoutNetwork.network_type">network_type</a>
                        </li>
                        <li>
                                <a class="function" href="#ReadoutNetwork.determine_input_dims">determine_input_dims</a>
                        </li>
                        <li>
                                <a class="function" href="#ReadoutNetwork.forward">forward</a>
                        </li>
                        <li>
                                <a class="function" href="#ReadoutNetwork.get_readout_locations">get_readout_locations</a>
                        </li>
                        <li>
                                <a class="function" href="#ReadoutNetwork.set_readout_locations">set_readout_locations</a>
                        </li>
                        <li>
                                <a class="function" href="#ReadoutNetwork.ffnet_dict">ffnet_dict</a>
                        </li>
                </ul>

            </li>
            <li>
                    <a class="class" href="#FFnet_external">FFnet_external</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#FFnet_external.__init__">FFnet_external</a>
                        </li>
                        <li>
                                <a class="variable" href="#FFnet_external.network_type">network_type</a>
                        </li>
                        <li>
                                <a class="variable" href="#FFnet_external.input_dims_reshape">input_dims_reshape</a>
                        </li>
                        <li>
                                <a class="function" href="#FFnet_external.forward">forward</a>
                        </li>
                        <li>
                                <a class="function" href="#FFnet_external.compute_reg_loss">compute_reg_loss</a>
                        </li>
                        <li>
                                <a class="function" href="#FFnet_external.list_params">list_params</a>
                        </li>
                        <li>
                                <a class="function" href="#FFnet_external.set_params">set_params</a>
                        </li>
                        <li>
                                <a class="function" href="#FFnet_external.ffnet_dict">ffnet_dict</a>
                        </li>
                </ul>

            </li>
    </ul>



        <a class="attribution" title="pdoc: Python API documentation generator" href="https://pdoc.dev" target="_blank">
            built with <span class="visually-hidden">pdoc</span><img
                alt="pdoc logo"
                src="data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20role%3D%22img%22%20aria-label%3D%22pdoc%20logo%22%20width%3D%22300%22%20height%3D%22150%22%20viewBox%3D%22-1%200%2060%2030%22%3E%3Ctitle%3Epdoc%3C/title%3E%3Cpath%20d%3D%22M29.621%2021.293c-.011-.273-.214-.475-.511-.481a.5.5%200%200%200-.489.503l-.044%201.393c-.097.551-.695%201.215-1.566%201.704-.577.428-1.306.486-2.193.182-1.426-.617-2.467-1.654-3.304-2.487l-.173-.172a3.43%203.43%200%200%200-.365-.306.49.49%200%200%200-.286-.196c-1.718-1.06-4.931-1.47-7.353.191l-.219.15c-1.707%201.187-3.413%202.131-4.328%201.03-.02-.027-.49-.685-.141-1.763.233-.721.546-2.408.772-4.076.042-.09.067-.187.046-.288.166-1.347.277-2.625.241-3.351%201.378-1.008%202.271-2.586%202.271-4.362%200-.976-.272-1.935-.788-2.774-.057-.094-.122-.18-.184-.268.033-.167.052-.339.052-.516%200-1.477-1.202-2.679-2.679-2.679-.791%200-1.496.352-1.987.9a6.3%206.3%200%200%200-1.001.029c-.492-.564-1.207-.929-2.012-.929-1.477%200-2.679%201.202-2.679%202.679A2.65%202.65%200%200%200%20.97%206.554c-.383.747-.595%201.572-.595%202.41%200%202.311%201.507%204.29%203.635%205.107-.037.699-.147%202.27-.423%203.294l-.137.461c-.622%202.042-2.515%208.257%201.727%2010.643%201.614.908%203.06%201.248%204.317%201.248%202.665%200%204.492-1.524%205.322-2.401%201.476-1.559%202.886-1.854%206.491.82%201.877%201.393%203.514%201.753%204.861%201.068%202.223-1.713%202.811-3.867%203.399-6.374.077-.846.056-1.469.054-1.537zm-4.835%204.313c-.054.305-.156.586-.242.629-.034-.007-.131-.022-.307-.157-.145-.111-.314-.478-.456-.908.221.121.432.25.675.355.115.039.219.051.33.081zm-2.251-1.238c-.05.33-.158.648-.252.694-.022.001-.125-.018-.307-.157-.217-.166-.488-.906-.639-1.573.358.344.754.693%201.198%201.036zm-3.887-2.337c-.006-.116-.018-.231-.041-.342.635.145%201.189.368%201.599.625.097.231.166.481.174.642-.03.049-.055.101-.067.158-.046.013-.128.026-.298.004-.278-.037-.901-.57-1.367-1.087zm-1.127-.497c.116.306.176.625.12.71-.019.014-.117.045-.345.016-.206-.027-.604-.332-.986-.695.41-.051.816-.056%201.211-.031zm-4.535%201.535c.209.22.379.47.358.598-.006.041-.088.138-.351.234-.144.055-.539-.063-.979-.259a11.66%2011.66%200%200%200%20.972-.573zm.983-.664c.359-.237.738-.418%201.126-.554.25.237.479.548.457.694-.006.042-.087.138-.351.235-.174.064-.694-.105-1.232-.375zm-3.381%201.794c-.022.145-.061.29-.149.401-.133.166-.358.248-.69.251h-.002c-.133%200-.306-.26-.45-.621.417.091.854.07%201.291-.031zm-2.066-8.077a4.78%204.78%200%200%201-.775-.584c.172-.115.505-.254.88-.378l-.105.962zm-.331%202.302a10.32%2010.32%200%200%201-.828-.502c.202-.143.576-.328.984-.49l-.156.992zm-.45%202.157l-.701-.403c.214-.115.536-.249.891-.376a11.57%2011.57%200%200%201-.19.779zm-.181%201.716c.064.398.194.702.298.893-.194-.051-.435-.162-.736-.398.061-.119.224-.3.438-.495zM8.87%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zm-.735-.389a1.15%201.15%200%200%200-.314.783%201.16%201.16%200%200%200%201.162%201.162c.457%200%20.842-.27%201.032-.653.026.117.042.238.042.362a1.68%201.68%200%200%201-1.679%201.679%201.68%201.68%200%200%201-1.679-1.679c0-.843.626-1.535%201.436-1.654zM5.059%205.406A1.68%201.68%200%200%201%203.38%207.085a1.68%201.68%200%200%201-1.679-1.679c0-.037.009-.072.011-.109.21.3.541.508.935.508a1.16%201.16%200%200%200%201.162-1.162%201.14%201.14%200%200%200-.474-.912c.015%200%20.03-.005.045-.005.926.001%201.679.754%201.679%201.68zM3.198%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zM1.375%208.964c0-.52.103-1.035.288-1.52.466.394%201.06.64%201.717.64%201.144%200%202.116-.725%202.499-1.738.383%201.012%201.355%201.738%202.499%201.738.867%200%201.631-.421%202.121-1.062.307.605.478%201.267.478%201.942%200%202.486-2.153%204.51-4.801%204.51s-4.801-2.023-4.801-4.51zm24.342%2019.349c-.985.498-2.267.168-3.813-.979-3.073-2.281-5.453-3.199-7.813-.705-1.315%201.391-4.163%203.365-8.423.97-3.174-1.786-2.239-6.266-1.261-9.479l.146-.492c.276-1.02.395-2.457.444-3.268a6.11%206.11%200%200%200%201.18.115%206.01%206.01%200%200%200%202.536-.562l-.006.175c-.802.215-1.848.612-2.021%201.25-.079.295.021.601.274.837.219.203.415.364.598.501-.667.304-1.243.698-1.311%201.179-.02.144-.022.507.393.787.213.144.395.26.564.365-1.285.521-1.361.96-1.381%201.126-.018.142-.011.496.427.746l.854.489c-.473.389-.971.914-.999%201.429-.018.278.095.532.316.713.675.556%201.231.721%201.653.721.059%200%20.104-.014.158-.02.207.707.641%201.64%201.513%201.64h.013c.8-.008%201.236-.345%201.462-.626.173-.216.268-.457.325-.692.424.195.93.374%201.372.374.151%200%20.294-.021.423-.068.732-.27.944-.704.993-1.021.009-.061.003-.119.002-.179.266.086.538.147.789.147.15%200%20.294-.021.423-.069.542-.2.797-.489.914-.754.237.147.478.258.704.288.106.014.205.021.296.021.356%200%20.595-.101.767-.229.438.435%201.094.992%201.656%201.067.106.014.205.021.296.021a1.56%201.56%200%200%200%20.323-.035c.17.575.453%201.289.866%201.605.358.273.665.362.914.362a.99.99%200%200%200%20.421-.093%201.03%201.03%200%200%200%20.245-.164c.168.428.39.846.68%201.068.358.273.665.362.913.362a.99.99%200%200%200%20.421-.093c.317-.148.512-.448.639-.762.251.157.495.257.726.257.127%200%20.25-.024.37-.071.427-.17.706-.617.841-1.314.022-.015.047-.022.068-.038.067-.051.133-.104.196-.159-.443%201.486-1.107%202.761-2.086%203.257zM8.66%209.925a.5.5%200%201%200-1%200c0%20.653-.818%201.205-1.787%201.205s-1.787-.552-1.787-1.205a.5.5%200%201%200-1%200c0%201.216%201.25%202.205%202.787%202.205s2.787-.989%202.787-2.205zm4.4%2015.965l-.208.097c-2.661%201.258-4.708%201.436-6.086.527-1.542-1.017-1.88-3.19-1.844-4.198a.4.4%200%200%200-.385-.414c-.242-.029-.406.164-.414.385-.046%201.249.367%203.686%202.202%204.896.708.467%201.547.7%202.51.7%201.248%200%202.706-.392%204.362-1.174l.185-.086a.4.4%200%200%200%20.205-.527c-.089-.204-.326-.291-.527-.206zM9.547%202.292c.093.077.205.114.317.114a.5.5%200%200%200%20.318-.886L8.817.397a.5.5%200%200%200-.703.068.5.5%200%200%200%20.069.703l1.364%201.124zm-7.661-.065c.086%200%20.173-.022.253-.068l1.523-.893a.5.5%200%200%200-.506-.863l-1.523.892a.5.5%200%200%200-.179.685c.094.158.261.247.432.247z%22%20transform%3D%22matrix%28-1%200%200%201%2058%200%29%22%20fill%3D%22%233bb300%22/%3E%3Cpath%20d%3D%22M.3%2021.86V10.18q0-.46.02-.68.04-.22.18-.5.28-.54%201.34-.54%201.06%200%201.42.28.38.26.44.78.76-1.04%202.38-1.04%201.64%200%203.1%201.54%201.46%201.54%201.46%203.58%200%202.04-1.46%203.58-1.44%201.54-3.08%201.54-1.64%200-2.38-.92v4.04q0%20.46-.04.68-.02.22-.18.5-.14.3-.5.42-.36.12-.98.12-.62%200-1-.12-.36-.12-.52-.4-.14-.28-.18-.5-.02-.22-.02-.68zm3.96-9.42q-.46.54-.46%201.18%200%20.64.46%201.18.48.52%201.2.52.74%200%201.24-.52.52-.52.52-1.18%200-.66-.48-1.18-.48-.54-1.26-.54-.76%200-1.22.54zm14.741-8.36q.16-.3.54-.42.38-.12%201-.12.64%200%201.02.12.38.12.52.42.16.3.18.54.04.22.04.68v11.94q0%20.46-.04.7-.02.22-.18.5-.3.54-1.7.54-1.38%200-1.54-.98-.84.96-2.34.96-1.8%200-3.28-1.56-1.48-1.58-1.48-3.66%200-2.1%201.48-3.68%201.5-1.58%203.28-1.58%201.48%200%202.3%201v-4.2q0-.46.02-.68.04-.24.18-.52zm-3.24%2010.86q.52.54%201.26.54.74%200%201.22-.54.5-.54.5-1.18%200-.66-.48-1.22-.46-.56-1.26-.56-.8%200-1.28.56-.48.54-.48%201.2%200%20.66.52%201.2zm7.833-1.2q0-2.4%201.68-3.96%201.68-1.56%203.84-1.56%202.16%200%203.82%201.56%201.66%201.54%201.66%203.94%200%201.66-.86%202.96-.86%201.28-2.1%201.9-1.22.6-2.54.6-1.32%200-2.56-.64-1.24-.66-2.1-1.92-.84-1.28-.84-2.88zm4.18%201.44q.64.48%201.3.48.66%200%201.32-.5.66-.5.66-1.48%200-.98-.62-1.46-.62-.48-1.34-.48-.72%200-1.34.5-.62.5-.62%201.48%200%20.96.64%201.46zm11.412-1.44q0%20.84.56%201.32.56.46%201.18.46.64%200%201.18-.36.56-.38.9-.38.6%200%201.46%201.06.46.58.46%201.04%200%20.76-1.1%201.42-1.14.8-2.8.8-1.86%200-3.58-1.34-.82-.64-1.34-1.7-.52-1.08-.52-2.36%200-1.3.52-2.34.52-1.06%201.34-1.7%201.66-1.32%203.54-1.32.76%200%201.48.22.72.2%201.06.4l.32.2q.36.24.56.38.52.4.52.92%200%20.5-.42%201.14-.72%201.1-1.38%201.1-.38%200-1.08-.44-.36-.34-1.04-.34-.66%200-1.24.48-.58.48-.58%201.34z%22%20fill%3D%22green%22/%3E%3C/svg%3E"/>
        </a>
</div>
    </nav>
    <main class="pdoc">
            <section class="module-info">
                    <h1 class="modulename">
<a href="./../NDNT.html">NDNT</a><wbr>.networks    </h1>

                
                        <input id="mod-networks-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">

                        <label class="view-source-button" for="mod-networks-view-source"><span>View Source</span></label>

                        <div class="pdoc-code codehilite"><pre><span></span><span id="L-1"><a href="#L-1"><span class="linenos">  1</span></a><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span><span id="L-2"><a href="#L-2"><span class="linenos">  2</span></a><span class="kn">import</span> <span class="nn">torch</span>
</span><span id="L-3"><a href="#L-3"><span class="linenos">  3</span></a><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
</span><span id="L-4"><a href="#L-4"><span class="linenos">  4</span></a>
</span><span id="L-5"><a href="#L-5"><span class="linenos">  5</span></a><span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">reduce</span>
</span><span id="L-6"><a href="#L-6"><span class="linenos">  6</span></a><span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>
</span><span id="L-7"><a href="#L-7"><span class="linenos">  7</span></a>
</span><span id="L-8"><a href="#L-8"><span class="linenos">  8</span></a><span class="kn">from</span> <span class="nn">NDNT.modules</span> <span class="kn">import</span> <span class="n">layers</span>
</span><span id="L-9"><a href="#L-9"><span class="linenos">  9</span></a>
</span><span id="L-10"><a href="#L-10"><span class="linenos"> 10</span></a><span class="n">LayerTypes</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="L-11"><a href="#L-11"><span class="linenos"> 11</span></a>    <span class="s1">&#39;normal&#39;</span><span class="p">:</span> <span class="n">layers</span><span class="o">.</span><span class="n">NDNLayer</span><span class="p">,</span>
</span><span id="L-12"><a href="#L-12"><span class="linenos"> 12</span></a>    <span class="s1">&#39;conv&#39;</span><span class="p">:</span> <span class="n">layers</span><span class="o">.</span><span class="n">ConvLayer</span><span class="p">,</span>
</span><span id="L-13"><a href="#L-13"><span class="linenos"> 13</span></a>    <span class="s1">&#39;divnorm&#39;</span><span class="p">:</span> <span class="n">layers</span><span class="o">.</span><span class="n">DivNormLayer</span><span class="p">,</span>
</span><span id="L-14"><a href="#L-14"><span class="linenos"> 14</span></a>    <span class="s1">&#39;tconv&#39;</span><span class="p">:</span> <span class="n">layers</span><span class="o">.</span><span class="n">TconvLayer</span><span class="p">,</span>
</span><span id="L-15"><a href="#L-15"><span class="linenos"> 15</span></a>    <span class="s1">&#39;stconv&#39;</span><span class="p">:</span> <span class="n">layers</span><span class="o">.</span><span class="n">STconvLayer</span><span class="p">,</span>
</span><span id="L-16"><a href="#L-16"><span class="linenos"> 16</span></a>    <span class="s1">&#39;tlayer&#39;</span><span class="p">:</span> <span class="n">layers</span><span class="o">.</span><span class="n">Tlayer</span><span class="p">,</span>
</span><span id="L-17"><a href="#L-17"><span class="linenos"> 17</span></a>    <span class="s1">&#39;biconv&#39;</span><span class="p">:</span> <span class="n">layers</span><span class="o">.</span><span class="n">BiConvLayer1D</span><span class="p">,</span>
</span><span id="L-18"><a href="#L-18"><span class="linenos"> 18</span></a>    <span class="s1">&#39;bistconv&#39;</span><span class="p">:</span> <span class="n">layers</span><span class="o">.</span><span class="n">BiSTconv1D</span><span class="p">,</span>
</span><span id="L-19"><a href="#L-19"><span class="linenos"> 19</span></a>    <span class="c1">#&#39;channelconv&#39;: layers.ChannelConvLayer,</span>
</span><span id="L-20"><a href="#L-20"><span class="linenos"> 20</span></a>    <span class="s1">&#39;ori&#39;</span><span class="p">:</span> <span class="n">layers</span><span class="o">.</span><span class="n">OriLayer</span><span class="p">,</span>
</span><span id="L-21"><a href="#L-21"><span class="linenos"> 21</span></a>    <span class="s1">&#39;oriconv&#39;</span><span class="p">:</span> <span class="n">layers</span><span class="o">.</span><span class="n">OriConvLayer</span><span class="p">,</span>
</span><span id="L-22"><a href="#L-22"><span class="linenos"> 22</span></a>    <span class="s1">&#39;conv3d&#39;</span><span class="p">:</span> <span class="n">layers</span><span class="o">.</span><span class="n">ConvLayer3D</span><span class="p">,</span>
</span><span id="L-23"><a href="#L-23"><span class="linenos"> 23</span></a>    <span class="s1">&#39;oolayer&#39;</span><span class="p">:</span> <span class="n">layers</span><span class="o">.</span><span class="n">OnOffLayer</span><span class="p">,</span>
</span><span id="L-24"><a href="#L-24"><span class="linenos"> 24</span></a>    <span class="s1">&#39;masklayer&#39;</span><span class="p">:</span> <span class="n">layers</span><span class="o">.</span><span class="n">MaskLayer</span><span class="p">,</span>
</span><span id="L-25"><a href="#L-25"><span class="linenos"> 25</span></a>    <span class="s1">&#39;iter&#39;</span><span class="p">:</span> <span class="n">layers</span><span class="o">.</span><span class="n">IterLayer</span><span class="p">,</span>
</span><span id="L-26"><a href="#L-26"><span class="linenos"> 26</span></a>    <span class="s1">&#39;iterT&#39;</span><span class="p">:</span> <span class="n">layers</span><span class="o">.</span><span class="n">IterTlayer</span><span class="p">,</span>
</span><span id="L-27"><a href="#L-27"><span class="linenos"> 27</span></a>    <span class="s1">&#39;iterST&#39;</span><span class="p">:</span> <span class="n">layers</span><span class="o">.</span><span class="n">IterSTlayer</span><span class="p">,</span>
</span><span id="L-28"><a href="#L-28"><span class="linenos"> 28</span></a>    <span class="s1">&#39;readout&#39;</span><span class="p">:</span> <span class="n">layers</span><span class="o">.</span><span class="n">ReadoutLayer</span><span class="p">,</span>
</span><span id="L-29"><a href="#L-29"><span class="linenos"> 29</span></a>    <span class="s1">&#39;readout3d&#39;</span><span class="p">:</span> <span class="n">layers</span><span class="o">.</span><span class="n">ReadoutLayer3d</span><span class="p">,</span>
</span><span id="L-30"><a href="#L-30"><span class="linenos"> 30</span></a>    <span class="s1">&#39;fixation&#39;</span><span class="p">:</span> <span class="n">layers</span><span class="o">.</span><span class="n">FixationLayer</span><span class="p">,</span>
</span><span id="L-31"><a href="#L-31"><span class="linenos"> 31</span></a>    <span class="s1">&#39;lag&#39;</span><span class="p">:</span> <span class="n">layers</span><span class="o">.</span><span class="n">LagLayer</span><span class="p">,</span>
</span><span id="L-32"><a href="#L-32"><span class="linenos"> 32</span></a>    <span class="s1">&#39;time&#39;</span><span class="p">:</span> <span class="n">layers</span><span class="o">.</span><span class="n">TimeLayer</span><span class="p">,</span>
</span><span id="L-33"><a href="#L-33"><span class="linenos"> 33</span></a>    <span class="s1">&#39;dim0&#39;</span><span class="p">:</span> <span class="n">layers</span><span class="o">.</span><span class="n">Dim0Layer</span><span class="p">,</span>
</span><span id="L-34"><a href="#L-34"><span class="linenos"> 34</span></a>    <span class="s1">&#39;dimSP&#39;</span><span class="p">:</span> <span class="n">layers</span><span class="o">.</span><span class="n">DimSPLayer</span><span class="p">,</span>
</span><span id="L-35"><a href="#L-35"><span class="linenos"> 35</span></a>    <span class="s1">&#39;dimSPT&#39;</span><span class="p">:</span> <span class="n">layers</span><span class="o">.</span><span class="n">DimSPTLayer</span><span class="p">,</span>
</span><span id="L-36"><a href="#L-36"><span class="linenos"> 36</span></a>    <span class="s1">&#39;channel&#39;</span><span class="p">:</span> <span class="n">layers</span><span class="o">.</span><span class="n">ChannelLayer</span><span class="p">,</span>
</span><span id="L-37"><a href="#L-37"><span class="linenos"> 37</span></a>    <span class="s1">&#39;LVlayer&#39;</span><span class="p">:</span> <span class="n">layers</span><span class="o">.</span><span class="n">LVLayer</span><span class="p">,</span>
</span><span id="L-38"><a href="#L-38"><span class="linenos"> 38</span></a>    <span class="s1">&#39;l1layer&#39;</span><span class="p">:</span> <span class="n">layers</span><span class="o">.</span><span class="n">L1convLayer</span>
</span><span id="L-39"><a href="#L-39"><span class="linenos"> 39</span></a>    <span class="c1"># &#39;external&#39;: layers.ExternalLayer,    </span>
</span><span id="L-40"><a href="#L-40"><span class="linenos"> 40</span></a>    <span class="c1">#&#39;res&#39;: layers.ResLayer,</span>
</span><span id="L-41"><a href="#L-41"><span class="linenos"> 41</span></a><span class="p">}</span>
</span><span id="L-42"><a href="#L-42"><span class="linenos"> 42</span></a>
</span><span id="L-43"><a href="#L-43"><span class="linenos"> 43</span></a><span class="n">_valid_ffnet_types</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;normal&#39;</span><span class="p">,</span> <span class="s1">&#39;add&#39;</span><span class="p">,</span> <span class="s1">&#39;mult&#39;</span><span class="p">,</span> <span class="s1">&#39;readout&#39;</span><span class="p">,</span> <span class="s1">&#39;scaffold&#39;</span><span class="p">,</span> <span class="s1">&#39;scaffold3d&#39;</span><span class="p">]</span>
</span><span id="L-44"><a href="#L-44"><span class="linenos"> 44</span></a>      
</span><span id="L-45"><a href="#L-45"><span class="linenos"> 45</span></a><span class="k">class</span> <span class="nc">FFnetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="L-46"><a href="#L-46"><span class="linenos"> 46</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-47"><a href="#L-47"><span class="linenos"> 47</span></a><span class="sd">    Initializes an instance of the network.</span>
</span><span id="L-48"><a href="#L-48"><span class="linenos"> 48</span></a>
</span><span id="L-49"><a href="#L-49"><span class="linenos"> 49</span></a><span class="sd">    Args:</span>
</span><span id="L-50"><a href="#L-50"><span class="linenos"> 50</span></a><span class="sd">        layer_list (list, optional): A list of dictionaries representing the layers of the network. Defaults to None.</span>
</span><span id="L-51"><a href="#L-51"><span class="linenos"> 51</span></a><span class="sd">        ffnet_type (str, optional): The type of the feedforward network. Defaults to &#39;normal&#39;.</span>
</span><span id="L-52"><a href="#L-52"><span class="linenos"> 52</span></a><span class="sd">        xstim_n (str, optional): The name of the stimulus input. Defaults to &#39;stim&#39;.</span>
</span><span id="L-53"><a href="#L-53"><span class="linenos"> 53</span></a><span class="sd">        ffnet_n (list, optional): A list of feedforward networks. Defaults to None.</span>
</span><span id="L-54"><a href="#L-54"><span class="linenos"> 54</span></a><span class="sd">        input_dims_list (list, optional): A list of input dimensions for each layer. Defaults to None.</span>
</span><span id="L-55"><a href="#L-55"><span class="linenos"> 55</span></a><span class="sd">        reg_list (list, optional): A list of regularization parameters. Defaults to None.</span>
</span><span id="L-56"><a href="#L-56"><span class="linenos"> 56</span></a><span class="sd">        scaffold_levels (list, optional): A list of scaffold levels. Defaults to None.</span>
</span><span id="L-57"><a href="#L-57"><span class="linenos"> 57</span></a><span class="sd">        **kwargs: Additional keyword arguments.</span>
</span><span id="L-58"><a href="#L-58"><span class="linenos"> 58</span></a>
</span><span id="L-59"><a href="#L-59"><span class="linenos"> 59</span></a><span class="sd">    Raises:</span>
</span><span id="L-60"><a href="#L-60"><span class="linenos"> 60</span></a><span class="sd">        AssertionError: If layer_list is not provided.</span>
</span><span id="L-61"><a href="#L-61"><span class="linenos"> 61</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-62"><a href="#L-62"><span class="linenos"> 62</span></a>
</span><span id="L-63"><a href="#L-63"><span class="linenos"> 63</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
</span><span id="L-64"><a href="#L-64"><span class="linenos"> 64</span></a>                <span class="n">layer_list</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-65"><a href="#L-65"><span class="linenos"> 65</span></a>                <span class="n">ffnet_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;normal&#39;</span><span class="p">,</span>
</span><span id="L-66"><a href="#L-66"><span class="linenos"> 66</span></a>                <span class="n">xstim_n</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;stim&#39;</span><span class="p">,</span>
</span><span id="L-67"><a href="#L-67"><span class="linenos"> 67</span></a>                <span class="n">ffnet_n</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-68"><a href="#L-68"><span class="linenos"> 68</span></a>                <span class="n">input_dims_list</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-69"><a href="#L-69"><span class="linenos"> 69</span></a>                <span class="n">reg_list</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-70"><a href="#L-70"><span class="linenos"> 70</span></a>                <span class="n">scaffold_levels</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="L-71"><a href="#L-71"><span class="linenos"> 71</span></a>                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="L-72"><a href="#L-72"><span class="linenos"> 72</span></a>                <span class="p">):</span>
</span><span id="L-73"><a href="#L-73"><span class="linenos"> 73</span></a>        <span class="c1"># if len(kwargs) &gt; 0:</span>
</span><span id="L-74"><a href="#L-74"><span class="linenos"> 74</span></a>        <span class="c1">#     print(&quot;FFnet: unknown kwargs:&quot;, kwargs)</span>
</span><span id="L-75"><a href="#L-75"><span class="linenos"> 75</span></a>        <span class="k">assert</span> <span class="n">layer_list</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;FFnetwork: Must supply a layer_list.&quot;</span>
</span><span id="L-76"><a href="#L-76"><span class="linenos"> 76</span></a>        
</span><span id="L-77"><a href="#L-77"><span class="linenos"> 77</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-78"><a href="#L-78"><span class="linenos"> 78</span></a>        
</span><span id="L-79"><a href="#L-79"><span class="linenos"> 79</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">network_type</span> <span class="o">=</span> <span class="n">ffnet_type</span>
</span><span id="L-80"><a href="#L-80"><span class="linenos"> 80</span></a>        <span class="c1">#print(&quot;FFnet: network type:&quot;, self.network_type)</span>
</span><span id="L-81"><a href="#L-81"><span class="linenos"> 81</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">network_type</span> <span class="ow">in</span> <span class="n">_valid_ffnet_types</span><span class="p">,</span> <span class="s2">&quot;ffnet_type &quot;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">network_type</span> <span class="o">+</span> <span class="s2">&quot; is unknown.&quot;</span>
</span><span id="L-82"><a href="#L-82"><span class="linenos"> 82</span></a>
</span><span id="L-83"><a href="#L-83"><span class="linenos"> 83</span></a>        <span class="c1"># Format and record inputs into ffnet</span>
</span><span id="L-84"><a href="#L-84"><span class="linenos"> 84</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layer_list</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">layer_list</span><span class="p">)</span>
</span><span id="L-85"><a href="#L-85"><span class="linenos"> 85</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layer_types</span> <span class="o">=</span> <span class="p">[]</span>   <span class="c1"># read from layer_list (if necessary at all)</span>
</span><span id="L-86"><a href="#L-86"><span class="linenos"> 86</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">xstim_n</span> <span class="o">=</span> <span class="n">xstim_n</span>
</span><span id="L-87"><a href="#L-87"><span class="linenos"> 87</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">ffnets_in</span> <span class="o">=</span> <span class="n">ffnet_n</span>
</span><span id="L-88"><a href="#L-88"><span class="linenos"> 88</span></a>
</span><span id="L-89"><a href="#L-89"><span class="linenos"> 89</span></a>        <span class="n">num_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_list</span><span class="p">)</span>
</span><span id="L-90"><a href="#L-90"><span class="linenos"> 90</span></a>
</span><span id="L-91"><a href="#L-91"><span class="linenos"> 91</span></a>        <span class="k">if</span> <span class="n">num_layers</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="L-92"><a href="#L-92"><span class="linenos"> 92</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
</span><span id="L-93"><a href="#L-93"><span class="linenos"> 93</span></a>            <span class="k">return</span>
</span><span id="L-94"><a href="#L-94"><span class="linenos"> 94</span></a>            
</span><span id="L-95"><a href="#L-95"><span class="linenos"> 95</span></a>        <span class="c1"># Establish input dims from the network</span>
</span><span id="L-96"><a href="#L-96"><span class="linenos"> 96</span></a>        <span class="k">if</span> <span class="n">input_dims_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-97"><a href="#L-97"><span class="linenos"> 97</span></a>            <span class="c1"># then pull from first layer</span>
</span><span id="L-98"><a href="#L-98"><span class="linenos"> 98</span></a>            <span class="k">assert</span> <span class="n">layer_list</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;input_dims&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;If input_dims is not specified, it must be specified in layer-0&quot;</span>
</span><span id="L-99"><a href="#L-99"><span class="linenos"> 99</span></a>            <span class="n">input_dims_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">layer_list</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;input_dims&#39;</span><span class="p">])]</span>
</span><span id="L-100"><a href="#L-100"><span class="linenos">100</span></a>        
</span><span id="L-101"><a href="#L-101"><span class="linenos">101</span></a>        <span class="c1"># Build input_dims from sources</span>
</span><span id="L-102"><a href="#L-102"><span class="linenos">102</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">determine_input_dims</span><span class="p">(</span><span class="n">input_dims_list</span><span class="p">,</span> <span class="n">ffnet_type</span><span class="o">=</span><span class="n">ffnet_type</span><span class="p">),</span> <span class="s1">&#39;Invalid network inputs.&#39;</span>
</span><span id="L-103"><a href="#L-103"><span class="linenos">103</span></a>
</span><span id="L-104"><a href="#L-104"><span class="linenos">104</span></a>        <span class="c1"># Process regularization into layer-specific list. Will save at this level too</span>
</span><span id="L-105"><a href="#L-105"><span class="linenos">105</span></a>        <span class="c1">#if reg_list is not None:  # can also be entered into layers directly</span>
</span><span id="L-106"><a href="#L-106"><span class="linenos">106</span></a>        <span class="c1">#    reg_params = self.__reg_setup_ffnet( reg_list )</span>
</span><span id="L-107"><a href="#L-107"><span class="linenos">107</span></a>
</span><span id="L-108"><a href="#L-108"><span class="linenos">108</span></a>        <span class="c1"># Make each layer as part of an array</span>
</span><span id="L-109"><a href="#L-109"><span class="linenos">109</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
</span><span id="L-110"><a href="#L-110"><span class="linenos">110</span></a>        <span class="k">for</span> <span class="n">ll</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">):</span>
</span><span id="L-111"><a href="#L-111"><span class="linenos">111</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_list</span><span class="p">[</span><span class="n">ll</span><span class="p">][</span><span class="s1">&#39;input_dims&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-112"><a href="#L-112"><span class="linenos">112</span></a>                <span class="k">if</span> <span class="n">ll</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="L-113"><a href="#L-113"><span class="linenos">113</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">layer_list</span><span class="p">[</span><span class="n">ll</span><span class="p">][</span><span class="s1">&#39;input_dims&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_dims</span><span class="p">)</span>
</span><span id="L-114"><a href="#L-114"><span class="linenos">114</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="L-115"><a href="#L-115"><span class="linenos">115</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">layer_list</span><span class="p">[</span><span class="n">ll</span><span class="p">][</span><span class="s1">&#39;input_dims&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">ll</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">output_dims</span><span class="p">)</span>
</span><span id="L-116"><a href="#L-116"><span class="linenos">116</span></a>            <span class="n">Ltype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_list</span><span class="p">[</span><span class="n">ll</span><span class="p">][</span><span class="s1">&#39;layer_type&#39;</span><span class="p">]</span>
</span><span id="L-117"><a href="#L-117"><span class="linenos">117</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">LayerTypes</span><span class="p">[</span><span class="n">Ltype</span><span class="p">](</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_list</span><span class="p">[</span><span class="n">ll</span><span class="p">])</span> <span class="p">)</span>
</span><span id="L-118"><a href="#L-118"><span class="linenos">118</span></a>
</span><span id="L-119"><a href="#L-119"><span class="linenos">119</span></a>        <span class="c1"># output dims determined by last layer</span>
</span><span id="L-120"><a href="#L-120"><span class="linenos">120</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">output_dims</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">output_dims</span>
</span><span id="L-121"><a href="#L-121"><span class="linenos">121</span></a>
</span><span id="L-122"><a href="#L-122"><span class="linenos">122</span></a>        <span class="c1"># Make scaffold output if requested</span>
</span><span id="L-123"><a href="#L-123"><span class="linenos">123</span></a>        <span class="k">if</span> <span class="n">scaffold_levels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-124"><a href="#L-124"><span class="linenos">124</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># output last layer only</span>
</span><span id="L-125"><a href="#L-125"><span class="linenos">125</span></a>        <span class="k">else</span><span class="p">:</span> <span class="c1"># output specified layers concatenated together</span>
</span><span id="L-126"><a href="#L-126"><span class="linenos">126</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span> <span class="o">=</span> <span class="p">[</span><span class="o">*</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">)[</span><span class="n">scaffold_levels</span><span class="p">:]]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scaffold_levels</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">else</span> <span class="n">scaffold_levels</span>
</span><span id="L-127"><a href="#L-127"><span class="linenos">127</span></a>    <span class="c1"># END FFnetwork.__init__</span>
</span><span id="L-128"><a href="#L-128"><span class="linenos">128</span></a> 
</span><span id="L-129"><a href="#L-129"><span class="linenos">129</span></a>    <span class="nd">@property</span>
</span><span id="L-130"><a href="#L-130"><span class="linenos">130</span></a>    <span class="k">def</span> <span class="nf">num_outputs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-131"><a href="#L-131"><span class="linenos">131</span></a>        <span class="n">n</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="L-132"><a href="#L-132"><span class="linenos">132</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">:</span>
</span><span id="L-133"><a href="#L-133"><span class="linenos">133</span></a>            <span class="n">n</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">output_dims</span>
</span><span id="L-134"><a href="#L-134"><span class="linenos">134</span></a>        <span class="k">return</span> <span class="n">n</span>
</span><span id="L-135"><a href="#L-135"><span class="linenos">135</span></a>
</span><span id="L-136"><a href="#L-136"><span class="linenos">136</span></a>    <span class="k">def</span> <span class="nf">determine_input_dims</span><span class="p">(</span> <span class="bp">self</span><span class="p">,</span> <span class="n">input_dims_list</span><span class="p">,</span> <span class="n">ffnet_type</span><span class="o">=</span><span class="s1">&#39;normal&#39;</span> <span class="p">):</span>
</span><span id="L-137"><a href="#L-137"><span class="linenos">137</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-138"><a href="#L-138"><span class="linenos">138</span></a><span class="sd">        Sets input_dims given network inputs. Can be overloaded depending on the network type. For this base class, there</span>
</span><span id="L-139"><a href="#L-139"><span class="linenos">139</span></a><span class="sd">        are two types of network input: external stimulus (xstim_n) or a list of internal (ffnet_in) networks:</span>
</span><span id="L-140"><a href="#L-140"><span class="linenos">140</span></a><span class="sd">            For external inputs, it just uses the passed-in input_dims</span>
</span><span id="L-141"><a href="#L-141"><span class="linenos">141</span></a><span class="sd">            For internal network inputs, it will concatenate inputs along the filter dimension, but MUST match other dims</span>
</span><span id="L-142"><a href="#L-142"><span class="linenos">142</span></a><span class="sd">        As currently designed, this can either external or internal, but not both</span>
</span><span id="L-143"><a href="#L-143"><span class="linenos">143</span></a><span class="sd">        </span>
</span><span id="L-144"><a href="#L-144"><span class="linenos">144</span></a><span class="sd">        This sets the following internal FFnetwork properties:</span>
</span><span id="L-145"><a href="#L-145"><span class="linenos">145</span></a><span class="sd">            self.input_dims</span>
</span><span id="L-146"><a href="#L-146"><span class="linenos">146</span></a><span class="sd">            self.input_dims_list</span>
</span><span id="L-147"><a href="#L-147"><span class="linenos">147</span></a><span class="sd">        and returns Boolean whether the passed in input dims are valid</span>
</span><span id="L-148"><a href="#L-148"><span class="linenos">148</span></a>
</span><span id="L-149"><a href="#L-149"><span class="linenos">149</span></a><span class="sd">        Args:</span>
</span><span id="L-150"><a href="#L-150"><span class="linenos">150</span></a><span class="sd">            input_dims_list (list): A list of input dimensions for each layer.</span>
</span><span id="L-151"><a href="#L-151"><span class="linenos">151</span></a><span class="sd">            ffnet_type (str): The type of the feedforward network.</span>
</span><span id="L-152"><a href="#L-152"><span class="linenos">152</span></a>
</span><span id="L-153"><a href="#L-153"><span class="linenos">153</span></a><span class="sd">        Returns:</span>
</span><span id="L-154"><a href="#L-154"><span class="linenos">154</span></a><span class="sd">            valid_input_dims (bool): Whether the passed in input dims are valid.</span>
</span><span id="L-155"><a href="#L-155"><span class="linenos">155</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-156"><a href="#L-156"><span class="linenos">156</span></a>
</span><span id="L-157"><a href="#L-157"><span class="linenos">157</span></a>        <span class="n">valid_input_dims</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="L-158"><a href="#L-158"><span class="linenos">158</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffnets_in</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-159"><a href="#L-159"><span class="linenos">159</span></a>            <span class="c1"># then external input (assume from one source)</span>
</span><span id="L-160"><a href="#L-160"><span class="linenos">160</span></a>            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_dims_list</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;FFnet constructor: Only one set of input dims can be specified.&quot;</span>
</span><span id="L-161"><a href="#L-161"><span class="linenos">161</span></a>            <span class="k">assert</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;FFnet constructor: External input dims must be specified.&quot;</span>
</span><span id="L-162"><a href="#L-162"><span class="linenos">162</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">input_dims</span> <span class="o">=</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-163"><a href="#L-163"><span class="linenos">163</span></a>        <span class="k">else</span><span class="p">:</span> 
</span><span id="L-164"><a href="#L-164"><span class="linenos">164</span></a>            <span class="n">num_input_networks</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ffnets_in</span><span class="p">)</span>
</span><span id="L-165"><a href="#L-165"><span class="linenos">165</span></a>            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_dims_list</span><span class="p">)</span> <span class="o">==</span> <span class="n">num_input_networks</span><span class="p">,</span> <span class="s1">&#39;Internal: misspecification of input_dims for FFnetwork.&#39;</span>
</span><span id="L-166"><a href="#L-166"><span class="linenos">166</span></a>
</span><span id="L-167"><a href="#L-167"><span class="linenos">167</span></a>            <span class="c1"># Go through the input dims of the other ffnetowrks to verify they are valid for the type of network</span>
</span><span id="L-168"><a href="#L-168"><span class="linenos">168</span></a>            <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_input_networks</span><span class="p">):</span>
</span><span id="L-169"><a href="#L-169"><span class="linenos">169</span></a>                <span class="k">if</span> <span class="n">ii</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="L-170"><a href="#L-170"><span class="linenos">170</span></a>                    <span class="n">num_cat_filters</span> <span class="o">=</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-171"><a href="#L-171"><span class="linenos">171</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="L-172"><a href="#L-172"><span class="linenos">172</span></a>                    <span class="k">if</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="n">ii</span><span class="p">][</span><span class="mi">1</span><span class="p">:]</span> <span class="o">!=</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">:]:</span>
</span><span id="L-173"><a href="#L-173"><span class="linenos">173</span></a>                        <span class="k">if</span> <span class="n">ffnet_type</span> <span class="o">==</span> <span class="s1">&#39;add&#39;</span><span class="p">:</span>
</span><span id="L-174"><a href="#L-174"><span class="linenos">174</span></a>                            <span class="k">for</span> <span class="n">jj</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
</span><span id="L-175"><a href="#L-175"><span class="linenos">175</span></a>                                <span class="c1">#if (input_dims_list[ii][jj+1] &gt; 1) | (input_dims_list[0][jj+1] == 1):</span>
</span><span id="L-176"><a href="#L-176"><span class="linenos">176</span></a>                                <span class="k">if</span> <span class="p">(</span><span class="n">input_dims_list</span><span class="p">[</span><span class="n">ii</span><span class="p">][</span><span class="n">jj</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">input_dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">jj</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="L-177"><a href="#L-177"><span class="linenos">177</span></a>                                    <span class="n">valid_input_dims</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="L-178"><a href="#L-178"><span class="linenos">178</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="L-179"><a href="#L-179"><span class="linenos">179</span></a>                            <span class="n">valid_input_dims</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="L-180"><a href="#L-180"><span class="linenos">180</span></a>                    <span class="k">assert</span> <span class="n">valid_input_dims</span><span class="p">,</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;FFnet: invalid concatenation </span><span class="si">%d</span><span class="s2">:&quot;</span><span class="o">%</span><span class="n">ii</span><span class="p">,</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="n">ii</span><span class="p">][</span><span class="mi">1</span><span class="p">:],</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">:]</span> <span class="p">)</span>
</span><span id="L-181"><a href="#L-181"><span class="linenos">181</span></a>
</span><span id="L-182"><a href="#L-182"><span class="linenos">182</span></a>                    <span class="k">if</span> <span class="n">ffnet_type</span> <span class="o">==</span> <span class="s1">&#39;normal&#39;</span><span class="p">:</span> <span class="c1"># then inputs will be concatenated along &#39;filter&#39; dimension</span>
</span><span id="L-183"><a href="#L-183"><span class="linenos">183</span></a>                        <span class="n">num_cat_filters</span> <span class="o">+=</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="n">ii</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-184"><a href="#L-184"><span class="linenos">184</span></a>                    <span class="k">elif</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="n">ii</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-185"><a href="#L-185"><span class="linenos">185</span></a>                        <span class="c1"># these are combined and input to first layer has same size as one input</span>
</span><span id="L-186"><a href="#L-186"><span class="linenos">186</span></a>                        <span class="k">assert</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="n">ii</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">num_cat_filters</span><span class="p">,</span> <span class="s1">&#39;Input dims must be the same for &#39;</span> <span class="o">+</span> <span class="n">ffnet_type</span> <span class="o">+</span> <span class="s1">&#39; ffnetwork&#39;</span>
</span><span id="L-187"><a href="#L-187"><span class="linenos">187</span></a>                    
</span><span id="L-188"><a href="#L-188"><span class="linenos">188</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">input_dims</span> <span class="o">=</span> <span class="p">[</span><span class="n">num_cat_filters</span><span class="p">]</span> <span class="o">+</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">:]</span>
</span><span id="L-189"><a href="#L-189"><span class="linenos">189</span></a>        
</span><span id="L-190"><a href="#L-190"><span class="linenos">190</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">input_dims_list</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">input_dims_list</span><span class="p">)</span>
</span><span id="L-191"><a href="#L-191"><span class="linenos">191</span></a>        <span class="k">return</span> <span class="n">valid_input_dims</span>
</span><span id="L-192"><a href="#L-192"><span class="linenos">192</span></a>    <span class="c1"># END FFnetwork.determine_input_dims</span>
</span><span id="L-193"><a href="#L-193"><span class="linenos">193</span></a>
</span><span id="L-194"><a href="#L-194"><span class="linenos">194</span></a>    <span class="k">def</span> <span class="nf">preprocess_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="L-195"><a href="#L-195"><span class="linenos">195</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-196"><a href="#L-196"><span class="linenos">196</span></a><span class="sd">        Preprocess input to network.</span>
</span><span id="L-197"><a href="#L-197"><span class="linenos">197</span></a>
</span><span id="L-198"><a href="#L-198"><span class="linenos">198</span></a><span class="sd">        Args:</span>
</span><span id="L-199"><a href="#L-199"><span class="linenos">199</span></a><span class="sd">            inputs (list, torch.Tensor): The input to the network.</span>
</span><span id="L-200"><a href="#L-200"><span class="linenos">200</span></a>
</span><span id="L-201"><a href="#L-201"><span class="linenos">201</span></a><span class="sd">        Returns:</span>
</span><span id="L-202"><a href="#L-202"><span class="linenos">202</span></a><span class="sd">            x (torch.Tensor): The preprocessed input.</span>
</span><span id="L-203"><a href="#L-203"><span class="linenos">203</span></a>
</span><span id="L-204"><a href="#L-204"><span class="linenos">204</span></a><span class="sd">        Raises:</span>
</span><span id="L-205"><a href="#L-205"><span class="linenos">205</span></a><span class="sd">            ValueError: If no layers are defined.</span>
</span><span id="L-206"><a href="#L-206"><span class="linenos">206</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-207"><a href="#L-207"><span class="linenos">207</span></a>
</span><span id="L-208"><a href="#L-208"><span class="linenos">208</span></a>        <span class="c1"># Combine network inputs (if relevant)</span>
</span><span id="L-209"><a href="#L-209"><span class="linenos">209</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="L-210"><a href="#L-210"><span class="linenos">210</span></a>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-211"><a href="#L-211"><span class="linenos">211</span></a>                <span class="n">x</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-212"><a href="#L-212"><span class="linenos">212</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-213"><a href="#L-213"><span class="linenos">213</span></a>                <span class="n">x</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">input_dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># this will allow for broadcasting</span>
</span><span id="L-214"><a href="#L-214"><span class="linenos">214</span></a>                <span class="n">nt</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-215"><a href="#L-215"><span class="linenos">215</span></a>                <span class="k">for</span> <span class="n">mm</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)):</span>
</span><span id="L-216"><a href="#L-216"><span class="linenos">216</span></a>                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">network_type</span> <span class="o">==</span> <span class="s1">&#39;normal&#39;</span><span class="p">:</span> <span class="c1"># concatentate inputs</span>
</span><span id="L-217"><a href="#L-217"><span class="linenos">217</span></a>                        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">inputs</span><span class="p">[</span><span class="n">mm</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">input_dims_list</span><span class="p">[</span><span class="n">mm</span><span class="p">])),</span> <span class="mi">1</span> <span class="p">)</span>
</span><span id="L-218"><a href="#L-218"><span class="linenos">218</span></a>                    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">network_type</span> <span class="o">==</span> <span class="s1">&#39;add&#39;</span><span class="p">:</span> <span class="c1"># add inputs</span>
</span><span id="L-219"><a href="#L-219"><span class="linenos">219</span></a>                        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">(</span> <span class="n">x</span><span class="p">,</span> <span class="n">inputs</span><span class="p">[</span><span class="n">mm</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">input_dims_list</span><span class="p">[</span><span class="n">mm</span><span class="p">])</span> <span class="p">)</span>
</span><span id="L-220"><a href="#L-220"><span class="linenos">220</span></a>                    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">network_type</span> <span class="o">==</span> <span class="s1">&#39;mult&#39;</span><span class="p">:</span> <span class="c1"># multiply: (input1) x (1+input2)</span>
</span><span id="L-221"><a href="#L-221"><span class="linenos">221</span></a>                        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span>
</span><span id="L-222"><a href="#L-222"><span class="linenos">222</span></a>                            <span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="n">mm</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">input_dims_list</span><span class="p">[</span><span class="n">mm</span><span class="p">]),</span> <span class="mf">1.0</span><span class="p">)</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span> <span class="p">)</span>
</span><span id="L-223"><a href="#L-223"><span class="linenos">223</span></a>                        <span class="c1"># Make sure multiplication is not negative</span>
</span><span id="L-224"><a href="#L-224"><span class="linenos">224</span></a>                <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="n">nt</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span><span id="L-225"><a href="#L-225"><span class="linenos">225</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-226"><a href="#L-226"><span class="linenos">226</span></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">inputs</span>
</span><span id="L-227"><a href="#L-227"><span class="linenos">227</span></a>        <span class="k">return</span> <span class="n">x</span>
</span><span id="L-228"><a href="#L-228"><span class="linenos">228</span></a>
</span><span id="L-229"><a href="#L-229"><span class="linenos">229</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="L-230"><a href="#L-230"><span class="linenos">230</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-231"><a href="#L-231"><span class="linenos">231</span></a><span class="sd">        Forward pass through the network.</span>
</span><span id="L-232"><a href="#L-232"><span class="linenos">232</span></a>
</span><span id="L-233"><a href="#L-233"><span class="linenos">233</span></a><span class="sd">        Args:</span>
</span><span id="L-234"><a href="#L-234"><span class="linenos">234</span></a><span class="sd">            inputs (list, torch.Tensor): The input to the network.</span>
</span><span id="L-235"><a href="#L-235"><span class="linenos">235</span></a>
</span><span id="L-236"><a href="#L-236"><span class="linenos">236</span></a><span class="sd">        Returns:</span>
</span><span id="L-237"><a href="#L-237"><span class="linenos">237</span></a><span class="sd">            x (torch.Tensor): The output of the network.</span>
</span><span id="L-238"><a href="#L-238"><span class="linenos">238</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-239"><a href="#L-239"><span class="linenos">239</span></a>
</span><span id="L-240"><a href="#L-240"><span class="linenos">240</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-241"><a href="#L-241"><span class="linenos">241</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;FFnet: no layers defined.&quot;</span><span class="p">)</span>
</span><span id="L-242"><a href="#L-242"><span class="linenos">242</span></a>        
</span><span id="L-243"><a href="#L-243"><span class="linenos">243</span></a>        <span class="n">out</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># returned </span>
</span><span id="L-244"><a href="#L-244"><span class="linenos">244</span></a>
</span><span id="L-245"><a href="#L-245"><span class="linenos">245</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess_input</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="L-246"><a href="#L-246"><span class="linenos">246</span></a>
</span><span id="L-247"><a href="#L-247"><span class="linenos">247</span></a>        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
</span><span id="L-248"><a href="#L-248"><span class="linenos">248</span></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="L-249"><a href="#L-249"><span class="linenos">249</span></a>            <span class="c1">#out.append(x)</span>
</span><span id="L-250"><a href="#L-250"><span class="linenos">250</span></a>
</span><span id="L-251"><a href="#L-251"><span class="linenos">251</span></a>        <span class="k">return</span> <span class="n">x</span>
</span><span id="L-252"><a href="#L-252"><span class="linenos">252</span></a>        <span class="c1">#return torch.cat([out[ind] for ind in self.scaffold_levels], dim=1)</span>
</span><span id="L-253"><a href="#L-253"><span class="linenos">253</span></a>    <span class="c1"># END FFnetwork.forward</span>
</span><span id="L-254"><a href="#L-254"><span class="linenos">254</span></a>
</span><span id="L-255"><a href="#L-255"><span class="linenos">255</span></a>    <span class="k">def</span> <span class="nf">__reg_setup_ffnet</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reg_params</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="L-256"><a href="#L-256"><span class="linenos">256</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-257"><a href="#L-257"><span class="linenos">257</span></a><span class="sd">        Sets up the regularization params for the network.</span>
</span><span id="L-258"><a href="#L-258"><span class="linenos">258</span></a>
</span><span id="L-259"><a href="#L-259"><span class="linenos">259</span></a><span class="sd">        Args:</span>
</span><span id="L-260"><a href="#L-260"><span class="linenos">260</span></a><span class="sd">            reg_params (dict): The regularization parameters to use.</span>
</span><span id="L-261"><a href="#L-261"><span class="linenos">261</span></a>
</span><span id="L-262"><a href="#L-262"><span class="linenos">262</span></a><span class="sd">        Returns:</span>
</span><span id="L-263"><a href="#L-263"><span class="linenos">263</span></a><span class="sd">            layer_reg_list (list): The regularization parameters for each layer.</span>
</span><span id="L-264"><a href="#L-264"><span class="linenos">264</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-265"><a href="#L-265"><span class="linenos">265</span></a>
</span><span id="L-266"><a href="#L-266"><span class="linenos">266</span></a>        <span class="c1"># Set all default values to none</span>
</span><span id="L-267"><a href="#L-267"><span class="linenos">267</span></a>        <span class="n">num_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_list</span><span class="p">)</span>
</span><span id="L-268"><a href="#L-268"><span class="linenos">268</span></a>        <span class="n">layer_reg_list</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-269"><a href="#L-269"><span class="linenos">269</span></a>        <span class="k">for</span> <span class="n">nn</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">):</span>
</span><span id="L-270"><a href="#L-270"><span class="linenos">270</span></a>            <span class="c1">#layer_reg_list.append(deepcopy(_allowed_reg_types))</span>
</span><span id="L-271"><a href="#L-271"><span class="linenos">271</span></a>            <span class="n">layer_reg_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">deepcopy</span><span class="p">({}))</span>  <span class="c1"># only put regs in that are there</span>
</span><span id="L-272"><a href="#L-272"><span class="linenos">272</span></a>
</span><span id="L-273"><a href="#L-273"><span class="linenos">273</span></a>        <span class="c1"># Set specific regularization</span>
</span><span id="L-274"><a href="#L-274"><span class="linenos">274</span></a>        <span class="k">if</span> <span class="n">reg_params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-275"><a href="#L-275"><span class="linenos">275</span></a>            <span class="k">for</span> <span class="n">kk</span><span class="p">,</span> <span class="n">vv</span> <span class="ow">in</span> <span class="n">reg_params</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="L-276"><a href="#L-276"><span class="linenos">276</span></a>                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">vv</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="L-277"><a href="#L-277"><span class="linenos">277</span></a>                    <span class="n">vv</span> <span class="o">=</span> <span class="p">[</span><span class="n">vv</span><span class="p">]</span>
</span><span id="L-278"><a href="#L-278"><span class="linenos">278</span></a>                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">vv</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">num_layers</span><span class="p">:</span>
</span><span id="L-279"><a href="#L-279"><span class="linenos">279</span></a>                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Warning: reg params too long for&quot;</span><span class="p">,</span> <span class="n">kk</span><span class="p">)</span>
</span><span id="L-280"><a href="#L-280"><span class="linenos">280</span></a>                <span class="k">for</span> <span class="n">nn</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">num_layers</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vv</span><span class="p">))):</span>
</span><span id="L-281"><a href="#L-281"><span class="linenos">281</span></a>                    <span class="n">layer_reg_list</span><span class="p">[</span><span class="n">nn</span><span class="p">][</span><span class="n">kk</span><span class="p">]</span> <span class="o">=</span> <span class="n">vv</span><span class="p">[</span><span class="n">nn</span><span class="p">]</span>
</span><span id="L-282"><a href="#L-282"><span class="linenos">282</span></a>        <span class="k">return</span> <span class="n">layer_reg_list</span>
</span><span id="L-283"><a href="#L-283"><span class="linenos">283</span></a>
</span><span id="L-284"><a href="#L-284"><span class="linenos">284</span></a>    <span class="k">def</span> <span class="nf">prepare_regularization</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="L-285"><a href="#L-285"><span class="linenos">285</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-286"><a href="#L-286"><span class="linenos">286</span></a><span class="sd">        Makes regularization modules with current requested values.</span>
</span><span id="L-287"><a href="#L-287"><span class="linenos">287</span></a><span class="sd">        This is done immediately before training, because it can change during training and tuning.</span>
</span><span id="L-288"><a href="#L-288"><span class="linenos">288</span></a>
</span><span id="L-289"><a href="#L-289"><span class="linenos">289</span></a><span class="sd">        Args:</span>
</span><span id="L-290"><a href="#L-290"><span class="linenos">290</span></a><span class="sd">            device (str, optional): The device to use. Defaults to None.</span>
</span><span id="L-291"><a href="#L-291"><span class="linenos">291</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-292"><a href="#L-292"><span class="linenos">292</span></a>
</span><span id="L-293"><a href="#L-293"><span class="linenos">293</span></a>        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
</span><span id="L-294"><a href="#L-294"><span class="linenos">294</span></a>            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;reg&#39;</span><span class="p">):</span>
</span><span id="L-295"><a href="#L-295"><span class="linenos">295</span></a>                <span class="n">layer</span><span class="o">.</span><span class="n">reg</span><span class="o">.</span><span class="n">build_reg_modules</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="L-296"><a href="#L-296"><span class="linenos">296</span></a>            
</span><span id="L-297"><a href="#L-297"><span class="linenos">297</span></a>    <span class="k">def</span> <span class="nf">compute_reg_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-298"><a href="#L-298"><span class="linenos">298</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-299"><a href="#L-299"><span class="linenos">299</span></a><span class="sd">        Computes the regularization loss.</span>
</span><span id="L-300"><a href="#L-300"><span class="linenos">300</span></a>
</span><span id="L-301"><a href="#L-301"><span class="linenos">301</span></a><span class="sd">        Args:</span>
</span><span id="L-302"><a href="#L-302"><span class="linenos">302</span></a><span class="sd">            None</span>
</span><span id="L-303"><a href="#L-303"><span class="linenos">303</span></a>
</span><span id="L-304"><a href="#L-304"><span class="linenos">304</span></a><span class="sd">        Returns:</span>
</span><span id="L-305"><a href="#L-305"><span class="linenos">305</span></a><span class="sd">            rloss (torch.Tensor): The regularization loss.</span>
</span><span id="L-306"><a href="#L-306"><span class="linenos">306</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-307"><a href="#L-307"><span class="linenos">307</span></a>
</span><span id="L-308"><a href="#L-308"><span class="linenos">308</span></a>        <span class="n">rloss</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-309"><a href="#L-309"><span class="linenos">309</span></a>        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
</span><span id="L-310"><a href="#L-310"><span class="linenos">310</span></a>            <span class="n">rloss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">compute_reg_loss</span><span class="p">())</span>
</span><span id="L-311"><a href="#L-311"><span class="linenos">311</span></a>        <span class="k">return</span> <span class="n">reduce</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">,</span> <span class="n">rloss</span><span class="p">)</span>
</span><span id="L-312"><a href="#L-312"><span class="linenos">312</span></a>
</span><span id="L-313"><a href="#L-313"><span class="linenos">313</span></a>    <span class="k">def</span> <span class="nf">list_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer_target</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="L-314"><a href="#L-314"><span class="linenos">314</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-315"><a href="#L-315"><span class="linenos">315</span></a><span class="sd">        Lists the parameters for the network.</span>
</span><span id="L-316"><a href="#L-316"><span class="linenos">316</span></a>
</span><span id="L-317"><a href="#L-317"><span class="linenos">317</span></a><span class="sd">        Args:</span>
</span><span id="L-318"><a href="#L-318"><span class="linenos">318</span></a><span class="sd">            layer_target (int, optional): The layer to list the parameters for. Defaults to None.</span>
</span><span id="L-319"><a href="#L-319"><span class="linenos">319</span></a>
</span><span id="L-320"><a href="#L-320"><span class="linenos">320</span></a><span class="sd">        Returns:</span>
</span><span id="L-321"><a href="#L-321"><span class="linenos">321</span></a><span class="sd">            None</span>
</span><span id="L-322"><a href="#L-322"><span class="linenos">322</span></a>
</span><span id="L-323"><a href="#L-323"><span class="linenos">323</span></a><span class="sd">        Raises:</span>
</span><span id="L-324"><a href="#L-324"><span class="linenos">324</span></a><span class="sd">            AssertionError: If the layer target is invalid.</span>
</span><span id="L-325"><a href="#L-325"><span class="linenos">325</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-326"><a href="#L-326"><span class="linenos">326</span></a>
</span><span id="L-327"><a href="#L-327"><span class="linenos">327</span></a>        <span class="k">if</span> <span class="n">layer_target</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-328"><a href="#L-328"><span class="linenos">328</span></a>            <span class="n">layer_target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;int32&#39;</span><span class="p">)</span>
</span><span id="L-329"><a href="#L-329"><span class="linenos">329</span></a>        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer_target</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="L-330"><a href="#L-330"><span class="linenos">330</span></a>            <span class="n">layer_target</span> <span class="o">=</span> <span class="p">[</span><span class="n">layer_target</span><span class="p">]</span>
</span><span id="L-331"><a href="#L-331"><span class="linenos">331</span></a>        <span class="k">for</span> <span class="n">nn</span> <span class="ow">in</span> <span class="n">layer_target</span><span class="p">:</span>
</span><span id="L-332"><a href="#L-332"><span class="linenos">332</span></a>            <span class="k">assert</span> <span class="n">nn</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">),</span> <span class="s1">&#39;  Invalid layer </span><span class="si">%d</span><span class="s1">.&#39;</span><span class="o">%</span><span class="n">nn</span>
</span><span id="L-333"><a href="#L-333"><span class="linenos">333</span></a>            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  Layer </span><span class="si">%d</span><span class="s2">:&quot;</span><span class="o">%</span><span class="n">nn</span><span class="p">)</span>
</span><span id="L-334"><a href="#L-334"><span class="linenos">334</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">nn</span><span class="p">]</span><span class="o">.</span><span class="n">list_parameters</span><span class="p">()</span>
</span><span id="L-335"><a href="#L-335"><span class="linenos">335</span></a>
</span><span id="L-336"><a href="#L-336"><span class="linenos">336</span></a>    <span class="k">def</span> <span class="nf">set_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer_target</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">val</span><span class="o">=</span><span class="kc">None</span> <span class="p">):</span>
</span><span id="L-337"><a href="#L-337"><span class="linenos">337</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-338"><a href="#L-338"><span class="linenos">338</span></a><span class="sd">        Sets the parameters for the listed layer or for all layers.</span>
</span><span id="L-339"><a href="#L-339"><span class="linenos">339</span></a>
</span><span id="L-340"><a href="#L-340"><span class="linenos">340</span></a><span class="sd">        Args:</span>
</span><span id="L-341"><a href="#L-341"><span class="linenos">341</span></a><span class="sd">            layer_target (int, optional): The layer to set the parameters for. Defaults to None.</span>
</span><span id="L-342"><a href="#L-342"><span class="linenos">342</span></a><span class="sd">            name (str): The name of the parameter.</span>
</span><span id="L-343"><a href="#L-343"><span class="linenos">343</span></a><span class="sd">            val (bool): The value to set the parameter to.</span>
</span><span id="L-344"><a href="#L-344"><span class="linenos">344</span></a>
</span><span id="L-345"><a href="#L-345"><span class="linenos">345</span></a><span class="sd">        Returns:</span>
</span><span id="L-346"><a href="#L-346"><span class="linenos">346</span></a><span class="sd">            None</span>
</span><span id="L-347"><a href="#L-347"><span class="linenos">347</span></a>
</span><span id="L-348"><a href="#L-348"><span class="linenos">348</span></a><span class="sd">        Raises:</span>
</span><span id="L-349"><a href="#L-349"><span class="linenos">349</span></a><span class="sd">            AssertionError: If the layer target is invalid.</span>
</span><span id="L-350"><a href="#L-350"><span class="linenos">350</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-351"><a href="#L-351"><span class="linenos">351</span></a>        <span class="k">if</span> <span class="n">layer_target</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-352"><a href="#L-352"><span class="linenos">352</span></a>            <span class="n">layer_target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;int32&#39;</span><span class="p">)</span>
</span><span id="L-353"><a href="#L-353"><span class="linenos">353</span></a>        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer_target</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="L-354"><a href="#L-354"><span class="linenos">354</span></a>            <span class="n">layer_target</span> <span class="o">=</span> <span class="p">[</span><span class="n">layer_target</span><span class="p">]</span>
</span><span id="L-355"><a href="#L-355"><span class="linenos">355</span></a>        <span class="k">for</span> <span class="n">nn</span> <span class="ow">in</span> <span class="n">layer_target</span><span class="p">:</span>
</span><span id="L-356"><a href="#L-356"><span class="linenos">356</span></a>            <span class="k">assert</span> <span class="n">nn</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">),</span> <span class="s1">&#39;  Invalid layer </span><span class="si">%d</span><span class="s1">.&#39;</span><span class="o">%</span><span class="n">nn</span>
</span><span id="L-357"><a href="#L-357"><span class="linenos">357</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">nn</span><span class="p">]</span><span class="o">.</span><span class="n">set_parameters</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">val</span><span class="o">=</span><span class="n">val</span><span class="p">)</span>
</span><span id="L-358"><a href="#L-358"><span class="linenos">358</span></a>
</span><span id="L-359"><a href="#L-359"><span class="linenos">359</span></a>    <span class="k">def</span> <span class="nf">set_reg_val</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reg_type</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reg_val</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">layer_target</span><span class="o">=</span><span class="kc">None</span> <span class="p">):</span>
</span><span id="L-360"><a href="#L-360"><span class="linenos">360</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-361"><a href="#L-361"><span class="linenos">361</span></a><span class="sd">        Set reg_values for listed layer or for all layers.</span>
</span><span id="L-362"><a href="#L-362"><span class="linenos">362</span></a><span class="sd">        </span>
</span><span id="L-363"><a href="#L-363"><span class="linenos">363</span></a><span class="sd">        Args:</span>
</span><span id="L-364"><a href="#L-364"><span class="linenos">364</span></a><span class="sd">            reg_type (str): The type of regularization to set.</span>
</span><span id="L-365"><a href="#L-365"><span class="linenos">365</span></a><span class="sd">            reg_val (float): The value to set the regularization to.</span>
</span><span id="L-366"><a href="#L-366"><span class="linenos">366</span></a><span class="sd">            layer_target (int, optional): The layer to set the regularization for. Defaults to None.</span>
</span><span id="L-367"><a href="#L-367"><span class="linenos">367</span></a>
</span><span id="L-368"><a href="#L-368"><span class="linenos">368</span></a><span class="sd">        Returns:</span>
</span><span id="L-369"><a href="#L-369"><span class="linenos">369</span></a><span class="sd">            None</span>
</span><span id="L-370"><a href="#L-370"><span class="linenos">370</span></a>
</span><span id="L-371"><a href="#L-371"><span class="linenos">371</span></a><span class="sd">        Raises:</span>
</span><span id="L-372"><a href="#L-372"><span class="linenos">372</span></a><span class="sd">            AssertionError: If the layer target is invalid.</span>
</span><span id="L-373"><a href="#L-373"><span class="linenos">373</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-374"><a href="#L-374"><span class="linenos">374</span></a>        <span class="k">if</span> <span class="n">layer_target</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-375"><a href="#L-375"><span class="linenos">375</span></a>            <span class="n">layer_target</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="L-376"><a href="#L-376"><span class="linenos">376</span></a>        <span class="k">assert</span> <span class="n">layer_target</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">),</span> <span class="s2">&quot;layer target too large (max = </span><span class="si">%d</span><span class="s2">)&quot;</span><span class="o">%</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span>
</span><span id="L-377"><a href="#L-377"><span class="linenos">377</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">layer_target</span><span class="p">]</span><span class="o">.</span><span class="n">set_reg_val</span><span class="p">(</span> <span class="n">reg_type</span><span class="o">=</span><span class="n">reg_type</span><span class="p">,</span> <span class="n">reg_val</span><span class="o">=</span><span class="n">reg_val</span> <span class="p">)</span>
</span><span id="L-378"><a href="#L-378"><span class="linenos">378</span></a>
</span><span id="L-379"><a href="#L-379"><span class="linenos">379</span></a>    <span class="k">def</span> <span class="nf">plot_filters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer_target</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="L-380"><a href="#L-380"><span class="linenos">380</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-381"><a href="#L-381"><span class="linenos">381</span></a><span class="sd">        Plots the filters for the listed layer.</span>
</span><span id="L-382"><a href="#L-382"><span class="linenos">382</span></a>
</span><span id="L-383"><a href="#L-383"><span class="linenos">383</span></a><span class="sd">        Args:</span>
</span><span id="L-384"><a href="#L-384"><span class="linenos">384</span></a><span class="sd">            layer_target (int, optional): The layer to plot the filters for. Defaults to 0.</span>
</span><span id="L-385"><a href="#L-385"><span class="linenos">385</span></a><span class="sd">            **kwargs: Additional keyword arguments.</span>
</span><span id="L-386"><a href="#L-386"><span class="linenos">386</span></a>
</span><span id="L-387"><a href="#L-387"><span class="linenos">387</span></a><span class="sd">        Returns:</span>
</span><span id="L-388"><a href="#L-388"><span class="linenos">388</span></a><span class="sd">            None</span>
</span><span id="L-389"><a href="#L-389"><span class="linenos">389</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-390"><a href="#L-390"><span class="linenos">390</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">layer_target</span><span class="p">]</span><span class="o">.</span><span class="n">plot_filters</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="L-391"><a href="#L-391"><span class="linenos">391</span></a>
</span><span id="L-392"><a href="#L-392"><span class="linenos">392</span></a>    <span class="k">def</span> <span class="nf">get_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer_target</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="L-393"><a href="#L-393"><span class="linenos">393</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-394"><a href="#L-394"><span class="linenos">394</span></a><span class="sd">        Passed down to layer call, with optional arguments conveyed.</span>
</span><span id="L-395"><a href="#L-395"><span class="linenos">395</span></a><span class="sd">        </span>
</span><span id="L-396"><a href="#L-396"><span class="linenos">396</span></a><span class="sd">        Args:</span>
</span><span id="L-397"><a href="#L-397"><span class="linenos">397</span></a><span class="sd">            layer_target (int): The layer to get the weights for.</span>
</span><span id="L-398"><a href="#L-398"><span class="linenos">398</span></a><span class="sd">            **kwargs: Additional keyword arguments.</span>
</span><span id="L-399"><a href="#L-399"><span class="linenos">399</span></a>
</span><span id="L-400"><a href="#L-400"><span class="linenos">400</span></a><span class="sd">        Returns:</span>
</span><span id="L-401"><a href="#L-401"><span class="linenos">401</span></a><span class="sd">            The weights for the specified layer.</span>
</span><span id="L-402"><a href="#L-402"><span class="linenos">402</span></a>
</span><span id="L-403"><a href="#L-403"><span class="linenos">403</span></a><span class="sd">        Raises:</span>
</span><span id="L-404"><a href="#L-404"><span class="linenos">404</span></a><span class="sd">            AssertionError: If the layer target is invalid.</span>
</span><span id="L-405"><a href="#L-405"><span class="linenos">405</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-406"><a href="#L-406"><span class="linenos">406</span></a>        <span class="k">assert</span> <span class="n">layer_target</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">),</span> <span class="s2">&quot;Invalid layer_target </span><span class="si">%d</span><span class="s2">&quot;</span><span class="o">%</span><span class="n">layer_target</span>
</span><span id="L-407"><a href="#L-407"><span class="linenos">407</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">layer_target</span><span class="p">]</span><span class="o">.</span><span class="n">get_weights</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="L-408"><a href="#L-408"><span class="linenos">408</span></a>
</span><span id="L-409"><a href="#L-409"><span class="linenos">409</span></a>    <span class="nd">@classmethod</span>
</span><span id="L-410"><a href="#L-410"><span class="linenos">410</span></a>    <span class="k">def</span> <span class="nf">ffnet_dict</span><span class="p">(</span> <span class="bp">cls</span><span class="p">,</span> <span class="n">layer_list</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">xstim_n</span> <span class="o">=</span><span class="s1">&#39;stim&#39;</span><span class="p">,</span> <span class="n">ffnet_n</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ffnet_type</span><span class="o">=</span><span class="s1">&#39;normal&#39;</span><span class="p">,</span> <span class="n">scaffold_levels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_lags_out</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="L-411"><a href="#L-411"><span class="linenos">411</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-412"><a href="#L-412"><span class="linenos">412</span></a><span class="sd">        Returns a dictionary of the feedforward network.</span>
</span><span id="L-413"><a href="#L-413"><span class="linenos">413</span></a>
</span><span id="L-414"><a href="#L-414"><span class="linenos">414</span></a><span class="sd">        Args:</span>
</span><span id="L-415"><a href="#L-415"><span class="linenos">415</span></a><span class="sd">            layer_list (list): A list of dictionaries representing the layers of the network.</span>
</span><span id="L-416"><a href="#L-416"><span class="linenos">416</span></a><span class="sd">            xstim_n (str): The name of the stimulus input.</span>
</span><span id="L-417"><a href="#L-417"><span class="linenos">417</span></a><span class="sd">            ffnet_n (list): A list of feedforward networks.</span>
</span><span id="L-418"><a href="#L-418"><span class="linenos">418</span></a><span class="sd">            ffnet_type (str): The type of the feedforward network.</span>
</span><span id="L-419"><a href="#L-419"><span class="linenos">419</span></a><span class="sd">            scaffold_levels (list): A list of scaffold levels.</span>
</span><span id="L-420"><a href="#L-420"><span class="linenos">420</span></a><span class="sd">            num_lags_out (int): The number of lags out.</span>
</span><span id="L-421"><a href="#L-421"><span class="linenos">421</span></a><span class="sd">            **kwargs: Additional keyword arguments.</span>
</span><span id="L-422"><a href="#L-422"><span class="linenos">422</span></a>
</span><span id="L-423"><a href="#L-423"><span class="linenos">423</span></a><span class="sd">        Returns:</span>
</span><span id="L-424"><a href="#L-424"><span class="linenos">424</span></a><span class="sd">            ffnet_dict (dict): The dictionary of the feedforward network.</span>
</span><span id="L-425"><a href="#L-425"><span class="linenos">425</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-426"><a href="#L-426"><span class="linenos">426</span></a>        <span class="k">return</span> <span class="p">{</span>
</span><span id="L-427"><a href="#L-427"><span class="linenos">427</span></a>            <span class="s1">&#39;ffnet_type&#39;</span><span class="p">:</span> <span class="n">ffnet_type</span><span class="p">,</span>
</span><span id="L-428"><a href="#L-428"><span class="linenos">428</span></a>            <span class="s1">&#39;xstim_n&#39;</span><span class="p">:</span><span class="n">xstim_n</span><span class="p">,</span> <span class="s1">&#39;ffnet_n&#39;</span><span class="p">:</span><span class="n">ffnet_n</span><span class="p">,</span>
</span><span id="L-429"><a href="#L-429"><span class="linenos">429</span></a>            <span class="s1">&#39;layer_list&#39;</span><span class="p">:</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">layer_list</span><span class="p">),</span>
</span><span id="L-430"><a href="#L-430"><span class="linenos">430</span></a>            <span class="s1">&#39;scaffold_levels&#39;</span><span class="p">:</span> <span class="n">scaffold_levels</span><span class="p">,</span>
</span><span id="L-431"><a href="#L-431"><span class="linenos">431</span></a>            <span class="s1">&#39;num_lags_out&#39;</span><span class="p">:</span> <span class="n">num_lags_out</span><span class="p">}</span>
</span><span id="L-432"><a href="#L-432"><span class="linenos">432</span></a>    <span class="c1"># END FFnetwork class</span>
</span><span id="L-433"><a href="#L-433"><span class="linenos">433</span></a>
</span><span id="L-434"><a href="#L-434"><span class="linenos">434</span></a>
</span><span id="L-435"><a href="#L-435"><span class="linenos">435</span></a><span class="k">class</span> <span class="nc">ScaffoldNetwork</span><span class="p">(</span><span class="n">FFnetwork</span><span class="p">):</span>
</span><span id="L-436"><a href="#L-436"><span class="linenos">436</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-437"><a href="#L-437"><span class="linenos">437</span></a><span class="sd">    Concatenates output of all layers together in filter dimension, preserving spatial dims.</span>
</span><span id="L-438"><a href="#L-438"><span class="linenos">438</span></a>
</span><span id="L-439"><a href="#L-439"><span class="linenos">439</span></a><span class="sd">    This essentially used the constructor for Point1DGaussian, with dicationary input.</span>
</span><span id="L-440"><a href="#L-440"><span class="linenos">440</span></a><span class="sd">    Currently there is no extra code required at the network level. I think the constructor</span>
</span><span id="L-441"><a href="#L-441"><span class="linenos">441</span></a><span class="sd">    can be left off entirely, but leaving in in case want to add something.</span>
</span><span id="L-442"><a href="#L-442"><span class="linenos">442</span></a>
</span><span id="L-443"><a href="#L-443"><span class="linenos">443</span></a><span class="sd">    Args:</span>
</span><span id="L-444"><a href="#L-444"><span class="linenos">444</span></a><span class="sd">        scaffold_levels (list): A list of scaffold levels.</span>
</span><span id="L-445"><a href="#L-445"><span class="linenos">445</span></a><span class="sd">        num_lags_out (int): The number of lags out.</span>
</span><span id="L-446"><a href="#L-446"><span class="linenos">446</span></a>
</span><span id="L-447"><a href="#L-447"><span class="linenos">447</span></a><span class="sd">    Raises:</span>
</span><span id="L-448"><a href="#L-448"><span class="linenos">448</span></a><span class="sd">        AssertionError: If the scaffold levels are invalid.</span>
</span><span id="L-449"><a href="#L-449"><span class="linenos">449</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-450"><a href="#L-450"><span class="linenos">450</span></a>
</span><span id="L-451"><a href="#L-451"><span class="linenos">451</span></a>    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-452"><a href="#L-452"><span class="linenos">452</span></a>        <span class="n">s</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__repr__</span><span class="p">()</span>
</span><span id="L-453"><a href="#L-453"><span class="linenos">453</span></a>        <span class="c1"># Add information about module to print out</span>
</span><span id="L-454"><a href="#L-454"><span class="linenos">454</span></a>        <span class="n">s</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
</span><span id="L-455"><a href="#L-455"><span class="linenos">455</span></a>        <span class="k">return</span> <span class="n">s</span>
</span><span id="L-456"><a href="#L-456"><span class="linenos">456</span></a>
</span><span id="L-457"><a href="#L-457"><span class="linenos">457</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scaffold_levels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_lags_out</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="L-458"><a href="#L-458"><span class="linenos">458</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="L-459"><a href="#L-459"><span class="linenos">459</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">network_type</span> <span class="o">=</span> <span class="s1">&#39;scaffold&#39;</span>
</span><span id="L-460"><a href="#L-460"><span class="linenos">460</span></a>
</span><span id="L-461"><a href="#L-461"><span class="linenos">461</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_lags_out</span> <span class="o">=</span> <span class="n">num_lags_out</span>
</span><span id="L-462"><a href="#L-462"><span class="linenos">462</span></a>
</span><span id="L-463"><a href="#L-463"><span class="linenos">463</span></a>        <span class="n">num_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span>
</span><span id="L-464"><a href="#L-464"><span class="linenos">464</span></a>        <span class="k">if</span> <span class="n">scaffold_levels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-465"><a href="#L-465"><span class="linenos">465</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)</span>
</span><span id="L-466"><a href="#L-466"><span class="linenos">466</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-467"><a href="#L-467"><span class="linenos">467</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scaffold_levels</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="L-468"><a href="#L-468"><span class="linenos">468</span></a>                <span class="n">scaffold_levels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">scaffold_levels</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
</span><span id="L-469"><a href="#L-469"><span class="linenos">469</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span> <span class="o">=</span> <span class="n">scaffold_levels</span> 
</span><span id="L-470"><a href="#L-470"><span class="linenos">470</span></a>        <span class="c1"># Determine output dimensions</span>
</span><span id="L-471"><a href="#L-471"><span class="linenos">471</span></a>        <span class="c1">#assert self.layers[self.scaffold_levels[0]].output_dims[3] == 1, &quot;Scaffold: cannot currently handle lag dimensions&quot;</span>
</span><span id="L-472"><a href="#L-472"><span class="linenos">472</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">spatial_dims</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">output_dims</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span>
</span><span id="L-473"><a href="#L-473"><span class="linenos">473</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">filter_count</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">))</span>
</span><span id="L-474"><a href="#L-474"><span class="linenos">474</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">filter_count</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">output_dims</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-475"><a href="#L-475"><span class="linenos">475</span></a>
</span><span id="L-476"><a href="#L-476"><span class="linenos">476</span></a>        <span class="c1">#Tchomps = np.zeros(self.scaffold_levels)</span>
</span><span id="L-477"><a href="#L-477"><span class="linenos">477</span></a>        <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">)):</span>
</span><span id="L-478"><a href="#L-478"><span class="linenos">478</span></a>            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">[</span><span class="n">ii</span><span class="p">]]</span><span class="o">.</span><span class="n">output_dims</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">spatial_dims</span><span class="p">,</span> <span class="s2">&quot;Spatial dims problem layer </span><span class="si">%d</span><span class="s2">&quot;</span><span class="o">%</span><span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span> 
</span><span id="L-479"><a href="#L-479"><span class="linenos">479</span></a>            <span class="c1">#assert self.layers[self.scaffold_levels[ii]].output_dims[3] == 1, &quot;Scaffold: cannot currently handle lag dimensions&quot;</span>
</span><span id="L-480"><a href="#L-480"><span class="linenos">480</span></a>            <span class="c1">#if self.layers[self.scaffold_levels[ii]].output_dims[3] &gt; 1:</span>
</span><span id="L-481"><a href="#L-481"><span class="linenos">481</span></a>            <span class="c1">#    Tchomps[ii] = self.layers[self.scaffold_levels[ii]].output_dims[3]-1</span>
</span><span id="L-482"><a href="#L-482"><span class="linenos">482</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">filter_count</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">[</span><span class="n">ii</span><span class="p">]]</span><span class="o">.</span><span class="n">output_dims</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-483"><a href="#L-483"><span class="linenos">483</span></a>
</span><span id="L-484"><a href="#L-484"><span class="linenos">484</span></a>        <span class="c1"># Construct output dimensions</span>
</span><span id="L-485"><a href="#L-485"><span class="linenos">485</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_lags_out</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-486"><a href="#L-486"><span class="linenos">486</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">output_dims</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filter_count</span><span class="p">))]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">spatial_dims</span> <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">num_lags_out</span><span class="p">]</span>
</span><span id="L-487"><a href="#L-487"><span class="linenos">487</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-488"><a href="#L-488"><span class="linenos">488</span></a>            <span class="n">scaffold_lags</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">[</span><span class="n">ii</span><span class="p">]]</span><span class="o">.</span><span class="n">output_dims</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">))]</span>
</span><span id="L-489"><a href="#L-489"><span class="linenos">489</span></a>            <span class="c1"># assert that all scaffold_lags are the same</span>
</span><span id="L-490"><a href="#L-490"><span class="linenos">490</span></a>            <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">scaffold_lags</span><span class="p">)</span> <span class="o">==</span> <span class="n">scaffold_lags</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="s2">&quot;Scaffold: cannot currently handle different lag dimensions&quot;</span>
</span><span id="L-491"><a href="#L-491"><span class="linenos">491</span></a>            <span class="n">filter_x_lag</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filter_count</span><span class="p">))</span> <span class="o">*</span> <span class="n">scaffold_lags</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-492"><a href="#L-492"><span class="linenos">492</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">output_dims</span> <span class="o">=</span> <span class="p">[</span><span class="n">filter_x_lag</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">spatial_dims</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="L-493"><a href="#L-493"><span class="linenos">493</span></a>    <span class="c1"># END ScaffoldNetwork.__init__</span>
</span><span id="L-494"><a href="#L-494"><span class="linenos">494</span></a>
</span><span id="L-495"><a href="#L-495"><span class="linenos">495</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="L-496"><a href="#L-496"><span class="linenos">496</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-497"><a href="#L-497"><span class="linenos">497</span></a><span class="sd">        Forward pass through the network.</span>
</span><span id="L-498"><a href="#L-498"><span class="linenos">498</span></a>
</span><span id="L-499"><a href="#L-499"><span class="linenos">499</span></a><span class="sd">        Args:</span>
</span><span id="L-500"><a href="#L-500"><span class="linenos">500</span></a><span class="sd">            inputs (list, torch.Tensor): The input to the network.</span>
</span><span id="L-501"><a href="#L-501"><span class="linenos">501</span></a>
</span><span id="L-502"><a href="#L-502"><span class="linenos">502</span></a><span class="sd">        Returns:</span>
</span><span id="L-503"><a href="#L-503"><span class="linenos">503</span></a><span class="sd">            x (torch.Tensor): The output of the network.</span>
</span><span id="L-504"><a href="#L-504"><span class="linenos">504</span></a>
</span><span id="L-505"><a href="#L-505"><span class="linenos">505</span></a><span class="sd">        Raises:</span>
</span><span id="L-506"><a href="#L-506"><span class="linenos">506</span></a><span class="sd">            ValueError: If no layers are defined.</span>
</span><span id="L-507"><a href="#L-507"><span class="linenos">507</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-508"><a href="#L-508"><span class="linenos">508</span></a>
</span><span id="L-509"><a href="#L-509"><span class="linenos">509</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-510"><a href="#L-510"><span class="linenos">510</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Scaffold: no layers defined.&quot;</span><span class="p">)</span>
</span><span id="L-511"><a href="#L-511"><span class="linenos">511</span></a>        
</span><span id="L-512"><a href="#L-512"><span class="linenos">512</span></a>        <span class="n">out</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># returned </span>
</span><span id="L-513"><a href="#L-513"><span class="linenos">513</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess_input</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="L-514"><a href="#L-514"><span class="linenos">514</span></a>
</span><span id="L-515"><a href="#L-515"><span class="linenos">515</span></a>        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
</span><span id="L-516"><a href="#L-516"><span class="linenos">516</span></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="L-517"><a href="#L-517"><span class="linenos">517</span></a>            <span class="n">nt</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-518"><a href="#L-518"><span class="linenos">518</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_lags_out</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">layer</span><span class="o">.</span><span class="n">output_dims</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="L-519"><a href="#L-519"><span class="linenos">519</span></a>                <span class="c1"># reshape y to combine the filters and lags in the second dimension</span>
</span><span id="L-520"><a href="#L-520"><span class="linenos">520</span></a>                <span class="c1"># batch x filters x (width x height) x lags</span>
</span><span id="L-521"><a href="#L-521"><span class="linenos">521</span></a>                <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="n">nt</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">output_dims</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">output_dims</span><span class="p">[</span><span class="mi">3</span><span class="p">]])</span>
</span><span id="L-522"><a href="#L-522"><span class="linenos">522</span></a>                <span class="c1"># move the lag dimension after the filters (batch, filter, lag, width x height)</span>
</span><span id="L-523"><a href="#L-523"><span class="linenos">523</span></a>                <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span><span id="L-524"><a href="#L-524"><span class="linenos">524</span></a>                <span class="c1"># flatten the filter and lag dimensions to be filters x lags</span>
</span><span id="L-525"><a href="#L-525"><span class="linenos">525</span></a>                <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="n">nt</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span><span id="L-526"><a href="#L-526"><span class="linenos">526</span></a>                <span class="n">out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span><span id="L-527"><a href="#L-527"><span class="linenos">527</span></a>            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_lags_out</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">layer</span><span class="o">.</span><span class="n">output_dims</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_lags_out</span><span class="p">:</span>
</span><span id="L-528"><a href="#L-528"><span class="linenos">528</span></a>                <span class="c1"># Need to return just first lag (lag0) -- &#39;chomp&#39;</span>
</span><span id="L-529"><a href="#L-529"><span class="linenos">529</span></a>                <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="n">nt</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">output_dims</span><span class="p">[</span><span class="mi">3</span><span class="p">]])[</span><span class="o">...</span><span class="p">,</span> <span class="p">:(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_lags_out</span><span class="p">)]</span>
</span><span id="L-530"><a href="#L-530"><span class="linenos">530</span></a>                <span class="n">out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">nt</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="p">))</span>
</span><span id="L-531"><a href="#L-531"><span class="linenos">531</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-532"><a href="#L-532"><span class="linenos">532</span></a>                <span class="n">out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="L-533"><a href="#L-533"><span class="linenos">533</span></a>        
</span><span id="L-534"><a href="#L-534"><span class="linenos">534</span></a>        <span class="c1"># this concatentates across the filter dimension</span>
</span><span id="L-535"><a href="#L-535"><span class="linenos">535</span></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">out</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="L-536"><a href="#L-536"><span class="linenos">536</span></a>    <span class="c1"># END ScaffoldNetwork.forward()</span>
</span><span id="L-537"><a href="#L-537"><span class="linenos">537</span></a>
</span><span id="L-538"><a href="#L-538"><span class="linenos">538</span></a>    <span class="nd">@classmethod</span>
</span><span id="L-539"><a href="#L-539"><span class="linenos">539</span></a>    <span class="k">def</span> <span class="nf">ffnet_dict</span><span class="p">(</span> <span class="bp">cls</span><span class="p">,</span> <span class="n">scaffold_levels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_lags_out</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="L-540"><a href="#L-540"><span class="linenos">540</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-541"><a href="#L-541"><span class="linenos">541</span></a><span class="sd">        Returns a dictionary of the scaffold network.</span>
</span><span id="L-542"><a href="#L-542"><span class="linenos">542</span></a>
</span><span id="L-543"><a href="#L-543"><span class="linenos">543</span></a><span class="sd">        Args:</span>
</span><span id="L-544"><a href="#L-544"><span class="linenos">544</span></a><span class="sd">            scaffold_levels (list): A list of scaffold levels.</span>
</span><span id="L-545"><a href="#L-545"><span class="linenos">545</span></a><span class="sd">            num_lags_out (int): The number of lags out.</span>
</span><span id="L-546"><a href="#L-546"><span class="linenos">546</span></a><span class="sd">            **kwargs: Additional keyword arguments.</span>
</span><span id="L-547"><a href="#L-547"><span class="linenos">547</span></a>
</span><span id="L-548"><a href="#L-548"><span class="linenos">548</span></a><span class="sd">        Returns:</span>
</span><span id="L-549"><a href="#L-549"><span class="linenos">549</span></a><span class="sd">            ffnet_dict (dict): The dictionary of the scaffold network.</span>
</span><span id="L-550"><a href="#L-550"><span class="linenos">550</span></a>
</span><span id="L-551"><a href="#L-551"><span class="linenos">551</span></a><span class="sd">        Raises:</span>
</span><span id="L-552"><a href="#L-552"><span class="linenos">552</span></a><span class="sd">            AssertionError: If the scaffold levels are invalid.</span>
</span><span id="L-553"><a href="#L-553"><span class="linenos">553</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-554"><a href="#L-554"><span class="linenos">554</span></a>        <span class="n">ffnet_dict</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">ffnet_dict</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="L-555"><a href="#L-555"><span class="linenos">555</span></a>        <span class="n">ffnet_dict</span><span class="p">[</span><span class="s1">&#39;ffnet_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;scaffold&#39;</span>
</span><span id="L-556"><a href="#L-556"><span class="linenos">556</span></a>        <span class="n">ffnet_dict</span><span class="p">[</span><span class="s1">&#39;scaffold_levels&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaffold_levels</span>
</span><span id="L-557"><a href="#L-557"><span class="linenos">557</span></a>        <span class="n">ffnet_dict</span><span class="p">[</span><span class="s1">&#39;num_lags_out&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_lags_out</span>
</span><span id="L-558"><a href="#L-558"><span class="linenos">558</span></a>        <span class="k">return</span> <span class="n">ffnet_dict</span>
</span><span id="L-559"><a href="#L-559"><span class="linenos">559</span></a><span class="c1"># END ScaffoldNetwork</span>
</span><span id="L-560"><a href="#L-560"><span class="linenos">560</span></a>
</span><span id="L-561"><a href="#L-561"><span class="linenos">561</span></a>
</span><span id="L-562"><a href="#L-562"><span class="linenos">562</span></a><span class="k">class</span> <span class="nc">ScaffoldNetwork3d</span><span class="p">(</span><span class="n">ScaffoldNetwork</span><span class="p">):</span>
</span><span id="L-563"><a href="#L-563"><span class="linenos">563</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-564"><a href="#L-564"><span class="linenos">564</span></a><span class="sd">    Like scaffold network above, but preserves the third dimension.</span>
</span><span id="L-565"><a href="#L-565"><span class="linenos">565</span></a>
</span><span id="L-566"><a href="#L-566"><span class="linenos">566</span></a><span class="sd">    This essentially used the constructor for Point1DGaussian, with dicationary input.</span>
</span><span id="L-567"><a href="#L-567"><span class="linenos">567</span></a><span class="sd">    Currently there is no extra code required at the network level. I think the constructor</span>
</span><span id="L-568"><a href="#L-568"><span class="linenos">568</span></a><span class="sd">    can be left off entirely, but leaving in in case want to add something.</span>
</span><span id="L-569"><a href="#L-569"><span class="linenos">569</span></a>
</span><span id="L-570"><a href="#L-570"><span class="linenos">570</span></a><span class="sd">    Args:</span>
</span><span id="L-571"><a href="#L-571"><span class="linenos">571</span></a><span class="sd">        num_lags_out (int): The number of lags out.</span>
</span><span id="L-572"><a href="#L-572"><span class="linenos">572</span></a>
</span><span id="L-573"><a href="#L-573"><span class="linenos">573</span></a><span class="sd">    Raises:</span>
</span><span id="L-574"><a href="#L-574"><span class="linenos">574</span></a><span class="sd">        AssertionError: If the scaffold levels are invalid.</span>
</span><span id="L-575"><a href="#L-575"><span class="linenos">575</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-576"><a href="#L-576"><span class="linenos">576</span></a>
</span><span id="L-577"><a href="#L-577"><span class="linenos">577</span></a>    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-578"><a href="#L-578"><span class="linenos">578</span></a>        <span class="n">s</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__repr__</span><span class="p">()</span>
</span><span id="L-579"><a href="#L-579"><span class="linenos">579</span></a>        <span class="c1"># Add information about module to print out</span>
</span><span id="L-580"><a href="#L-580"><span class="linenos">580</span></a>        <span class="n">s</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
</span><span id="L-581"><a href="#L-581"><span class="linenos">581</span></a>        <span class="k">return</span> <span class="n">s</span>
</span><span id="L-582"><a href="#L-582"><span class="linenos">582</span></a>
</span><span id="L-583"><a href="#L-583"><span class="linenos">583</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_lags_out</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="L-584"><a href="#L-584"><span class="linenos">584</span></a>        <span class="k">assert</span> <span class="n">num_lags_out</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;should be using num_lags_out with the scaffold3d network&quot;</span>
</span><span id="L-585"><a href="#L-585"><span class="linenos">585</span></a>
</span><span id="L-586"><a href="#L-586"><span class="linenos">586</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="L-587"><a href="#L-587"><span class="linenos">587</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">network_type</span> <span class="o">=</span> <span class="s1">&#39;scaffold3d&#39;</span>
</span><span id="L-588"><a href="#L-588"><span class="linenos">588</span></a>
</span><span id="L-589"><a href="#L-589"><span class="linenos">589</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_lags_out</span> <span class="o">=</span> <span class="n">num_lags_out</span>  <span class="c1"># Makes output equal to number of lags</span>
</span><span id="L-590"><a href="#L-590"><span class="linenos">590</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">output_dims</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_lags_out</span>
</span><span id="L-591"><a href="#L-591"><span class="linenos">591</span></a>    <span class="c1"># END ScaffoldNetwork3d.__init__</span>
</span><span id="L-592"><a href="#L-592"><span class="linenos">592</span></a>
</span><span id="L-593"><a href="#L-593"><span class="linenos">593</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="L-594"><a href="#L-594"><span class="linenos">594</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-595"><a href="#L-595"><span class="linenos">595</span></a><span class="sd">        Forward pass through the network.</span>
</span><span id="L-596"><a href="#L-596"><span class="linenos">596</span></a>
</span><span id="L-597"><a href="#L-597"><span class="linenos">597</span></a><span class="sd">        Args:</span>
</span><span id="L-598"><a href="#L-598"><span class="linenos">598</span></a><span class="sd">            inputs (list, torch.Tensor): The input to the network.</span>
</span><span id="L-599"><a href="#L-599"><span class="linenos">599</span></a>
</span><span id="L-600"><a href="#L-600"><span class="linenos">600</span></a><span class="sd">        Returns:</span>
</span><span id="L-601"><a href="#L-601"><span class="linenos">601</span></a><span class="sd">            x (torch.Tensor): The output of the network.</span>
</span><span id="L-602"><a href="#L-602"><span class="linenos">602</span></a><span class="sd">        </span>
</span><span id="L-603"><a href="#L-603"><span class="linenos">603</span></a><span class="sd">        Raises:</span>
</span><span id="L-604"><a href="#L-604"><span class="linenos">604</span></a><span class="sd">            ValueError: If no layers are defined.</span>
</span><span id="L-605"><a href="#L-605"><span class="linenos">605</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-606"><a href="#L-606"><span class="linenos">606</span></a>
</span><span id="L-607"><a href="#L-607"><span class="linenos">607</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-608"><a href="#L-608"><span class="linenos">608</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Scaffold: no layers defined.&quot;</span><span class="p">)</span>
</span><span id="L-609"><a href="#L-609"><span class="linenos">609</span></a>        
</span><span id="L-610"><a href="#L-610"><span class="linenos">610</span></a>        <span class="n">out</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># returned </span>
</span><span id="L-611"><a href="#L-611"><span class="linenos">611</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess_input</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="L-612"><a href="#L-612"><span class="linenos">612</span></a>
</span><span id="L-613"><a href="#L-613"><span class="linenos">613</span></a>        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
</span><span id="L-614"><a href="#L-614"><span class="linenos">614</span></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="L-615"><a href="#L-615"><span class="linenos">615</span></a>            <span class="n">nt</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-616"><a href="#L-616"><span class="linenos">616</span></a>            <span class="c1">#if self.num_lags_out is None and layer.output_dims[3] &gt; 1:</span>
</span><span id="L-617"><a href="#L-617"><span class="linenos">617</span></a>                <span class="c1"># reshape y to combine the filters and lags in the second dimension</span>
</span><span id="L-618"><a href="#L-618"><span class="linenos">618</span></a>                <span class="c1"># batch x filters x (width x height) x lags</span>
</span><span id="L-619"><a href="#L-619"><span class="linenos">619</span></a>            <span class="c1">#    y = x.reshape([nt, layer.output_dims[0], -1, layer.output_dims[3]])</span>
</span><span id="L-620"><a href="#L-620"><span class="linenos">620</span></a>                <span class="c1"># move the lag dimension after the filters (batch, filter, lag, width x height)</span>
</span><span id="L-621"><a href="#L-621"><span class="linenos">621</span></a>            <span class="c1">#    y = y.permute(0, 1, 3, 2)</span>
</span><span id="L-622"><a href="#L-622"><span class="linenos">622</span></a>                <span class="c1"># flatten the filter and lag dimensions to be filters x lags</span>
</span><span id="L-623"><a href="#L-623"><span class="linenos">623</span></a>            <span class="c1">#    y = y.reshape([nt, -1])</span>
</span><span id="L-624"><a href="#L-624"><span class="linenos">624</span></a>            <span class="c1">#    out.append(y)</span>
</span><span id="L-625"><a href="#L-625"><span class="linenos">625</span></a>            <span class="c1">#elif self.num_lags_out is not None and layer.output_dims[3] &gt; self.num_lags_out:</span>
</span><span id="L-626"><a href="#L-626"><span class="linenos">626</span></a>                <span class="c1"># Need to return just first lag (lag0) -- &#39;chomp&#39;</span>
</span><span id="L-627"><a href="#L-627"><span class="linenos">627</span></a>            <span class="c1">#    y = x.reshape([nt, -1, layer.output_dims[3]])[..., :(self.num_lags_out)]</span>
</span><span id="L-628"><a href="#L-628"><span class="linenos">628</span></a>            <span class="c1">#    out.append( y.reshape((nt, -1) ))</span>
</span><span id="L-629"><a href="#L-629"><span class="linenos">629</span></a>            <span class="c1">#else:</span>
</span><span id="L-630"><a href="#L-630"><span class="linenos">630</span></a>            <span class="n">out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="L-631"><a href="#L-631"><span class="linenos">631</span></a>        
</span><span id="L-632"><a href="#L-632"><span class="linenos">632</span></a>        <span class="c1"># this concatentates across the filter dimension</span>
</span><span id="L-633"><a href="#L-633"><span class="linenos">633</span></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">out</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="L-634"><a href="#L-634"><span class="linenos">634</span></a>    <span class="c1"># END ScaffoldNetwork3d.forward()</span>
</span><span id="L-635"><a href="#L-635"><span class="linenos">635</span></a>
</span><span id="L-636"><a href="#L-636"><span class="linenos">636</span></a>    <span class="nd">@classmethod</span>
</span><span id="L-637"><a href="#L-637"><span class="linenos">637</span></a>    <span class="k">def</span> <span class="nf">ffnet_dict</span><span class="p">(</span> <span class="bp">cls</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="L-638"><a href="#L-638"><span class="linenos">638</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-639"><a href="#L-639"><span class="linenos">639</span></a><span class="sd">        Returns a dictionary of the scaffold network.</span>
</span><span id="L-640"><a href="#L-640"><span class="linenos">640</span></a>
</span><span id="L-641"><a href="#L-641"><span class="linenos">641</span></a><span class="sd">        Args:</span>
</span><span id="L-642"><a href="#L-642"><span class="linenos">642</span></a><span class="sd">            **kwargs: Additional keyword arguments.</span>
</span><span id="L-643"><a href="#L-643"><span class="linenos">643</span></a>
</span><span id="L-644"><a href="#L-644"><span class="linenos">644</span></a><span class="sd">        Returns:</span>
</span><span id="L-645"><a href="#L-645"><span class="linenos">645</span></a><span class="sd">            ffnet_dict (dict): The dictionary of the scaffold network.</span>
</span><span id="L-646"><a href="#L-646"><span class="linenos">646</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-647"><a href="#L-647"><span class="linenos">647</span></a>        <span class="n">ffnet_dict</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">ffnet_dict</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="L-648"><a href="#L-648"><span class="linenos">648</span></a>        <span class="n">ffnet_dict</span><span class="p">[</span><span class="s1">&#39;ffnet_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;scaffold3d&#39;</span>
</span><span id="L-649"><a href="#L-649"><span class="linenos">649</span></a>        <span class="k">return</span> <span class="n">ffnet_dict</span>
</span><span id="L-650"><a href="#L-650"><span class="linenos">650</span></a><span class="c1"># END ScaffoldNetwork3d</span>
</span><span id="L-651"><a href="#L-651"><span class="linenos">651</span></a>
</span><span id="L-652"><a href="#L-652"><span class="linenos">652</span></a>
</span><span id="L-653"><a href="#L-653"><span class="linenos">653</span></a><span class="k">class</span> <span class="nc">ReadoutNetwork</span><span class="p">(</span><span class="n">FFnetwork</span><span class="p">):</span>
</span><span id="L-654"><a href="#L-654"><span class="linenos">654</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-655"><a href="#L-655"><span class="linenos">655</span></a><span class="sd">    A readout using a spatial transformer layer whose positions are sampled from one Gaussian per neuron. Mean</span>
</span><span id="L-656"><a href="#L-656"><span class="linenos">656</span></a><span class="sd">    and covariance of that Gaussian are learned.</span>
</span><span id="L-657"><a href="#L-657"><span class="linenos">657</span></a><span class="sd">    </span>
</span><span id="L-658"><a href="#L-658"><span class="linenos">658</span></a><span class="sd">    This essentially used the constructor for Point1DGaussian, with dicationary input.</span>
</span><span id="L-659"><a href="#L-659"><span class="linenos">659</span></a><span class="sd">    Currently there is no extra code required at the network level. I think the constructor</span>
</span><span id="L-660"><a href="#L-660"><span class="linenos">660</span></a><span class="sd">    can be left off entirely, but leaving in in case want to add something.</span>
</span><span id="L-661"><a href="#L-661"><span class="linenos">661</span></a>
</span><span id="L-662"><a href="#L-662"><span class="linenos">662</span></a><span class="sd">    Args:</span>
</span><span id="L-663"><a href="#L-663"><span class="linenos">663</span></a><span class="sd">        in_shape (list, tuple): shape of the input feature map [channels, width, height]</span>
</span><span id="L-664"><a href="#L-664"><span class="linenos">664</span></a><span class="sd">        outdims (int): number of output units</span>
</span><span id="L-665"><a href="#L-665"><span class="linenos">665</span></a><span class="sd">        bias (bool): adds a bias term</span>
</span><span id="L-666"><a href="#L-666"><span class="linenos">666</span></a><span class="sd">        init_mu_range (float): initialises the the mean with Uniform([-init_range, init_range])</span>
</span><span id="L-667"><a href="#L-667"><span class="linenos">667</span></a><span class="sd">                            [expected: positive value &lt;=1]. Default: 0.1</span>
</span><span id="L-668"><a href="#L-668"><span class="linenos">668</span></a><span class="sd">        init_sigma (float): The standard deviation of the Gaussian with `init_sigma` when `gauss_type` is</span>
</span><span id="L-669"><a href="#L-669"><span class="linenos">669</span></a><span class="sd">            &#39;isotropic&#39; or &#39;uncorrelated&#39;. When `gauss_type=&#39;full&#39;` initialize the square root of the</span>
</span><span id="L-670"><a href="#L-670"><span class="linenos">670</span></a><span class="sd">            covariance matrix with with Uniform([-init_sigma, init_sigma]). Default: 1</span>
</span><span id="L-671"><a href="#L-671"><span class="linenos">671</span></a><span class="sd">        batch_sample (bool): if True, samples a position for each image in the batch separately</span>
</span><span id="L-672"><a href="#L-672"><span class="linenos">672</span></a><span class="sd">                            [default: True as it decreases convergence time and performs just as well]</span>
</span><span id="L-673"><a href="#L-673"><span class="linenos">673</span></a><span class="sd">        align_corners (bool): Keyword agrument to gridsample for bilinear interpolation.</span>
</span><span id="L-674"><a href="#L-674"><span class="linenos">674</span></a><span class="sd">                It changed behavior in PyTorch 1.3. The default of align_corners = True is setting the</span>
</span><span id="L-675"><a href="#L-675"><span class="linenos">675</span></a><span class="sd">                behavior to pre PyTorch 1.3 functionality for comparability.</span>
</span><span id="L-676"><a href="#L-676"><span class="linenos">676</span></a><span class="sd">        gauss_type (str): Which Gaussian to use. Options are &#39;isotropic&#39;, &#39;uncorrelated&#39;, or &#39;full&#39; (default).</span>
</span><span id="L-677"><a href="#L-677"><span class="linenos">677</span></a><span class="sd">        shifter (dict): Parameters for a predictor of shfiting grid locations. Has to have a form like</span>
</span><span id="L-678"><a href="#L-678"><span class="linenos">678</span></a><span class="sd">                        {</span>
</span><span id="L-679"><a href="#L-679"><span class="linenos">679</span></a><span class="sd">                        &#39;hidden_layers&#39;:1,</span>
</span><span id="L-680"><a href="#L-680"><span class="linenos">680</span></a><span class="sd">                        &#39;hidden_features&#39;:20,</span>
</span><span id="L-681"><a href="#L-681"><span class="linenos">681</span></a><span class="sd">                        &#39;final_tanh&#39;: False,</span>
</span><span id="L-682"><a href="#L-682"><span class="linenos">682</span></a><span class="sd">                        }</span>
</span><span id="L-683"><a href="#L-683"><span class="linenos">683</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-684"><a href="#L-684"><span class="linenos">684</span></a>
</span><span id="L-685"><a href="#L-685"><span class="linenos">685</span></a>    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-686"><a href="#L-686"><span class="linenos">686</span></a>        <span class="n">s</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__repr__</span><span class="p">()</span>
</span><span id="L-687"><a href="#L-687"><span class="linenos">687</span></a>        <span class="c1"># Add information about module to print out</span>
</span><span id="L-688"><a href="#L-688"><span class="linenos">688</span></a>        <span class="n">s</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
</span><span id="L-689"><a href="#L-689"><span class="linenos">689</span></a>        <span class="k">return</span> <span class="n">s</span>
</span><span id="L-690"><a href="#L-690"><span class="linenos">690</span></a>
</span><span id="L-691"><a href="#L-691"><span class="linenos">691</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="L-692"><a href="#L-692"><span class="linenos">692</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="L-693"><a href="#L-693"><span class="linenos">693</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">network_type</span> <span class="o">=</span> <span class="s1">&#39;readout&#39;</span>
</span><span id="L-694"><a href="#L-694"><span class="linenos">694</span></a>        <span class="c1"># Make sure first type is readout: important for interpretation of input dims and potential shifter</span>
</span><span id="L-695"><a href="#L-695"><span class="linenos">695</span></a>        <span class="c1">#assert kwargs[&#39;layer_list&#39;][0][&#39;layer_type&#39;] == &#39;readout&#39;, &quot;READOUT NET: Incorrect leading layer type&quot;</span>
</span><span id="L-696"><a href="#L-696"><span class="linenos">696</span></a>
</span><span id="L-697"><a href="#L-697"><span class="linenos">697</span></a>    <span class="k">def</span> <span class="nf">determine_input_dims</span><span class="p">(</span> <span class="bp">self</span><span class="p">,</span> <span class="n">input_dims_list</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="L-698"><a href="#L-698"><span class="linenos">698</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-699"><a href="#L-699"><span class="linenos">699</span></a><span class="sd">        Sets input_dims given network inputs. Can be overloaded depending on the network type. For this base class, there</span>
</span><span id="L-700"><a href="#L-700"><span class="linenos">700</span></a><span class="sd">        are two types of network input: external stimulus (xstim_n) or a list of internal (ffnet_in) networks:</span>
</span><span id="L-701"><a href="#L-701"><span class="linenos">701</span></a><span class="sd">            For external inputs, it just uses the passed-in input_dims</span>
</span><span id="L-702"><a href="#L-702"><span class="linenos">702</span></a><span class="sd">            For internal network inputs, it will concatenate inputs along the filter dimension, but MUST match other dims</span>
</span><span id="L-703"><a href="#L-703"><span class="linenos">703</span></a><span class="sd">        As currently designed, this can either external or internal, but not both</span>
</span><span id="L-704"><a href="#L-704"><span class="linenos">704</span></a><span class="sd">        </span>
</span><span id="L-705"><a href="#L-705"><span class="linenos">705</span></a><span class="sd">        This sets the following internal FFnetwork properties:</span>
</span><span id="L-706"><a href="#L-706"><span class="linenos">706</span></a><span class="sd">            self.input_dims</span>
</span><span id="L-707"><a href="#L-707"><span class="linenos">707</span></a><span class="sd">            self.input_dims_list</span>
</span><span id="L-708"><a href="#L-708"><span class="linenos">708</span></a><span class="sd">        and returns Boolean whether the passed in input dims are valid</span>
</span><span id="L-709"><a href="#L-709"><span class="linenos">709</span></a>
</span><span id="L-710"><a href="#L-710"><span class="linenos">710</span></a><span class="sd">        Args:</span>
</span><span id="L-711"><a href="#L-711"><span class="linenos">711</span></a><span class="sd">            input_dims_list (list): A list of input dimensions for each layer.</span>
</span><span id="L-712"><a href="#L-712"><span class="linenos">712</span></a><span class="sd">            **kwargs: Additional keyword arguments.</span>
</span><span id="L-713"><a href="#L-713"><span class="linenos">713</span></a>
</span><span id="L-714"><a href="#L-714"><span class="linenos">714</span></a><span class="sd">        Returns:</span>
</span><span id="L-715"><a href="#L-715"><span class="linenos">715</span></a><span class="sd">            valid_input_dims (bool): Whether the passed in input dims are valid.</span>
</span><span id="L-716"><a href="#L-716"><span class="linenos">716</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-717"><a href="#L-717"><span class="linenos">717</span></a>
</span><span id="L-718"><a href="#L-718"><span class="linenos">718</span></a>        <span class="n">valid_input_dims</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="L-719"><a href="#L-719"><span class="linenos">719</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffnets_in</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-720"><a href="#L-720"><span class="linenos">720</span></a>            <span class="c1"># then external input (assume from one source)</span>
</span><span id="L-721"><a href="#L-721"><span class="linenos">721</span></a>            <span class="n">valid_input_dims</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="L-722"><a href="#L-722"><span class="linenos">722</span></a>            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Readout layer cannot get an external input.&#39;</span><span class="p">)</span> 
</span><span id="L-723"><a href="#L-723"><span class="linenos">723</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">input_dims</span> <span class="o">=</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-724"><a href="#L-724"><span class="linenos">724</span></a>        <span class="k">else</span><span class="p">:</span>             
</span><span id="L-725"><a href="#L-725"><span class="linenos">725</span></a>            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_dims_list</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ffnets_in</span><span class="p">),</span> <span class="s1">&#39;Internal: misspecification of input_dims for FFnetwork.&#39;</span>
</span><span id="L-726"><a href="#L-726"><span class="linenos">726</span></a>            <span class="c1"># First dimension is the input network</span>
</span><span id="L-727"><a href="#L-727"><span class="linenos">727</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">input_dims</span> <span class="o">=</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-728"><a href="#L-728"><span class="linenos">728</span></a>            <span class="c1"># Second dimension would be </span>
</span><span id="L-729"><a href="#L-729"><span class="linenos">729</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">shifter</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ffnets_in</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span>
</span><span id="L-730"><a href="#L-730"><span class="linenos">730</span></a>
</span><span id="L-731"><a href="#L-731"><span class="linenos">731</span></a>        <span class="k">return</span> <span class="n">valid_input_dims</span>
</span><span id="L-732"><a href="#L-732"><span class="linenos">732</span></a>    <span class="c1"># END ReadoutNetwork.determine_input_dims</span>
</span><span id="L-733"><a href="#L-733"><span class="linenos">733</span></a>
</span><span id="L-734"><a href="#L-734"><span class="linenos">734</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="L-735"><a href="#L-735"><span class="linenos">735</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-736"><a href="#L-736"><span class="linenos">736</span></a><span class="sd">        Network inputs correspond to output of conv layer, and (if it exists), a shifter.</span>
</span><span id="L-737"><a href="#L-737"><span class="linenos">737</span></a><span class="sd">        </span>
</span><span id="L-738"><a href="#L-738"><span class="linenos">738</span></a><span class="sd">        Args:</span>
</span><span id="L-739"><a href="#L-739"><span class="linenos">739</span></a><span class="sd">            inputs (list, torch.Tensor): The input to the network.</span>
</span><span id="L-740"><a href="#L-740"><span class="linenos">740</span></a>
</span><span id="L-741"><a href="#L-741"><span class="linenos">741</span></a><span class="sd">        Returns:</span>
</span><span id="L-742"><a href="#L-742"><span class="linenos">742</span></a><span class="sd">            y (torch.Tensor): The output of the network.</span>
</span><span id="L-743"><a href="#L-743"><span class="linenos">743</span></a><span class="sd">        &quot;&quot;&quot;</span> 
</span><span id="L-744"><a href="#L-744"><span class="linenos">744</span></a>
</span><span id="L-745"><a href="#L-745"><span class="linenos">745</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="L-746"><a href="#L-746"><span class="linenos">746</span></a>            <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">inputs</span><span class="p">]</span>
</span><span id="L-747"><a href="#L-747"><span class="linenos">747</span></a>
</span><span id="L-748"><a href="#L-748"><span class="linenos">748</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">shifter</span><span class="p">:</span>
</span><span id="L-749"><a href="#L-749"><span class="linenos">749</span></a>            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">shift</span><span class="o">=</span><span class="n">inputs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span><span id="L-750"><a href="#L-750"><span class="linenos">750</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="L-751"><a href="#L-751"><span class="linenos">751</span></a>            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span><span id="L-752"><a href="#L-752"><span class="linenos">752</span></a>        <span class="k">return</span> <span class="n">y</span>
</span><span id="L-753"><a href="#L-753"><span class="linenos">753</span></a>    <span class="c1"># END ReadoutNetwork.forward</span>
</span><span id="L-754"><a href="#L-754"><span class="linenos">754</span></a>
</span><span id="L-755"><a href="#L-755"><span class="linenos">755</span></a>    <span class="k">def</span> <span class="nf">get_readout_locations</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-756"><a href="#L-756"><span class="linenos">756</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-757"><a href="#L-757"><span class="linenos">757</span></a><span class="sd">        Returns the readout locations.</span>
</span><span id="L-758"><a href="#L-758"><span class="linenos">758</span></a>
</span><span id="L-759"><a href="#L-759"><span class="linenos">759</span></a><span class="sd">        Args:</span>
</span><span id="L-760"><a href="#L-760"><span class="linenos">760</span></a><span class="sd">            None</span>
</span><span id="L-761"><a href="#L-761"><span class="linenos">761</span></a>
</span><span id="L-762"><a href="#L-762"><span class="linenos">762</span></a><span class="sd">        Returns:</span>
</span><span id="L-763"><a href="#L-763"><span class="linenos">763</span></a><span class="sd">            The readout locations.</span>
</span><span id="L-764"><a href="#L-764"><span class="linenos">764</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-765"><a href="#L-765"><span class="linenos">765</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_readout_locations</span><span class="p">()</span>
</span><span id="L-766"><a href="#L-766"><span class="linenos">766</span></a>
</span><span id="L-767"><a href="#L-767"><span class="linenos">767</span></a>    <span class="k">def</span> <span class="nf">set_readout_locations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">locs</span><span class="p">):</span>
</span><span id="L-768"><a href="#L-768"><span class="linenos">768</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-769"><a href="#L-769"><span class="linenos">769</span></a><span class="sd">        Sets the readout locations.</span>
</span><span id="L-770"><a href="#L-770"><span class="linenos">770</span></a>
</span><span id="L-771"><a href="#L-771"><span class="linenos">771</span></a><span class="sd">        Args:</span>
</span><span id="L-772"><a href="#L-772"><span class="linenos">772</span></a><span class="sd">            locs: The readout locations.</span>
</span><span id="L-773"><a href="#L-773"><span class="linenos">773</span></a>
</span><span id="L-774"><a href="#L-774"><span class="linenos">774</span></a><span class="sd">        Returns:</span>
</span><span id="L-775"><a href="#L-775"><span class="linenos">775</span></a><span class="sd">            None</span>
</span><span id="L-776"><a href="#L-776"><span class="linenos">776</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-777"><a href="#L-777"><span class="linenos">777</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_readout_locations</span><span class="p">(</span><span class="n">locs</span><span class="p">)</span>
</span><span id="L-778"><a href="#L-778"><span class="linenos">778</span></a>
</span><span id="L-779"><a href="#L-779"><span class="linenos">779</span></a>    <span class="nd">@classmethod</span>
</span><span id="L-780"><a href="#L-780"><span class="linenos">780</span></a>    <span class="k">def</span> <span class="nf">ffnet_dict</span><span class="p">(</span> <span class="bp">cls</span><span class="p">,</span> <span class="n">ffnet_n</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="L-781"><a href="#L-781"><span class="linenos">781</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-782"><a href="#L-782"><span class="linenos">782</span></a><span class="sd">        Returns a dictionary of the readout network.</span>
</span><span id="L-783"><a href="#L-783"><span class="linenos">783</span></a>
</span><span id="L-784"><a href="#L-784"><span class="linenos">784</span></a><span class="sd">        Args:</span>
</span><span id="L-785"><a href="#L-785"><span class="linenos">785</span></a><span class="sd">            ffnet_n (int): The feedforward network.</span>
</span><span id="L-786"><a href="#L-786"><span class="linenos">786</span></a>
</span><span id="L-787"><a href="#L-787"><span class="linenos">787</span></a><span class="sd">        Returns:</span>
</span><span id="L-788"><a href="#L-788"><span class="linenos">788</span></a><span class="sd">            ffnet_dict (dict): The dictionary of the readout network.</span>
</span><span id="L-789"><a href="#L-789"><span class="linenos">789</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-790"><a href="#L-790"><span class="linenos">790</span></a>        <span class="n">ffnet_dict</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">ffnet_dict</span><span class="p">(</span><span class="n">xstim_n</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ffnet_n</span><span class="o">=</span><span class="n">ffnet_n</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="L-791"><a href="#L-791"><span class="linenos">791</span></a>        <span class="n">ffnet_dict</span><span class="p">[</span><span class="s1">&#39;ffnet_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;readout&#39;</span>
</span><span id="L-792"><a href="#L-792"><span class="linenos">792</span></a>        <span class="k">return</span> <span class="n">ffnet_dict</span>
</span><span id="L-793"><a href="#L-793"><span class="linenos">793</span></a>    <span class="c1"># END ReadoutNetwork</span>
</span><span id="L-794"><a href="#L-794"><span class="linenos">794</span></a>
</span><span id="L-795"><a href="#L-795"><span class="linenos">795</span></a>
</span><span id="L-796"><a href="#L-796"><span class="linenos">796</span></a><span class="k">class</span> <span class="nc">FFnet_external</span><span class="p">(</span><span class="n">FFnetwork</span><span class="p">):</span>
</span><span id="L-797"><a href="#L-797"><span class="linenos">797</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-798"><a href="#L-798"><span class="linenos">798</span></a><span class="sd">    This is a &#39;shell&#39; that lets an external network be plugged into the NDN. It establishes all the basics</span>
</span><span id="L-799"><a href="#L-799"><span class="linenos">799</span></a><span class="sd">    so that information requested to this network from other parts of the NDN will behave correctly.</span>
</span><span id="L-800"><a href="#L-800"><span class="linenos">800</span></a>
</span><span id="L-801"><a href="#L-801"><span class="linenos">801</span></a><span class="sd">    Args:</span>
</span><span id="L-802"><a href="#L-802"><span class="linenos">802</span></a><span class="sd">        external_module_dict (dict): A dictionary of external modules.</span>
</span><span id="L-803"><a href="#L-803"><span class="linenos">803</span></a><span class="sd">        external_module_name (str): The name of the external module.</span>
</span><span id="L-804"><a href="#L-804"><span class="linenos">804</span></a><span class="sd">        input_dims_reshape (list): A list of input dimensions to reshape.</span>
</span><span id="L-805"><a href="#L-805"><span class="linenos">805</span></a><span class="sd">        **kwargs: Additional keyword arguments.</span>
</span><span id="L-806"><a href="#L-806"><span class="linenos">806</span></a>
</span><span id="L-807"><a href="#L-807"><span class="linenos">807</span></a><span class="sd">    Raises:</span>
</span><span id="L-808"><a href="#L-808"><span class="linenos">808</span></a><span class="sd">        AssertionError: If the external module dictionary is invalid.</span>
</span><span id="L-809"><a href="#L-809"><span class="linenos">809</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="L-810"><a href="#L-810"><span class="linenos">810</span></a>    <span class="c1">#def __repr__(self):</span>
</span><span id="L-811"><a href="#L-811"><span class="linenos">811</span></a>    <span class="c1">#    s = super().__repr__()</span>
</span><span id="L-812"><a href="#L-812"><span class="linenos">812</span></a>    <span class="c1">#    # Add information about module to print out</span>
</span><span id="L-813"><a href="#L-813"><span class="linenos">813</span></a>
</span><span id="L-814"><a href="#L-814"><span class="linenos">814</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">external_module_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">external_module_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_dims_reshape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="L-815"><a href="#L-815"><span class="linenos">815</span></a>        <span class="c1"># The parent construct will make a &#39;dummy layer&#39; that will be filled in with module 0 below</span>
</span><span id="L-816"><a href="#L-816"><span class="linenos">816</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">FFnet_external</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="L-817"><a href="#L-817"><span class="linenos">817</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">network_type</span> <span class="o">=</span> <span class="s1">&#39;external&#39;</span>
</span><span id="L-818"><a href="#L-818"><span class="linenos">818</span></a>
</span><span id="L-819"><a href="#L-819"><span class="linenos">819</span></a>        <span class="c1"># Extract relevant network fom extenal_module_dict using the ffnet_params[&#39;layer_types&#39;]</span>
</span><span id="L-820"><a href="#L-820"><span class="linenos">820</span></a>        <span class="k">assert</span> <span class="n">external_module_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;external_module_dict cannot be None.&#39;</span>
</span><span id="L-821"><a href="#L-821"><span class="linenos">821</span></a>        
</span><span id="L-822"><a href="#L-822"><span class="linenos">822</span></a>        <span class="n">net_name</span> <span class="o">=</span> <span class="n">external_module_name</span>
</span><span id="L-823"><a href="#L-823"><span class="linenos">823</span></a>        <span class="k">assert</span> <span class="n">net_name</span> <span class="ow">in</span> <span class="n">external_module_dict</span><span class="p">,</span> <span class="s1">&#39;External network </span><span class="si">%s</span><span class="s1"> not found in external_modules dict.&#39;</span><span class="o">%</span><span class="n">net_name</span>
</span><span id="L-824"><a href="#L-824"><span class="linenos">824</span></a>
</span><span id="L-825"><a href="#L-825"><span class="linenos">825</span></a>        <span class="c1"># This network will be made to be a layer (so the ffnet forward is the layer forward). Now place external network here</span>
</span><span id="L-826"><a href="#L-826"><span class="linenos">826</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">external_network</span> <span class="o">=</span> <span class="n">external_module_dict</span><span class="p">[</span><span class="n">net_name</span><span class="p">]</span>
</span><span id="L-827"><a href="#L-827"><span class="linenos">827</span></a>        <span class="k">assert</span> <span class="n">input_dims_reshape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;input_dims_reshape cannot be None. Jake did not know what it is supposed to default to so he used None.&#39;</span>
</span><span id="L-828"><a href="#L-828"><span class="linenos">828</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">input_dims_reshape</span> <span class="o">=</span> <span class="n">input_dims_reshape</span>
</span><span id="L-829"><a href="#L-829"><span class="linenos">829</span></a>    <span class="c1"># END FFnet_external.__init__</span>
</span><span id="L-830"><a href="#L-830"><span class="linenos">830</span></a>
</span><span id="L-831"><a href="#L-831"><span class="linenos">831</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="L-832"><a href="#L-832"><span class="linenos">832</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-833"><a href="#L-833"><span class="linenos">833</span></a><span class="sd">        Forward pass through the network.</span>
</span><span id="L-834"><a href="#L-834"><span class="linenos">834</span></a>
</span><span id="L-835"><a href="#L-835"><span class="linenos">835</span></a><span class="sd">        Args:</span>
</span><span id="L-836"><a href="#L-836"><span class="linenos">836</span></a><span class="sd">            inputs (list, torch.Tensor): The input to the network.</span>
</span><span id="L-837"><a href="#L-837"><span class="linenos">837</span></a>
</span><span id="L-838"><a href="#L-838"><span class="linenos">838</span></a><span class="sd">        Returns:</span>
</span><span id="L-839"><a href="#L-839"><span class="linenos">839</span></a><span class="sd">            y (torch.Tensor): The output of the network.</span>
</span><span id="L-840"><a href="#L-840"><span class="linenos">840</span></a>
</span><span id="L-841"><a href="#L-841"><span class="linenos">841</span></a><span class="sd">        Raises:</span>
</span><span id="L-842"><a href="#L-842"><span class="linenos">842</span></a><span class="sd">            ValueError: If no layers are defined.</span>
</span><span id="L-843"><a href="#L-843"><span class="linenos">843</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-844"><a href="#L-844"><span class="linenos">844</span></a>        
</span><span id="L-845"><a href="#L-845"><span class="linenos">845</span></a>        <span class="c1"># Leave all heavy lifting to the external module, which is in layers[0]. But concatenate network inputs, as needed</span>
</span><span id="L-846"><a href="#L-846"><span class="linenos">846</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-847"><a href="#L-847"><span class="linenos">847</span></a>        <span class="k">for</span> <span class="n">mm</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)):</span>
</span><span id="L-848"><a href="#L-848"><span class="linenos">848</span></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">inputs</span><span class="p">[</span><span class="n">mm</span><span class="p">]),</span> <span class="mi">1</span> <span class="p">)</span>
</span><span id="L-849"><a href="#L-849"><span class="linenos">849</span></a>        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="L-850"><a href="#L-850"><span class="linenos">850</span></a>
</span><span id="L-851"><a href="#L-851"><span class="linenos">851</span></a>        <span class="c1"># Reshape dimensions for layer as needed</span>
</span><span id="L-852"><a href="#L-852"><span class="linenos">852</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_dims_reshape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-853"><a href="#L-853"><span class="linenos">853</span></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span> <span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_dims_reshape</span><span class="p">)</span>
</span><span id="L-854"><a href="#L-854"><span class="linenos">854</span></a>        
</span><span id="L-855"><a href="#L-855"><span class="linenos">855</span></a>        <span class="c1"># Pass into external network</span>
</span><span id="L-856"><a href="#L-856"><span class="linenos">856</span></a>        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">x</span><span class="p">)</span>
</span><span id="L-857"><a href="#L-857"><span class="linenos">857</span></a>
</span><span id="L-858"><a href="#L-858"><span class="linenos">858</span></a>        <span class="c1"># Ensure that output is flattened</span>
</span><span id="L-859"><a href="#L-859"><span class="linenos">859</span></a>        <span class="k">return</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="L-860"><a href="#L-860"><span class="linenos">860</span></a>    
</span><span id="L-861"><a href="#L-861"><span class="linenos">861</span></a>    <span class="k">def</span> <span class="nf">compute_reg_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-862"><a href="#L-862"><span class="linenos">862</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-863"><a href="#L-863"><span class="linenos">863</span></a><span class="sd">        Computes the regularization loss.</span>
</span><span id="L-864"><a href="#L-864"><span class="linenos">864</span></a>
</span><span id="L-865"><a href="#L-865"><span class="linenos">865</span></a><span class="sd">        Args:</span>
</span><span id="L-866"><a href="#L-866"><span class="linenos">866</span></a><span class="sd">            None</span>
</span><span id="L-867"><a href="#L-867"><span class="linenos">867</span></a>
</span><span id="L-868"><a href="#L-868"><span class="linenos">868</span></a><span class="sd">        Returns:</span>
</span><span id="L-869"><a href="#L-869"><span class="linenos">869</span></a><span class="sd">            0</span>
</span><span id="L-870"><a href="#L-870"><span class="linenos">870</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-871"><a href="#L-871"><span class="linenos">871</span></a>        <span class="c1"># Since we do not implement regularization within the external network, this returns nothing</span>
</span><span id="L-872"><a href="#L-872"><span class="linenos">872</span></a>        <span class="k">return</span> <span class="mi">0</span>
</span><span id="L-873"><a href="#L-873"><span class="linenos">873</span></a>
</span><span id="L-874"><a href="#L-874"><span class="linenos">874</span></a>    <span class="k">def</span> <span class="nf">list_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer_target</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="L-875"><a href="#L-875"><span class="linenos">875</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-876"><a href="#L-876"><span class="linenos">876</span></a><span class="sd">        Lists the parameters for the network.</span>
</span><span id="L-877"><a href="#L-877"><span class="linenos">877</span></a>
</span><span id="L-878"><a href="#L-878"><span class="linenos">878</span></a><span class="sd">        Args:</span>
</span><span id="L-879"><a href="#L-879"><span class="linenos">879</span></a><span class="sd">            layer_target (int, optional): The layer to list the parameters for. Defaults to None.</span>
</span><span id="L-880"><a href="#L-880"><span class="linenos">880</span></a>
</span><span id="L-881"><a href="#L-881"><span class="linenos">881</span></a><span class="sd">        Returns:</span>
</span><span id="L-882"><a href="#L-882"><span class="linenos">882</span></a><span class="sd">            None</span>
</span><span id="L-883"><a href="#L-883"><span class="linenos">883</span></a>
</span><span id="L-884"><a href="#L-884"><span class="linenos">884</span></a><span class="sd">        Raises:</span>
</span><span id="L-885"><a href="#L-885"><span class="linenos">885</span></a><span class="sd">            AssertionError: If the layer target is invalid.</span>
</span><span id="L-886"><a href="#L-886"><span class="linenos">886</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-887"><a href="#L-887"><span class="linenos">887</span></a>        <span class="k">assert</span> <span class="n">layer_target</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;No ability to directly distinguish layers in the external network.&#39;</span>
</span><span id="L-888"><a href="#L-888"><span class="linenos">888</span></a>        <span class="k">for</span> <span class="n">nm</span><span class="p">,</span> <span class="n">pp</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">(</span><span class="n">recurse</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
</span><span id="L-889"><a href="#L-889"><span class="linenos">889</span></a>            <span class="k">if</span> <span class="n">pp</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
</span><span id="L-890"><a href="#L-890"><span class="linenos">890</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;    </span><span class="si">%s</span><span class="s2">:&quot;</span><span class="o">%</span><span class="n">nm</span><span class="p">,</span> <span class="n">pp</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</span><span id="L-891"><a href="#L-891"><span class="linenos">891</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="L-892"><a href="#L-892"><span class="linenos">892</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;    NOT FIT: </span><span class="si">%s</span><span class="s2">:&quot;</span><span class="o">%</span><span class="n">nm</span><span class="p">,</span> <span class="n">pp</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</span><span id="L-893"><a href="#L-893"><span class="linenos">893</span></a>
</span><span id="L-894"><a href="#L-894"><span class="linenos">894</span></a>    <span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer_target</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">val</span><span class="o">=</span><span class="kc">None</span> <span class="p">):</span>
</span><span id="L-895"><a href="#L-895"><span class="linenos">895</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-896"><a href="#L-896"><span class="linenos">896</span></a><span class="sd">        Sets the parameters for the listed layer or for all layers.</span>
</span><span id="L-897"><a href="#L-897"><span class="linenos">897</span></a>
</span><span id="L-898"><a href="#L-898"><span class="linenos">898</span></a><span class="sd">        Args:</span>
</span><span id="L-899"><a href="#L-899"><span class="linenos">899</span></a><span class="sd">            layer_target (int, optional): The layer to set the parameters for. Defaults to None.</span>
</span><span id="L-900"><a href="#L-900"><span class="linenos">900</span></a><span class="sd">            name (str): The name of the parameter.</span>
</span><span id="L-901"><a href="#L-901"><span class="linenos">901</span></a><span class="sd">            val (bool): The value to set the parameter to.</span>
</span><span id="L-902"><a href="#L-902"><span class="linenos">902</span></a>
</span><span id="L-903"><a href="#L-903"><span class="linenos">903</span></a><span class="sd">        Returns:</span>
</span><span id="L-904"><a href="#L-904"><span class="linenos">904</span></a><span class="sd">            None</span>
</span><span id="L-905"><a href="#L-905"><span class="linenos">905</span></a>
</span><span id="L-906"><a href="#L-906"><span class="linenos">906</span></a><span class="sd">        Raises:</span>
</span><span id="L-907"><a href="#L-907"><span class="linenos">907</span></a><span class="sd">            AssertionError: If the layer target is invalid.</span>
</span><span id="L-908"><a href="#L-908"><span class="linenos">908</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-909"><a href="#L-909"><span class="linenos">909</span></a>        <span class="k">assert</span> <span class="n">layer_target</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;No ability to directly distinguish layers in the external network.&#39;</span>
</span><span id="L-910"><a href="#L-910"><span class="linenos">910</span></a>        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="nb">bool</span><span class="p">),</span> <span class="s1">&#39;val must be set.&#39;</span>
</span><span id="L-911"><a href="#L-911"><span class="linenos">911</span></a>        <span class="k">for</span> <span class="n">nm</span><span class="p">,</span> <span class="n">pp</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">(</span><span class="n">recurse</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
</span><span id="L-912"><a href="#L-912"><span class="linenos">912</span></a>            <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-913"><a href="#L-913"><span class="linenos">913</span></a>                <span class="n">pp</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="n">val</span>
</span><span id="L-914"><a href="#L-914"><span class="linenos">914</span></a>            <span class="k">elif</span> <span class="n">nm</span> <span class="o">==</span> <span class="n">name</span><span class="p">:</span>
</span><span id="L-915"><a href="#L-915"><span class="linenos">915</span></a>                <span class="n">pp</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="n">val</span>
</span><span id="L-916"><a href="#L-916"><span class="linenos">916</span></a>
</span><span id="L-917"><a href="#L-917"><span class="linenos">917</span></a>    <span class="nd">@classmethod</span>
</span><span id="L-918"><a href="#L-918"><span class="linenos">918</span></a>    <span class="k">def</span> <span class="nf">ffnet_dict</span><span class="p">(</span> <span class="bp">cls</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="L-919"><a href="#L-919"><span class="linenos">919</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-920"><a href="#L-920"><span class="linenos">920</span></a><span class="sd">        Returns a dictionary of the external network.</span>
</span><span id="L-921"><a href="#L-921"><span class="linenos">921</span></a>
</span><span id="L-922"><a href="#L-922"><span class="linenos">922</span></a><span class="sd">        Args:</span>
</span><span id="L-923"><a href="#L-923"><span class="linenos">923</span></a><span class="sd">            **kwargs: Additional keyword arguments.</span>
</span><span id="L-924"><a href="#L-924"><span class="linenos">924</span></a>
</span><span id="L-925"><a href="#L-925"><span class="linenos">925</span></a><span class="sd">        Returns:</span>
</span><span id="L-926"><a href="#L-926"><span class="linenos">926</span></a><span class="sd">            ffnet_dict (dict): The dictionary of the external network.</span>
</span><span id="L-927"><a href="#L-927"><span class="linenos">927</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="L-928"><a href="#L-928"><span class="linenos">928</span></a>        <span class="n">ffnet_dict</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">ffnet_dict</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="L-929"><a href="#L-929"><span class="linenos">929</span></a>        <span class="n">ffnet_dict</span><span class="p">[</span><span class="s1">&#39;ffnet_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;external&#39;</span>
</span><span id="L-930"><a href="#L-930"><span class="linenos">930</span></a>        <span class="k">return</span> <span class="n">ffnet_dict</span>
</span></pre></div>


            </section>
                <section id="LayerTypes">
                    <div class="attr variable">
            <span class="name">LayerTypes</span>        =
<input id="LayerTypes-view-value" class="view-value-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
            <label class="view-value-button pdoc-button" for="LayerTypes-view-value"></label><span class="default_value">{&#39;normal&#39;: &lt;class &#39;<a href="modules/layers/ndnlayer.html#NDNLayer">NDNT.modules.layers.ndnlayer.NDNLayer</a>&#39;&gt;, &#39;conv&#39;: &lt;class &#39;<a href="modules/layers/convlayers.html#ConvLayer">NDNT.modules.layers.convlayers.ConvLayer</a>&#39;&gt;, &#39;divnorm&#39;: &lt;class &#39;<a href="modules/layers/normlayers.html#DivNormLayer">NDNT.modules.layers.normlayers.DivNormLayer</a>&#39;&gt;, &#39;tconv&#39;: &lt;class &#39;<a href="modules/layers/convlayers.html#TconvLayer">NDNT.modules.layers.convlayers.TconvLayer</a>&#39;&gt;, &#39;stconv&#39;: &lt;class &#39;<a href="modules/layers/convlayers.html#STconvLayer">NDNT.modules.layers.convlayers.STconvLayer</a>&#39;&gt;, &#39;tlayer&#39;: &lt;class &#39;<a href="modules/layers/specialtylayers.html#Tlayer">NDNT.modules.layers.specialtylayers.Tlayer</a>&#39;&gt;, &#39;biconv&#39;: &lt;class &#39;<a href="modules/layers/bilayers.html#BiConvLayer1D">NDNT.modules.layers.bilayers.BiConvLayer1D</a>&#39;&gt;, &#39;bistconv&#39;: &lt;class &#39;<a href="modules/layers/bilayers.html#BiSTconv1D">NDNT.modules.layers.bilayers.BiSTconv1D</a>&#39;&gt;, &#39;ori&#39;: &lt;class &#39;<a href="modules/layers/orilayers.html#OriLayer">NDNT.modules.layers.orilayers.OriLayer</a>&#39;&gt;, &#39;oriconv&#39;: &lt;class &#39;<a href="modules/layers/orilayers.html#OriConvLayer">NDNT.modules.layers.orilayers.OriConvLayer</a>&#39;&gt;, &#39;conv3d&#39;: &lt;class &#39;<a href="modules/layers/orilayers.html#ConvLayer3D">NDNT.modules.layers.orilayers.ConvLayer3D</a>&#39;&gt;, &#39;oolayer&#39;: &lt;class &#39;<a href="modules/layers/specialtylayers.html#OnOffLayer">NDNT.modules.layers.specialtylayers.OnOffLayer</a>&#39;&gt;, &#39;masklayer&#39;: &lt;class &#39;<a href="modules/layers/specialtylayers.html#MaskLayer">NDNT.modules.layers.specialtylayers.MaskLayer</a>&#39;&gt;, &#39;iter&#39;: &lt;class &#39;<a href="modules/layers/reslayers.html#IterLayer">NDNT.modules.layers.reslayers.IterLayer</a>&#39;&gt;, &#39;iterT&#39;: &lt;class &#39;<a href="modules/layers/reslayers.html#IterTlayer">NDNT.modules.layers.reslayers.IterTlayer</a>&#39;&gt;, &#39;iterST&#39;: &lt;class &#39;<a href="modules/layers/reslayers.html#IterSTlayer">NDNT.modules.layers.reslayers.IterSTlayer</a>&#39;&gt;, &#39;readout&#39;: &lt;class &#39;<a href="modules/layers/readouts.html#ReadoutLayer">NDNT.modules.layers.readouts.ReadoutLayer</a>&#39;&gt;, &#39;readout3d&#39;: &lt;class &#39;<a href="modules/layers/readouts.html#ReadoutLayer3d">NDNT.modules.layers.readouts.ReadoutLayer3d</a>&#39;&gt;, &#39;fixation&#39;: &lt;class &#39;<a href="modules/layers/readouts.html#FixationLayer">NDNT.modules.layers.readouts.FixationLayer</a>&#39;&gt;, &#39;lag&#39;: &lt;class &#39;<a href="modules/layers/laglayers.html#LagLayer">NDNT.modules.layers.laglayers.LagLayer</a>&#39;&gt;, &#39;time&#39;: &lt;class &#39;<a href="modules/layers/timelayers.html#TimeLayer">NDNT.modules.layers.timelayers.TimeLayer</a>&#39;&gt;, &#39;dim0&#39;: &lt;class &#39;<a href="modules/layers/dimlayers.html#Dim0Layer">NDNT.modules.layers.dimlayers.Dim0Layer</a>&#39;&gt;, &#39;dimSP&#39;: &lt;class &#39;<a href="modules/layers/dimlayers.html#DimSPLayer">NDNT.modules.layers.dimlayers.DimSPLayer</a>&#39;&gt;, &#39;dimSPT&#39;: &lt;class &#39;<a href="modules/layers/dimlayers.html#DimSPTLayer">NDNT.modules.layers.dimlayers.DimSPTLayer</a>&#39;&gt;, &#39;channel&#39;: &lt;class &#39;<a href="modules/layers/dimlayers.html#ChannelLayer">NDNT.modules.layers.dimlayers.ChannelLayer</a>&#39;&gt;, &#39;LVlayer&#39;: &lt;class &#39;<a href="modules/layers/lvlayers.html#LVLayer">NDNT.modules.layers.lvlayers.LVLayer</a>&#39;&gt;, &#39;l1layer&#39;: &lt;class &#39;<a href="modules/layers/specialtylayers.html#L1convLayer">NDNT.modules.layers.specialtylayers.L1convLayer</a>&#39;&gt;}</span>

        
    </div>
    <a class="headerlink" href="#LayerTypes"></a>
    
    

                </section>
                <section id="FFnetwork">
                            <input id="FFnetwork-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">FFnetwork</span><wbr>(<span class="base">torch.nn.modules.module.Module</span>):

                <label class="view-source-button" for="FFnetwork-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FFnetwork"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FFnetwork-46"><a href="#FFnetwork-46"><span class="linenos"> 46</span></a><span class="k">class</span> <span class="nc">FFnetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="FFnetwork-47"><a href="#FFnetwork-47"><span class="linenos"> 47</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnetwork-48"><a href="#FFnetwork-48"><span class="linenos"> 48</span></a><span class="sd">    Initializes an instance of the network.</span>
</span><span id="FFnetwork-49"><a href="#FFnetwork-49"><span class="linenos"> 49</span></a>
</span><span id="FFnetwork-50"><a href="#FFnetwork-50"><span class="linenos"> 50</span></a><span class="sd">    Args:</span>
</span><span id="FFnetwork-51"><a href="#FFnetwork-51"><span class="linenos"> 51</span></a><span class="sd">        layer_list (list, optional): A list of dictionaries representing the layers of the network. Defaults to None.</span>
</span><span id="FFnetwork-52"><a href="#FFnetwork-52"><span class="linenos"> 52</span></a><span class="sd">        ffnet_type (str, optional): The type of the feedforward network. Defaults to &#39;normal&#39;.</span>
</span><span id="FFnetwork-53"><a href="#FFnetwork-53"><span class="linenos"> 53</span></a><span class="sd">        xstim_n (str, optional): The name of the stimulus input. Defaults to &#39;stim&#39;.</span>
</span><span id="FFnetwork-54"><a href="#FFnetwork-54"><span class="linenos"> 54</span></a><span class="sd">        ffnet_n (list, optional): A list of feedforward networks. Defaults to None.</span>
</span><span id="FFnetwork-55"><a href="#FFnetwork-55"><span class="linenos"> 55</span></a><span class="sd">        input_dims_list (list, optional): A list of input dimensions for each layer. Defaults to None.</span>
</span><span id="FFnetwork-56"><a href="#FFnetwork-56"><span class="linenos"> 56</span></a><span class="sd">        reg_list (list, optional): A list of regularization parameters. Defaults to None.</span>
</span><span id="FFnetwork-57"><a href="#FFnetwork-57"><span class="linenos"> 57</span></a><span class="sd">        scaffold_levels (list, optional): A list of scaffold levels. Defaults to None.</span>
</span><span id="FFnetwork-58"><a href="#FFnetwork-58"><span class="linenos"> 58</span></a><span class="sd">        **kwargs: Additional keyword arguments.</span>
</span><span id="FFnetwork-59"><a href="#FFnetwork-59"><span class="linenos"> 59</span></a>
</span><span id="FFnetwork-60"><a href="#FFnetwork-60"><span class="linenos"> 60</span></a><span class="sd">    Raises:</span>
</span><span id="FFnetwork-61"><a href="#FFnetwork-61"><span class="linenos"> 61</span></a><span class="sd">        AssertionError: If layer_list is not provided.</span>
</span><span id="FFnetwork-62"><a href="#FFnetwork-62"><span class="linenos"> 62</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="FFnetwork-63"><a href="#FFnetwork-63"><span class="linenos"> 63</span></a>
</span><span id="FFnetwork-64"><a href="#FFnetwork-64"><span class="linenos"> 64</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
</span><span id="FFnetwork-65"><a href="#FFnetwork-65"><span class="linenos"> 65</span></a>                <span class="n">layer_list</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="FFnetwork-66"><a href="#FFnetwork-66"><span class="linenos"> 66</span></a>                <span class="n">ffnet_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;normal&#39;</span><span class="p">,</span>
</span><span id="FFnetwork-67"><a href="#FFnetwork-67"><span class="linenos"> 67</span></a>                <span class="n">xstim_n</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;stim&#39;</span><span class="p">,</span>
</span><span id="FFnetwork-68"><a href="#FFnetwork-68"><span class="linenos"> 68</span></a>                <span class="n">ffnet_n</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="FFnetwork-69"><a href="#FFnetwork-69"><span class="linenos"> 69</span></a>                <span class="n">input_dims_list</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="FFnetwork-70"><a href="#FFnetwork-70"><span class="linenos"> 70</span></a>                <span class="n">reg_list</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="FFnetwork-71"><a href="#FFnetwork-71"><span class="linenos"> 71</span></a>                <span class="n">scaffold_levels</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="FFnetwork-72"><a href="#FFnetwork-72"><span class="linenos"> 72</span></a>                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="FFnetwork-73"><a href="#FFnetwork-73"><span class="linenos"> 73</span></a>                <span class="p">):</span>
</span><span id="FFnetwork-74"><a href="#FFnetwork-74"><span class="linenos"> 74</span></a>        <span class="c1"># if len(kwargs) &gt; 0:</span>
</span><span id="FFnetwork-75"><a href="#FFnetwork-75"><span class="linenos"> 75</span></a>        <span class="c1">#     print(&quot;FFnet: unknown kwargs:&quot;, kwargs)</span>
</span><span id="FFnetwork-76"><a href="#FFnetwork-76"><span class="linenos"> 76</span></a>        <span class="k">assert</span> <span class="n">layer_list</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;FFnetwork: Must supply a layer_list.&quot;</span>
</span><span id="FFnetwork-77"><a href="#FFnetwork-77"><span class="linenos"> 77</span></a>        
</span><span id="FFnetwork-78"><a href="#FFnetwork-78"><span class="linenos"> 78</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="FFnetwork-79"><a href="#FFnetwork-79"><span class="linenos"> 79</span></a>        
</span><span id="FFnetwork-80"><a href="#FFnetwork-80"><span class="linenos"> 80</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">network_type</span> <span class="o">=</span> <span class="n">ffnet_type</span>
</span><span id="FFnetwork-81"><a href="#FFnetwork-81"><span class="linenos"> 81</span></a>        <span class="c1">#print(&quot;FFnet: network type:&quot;, self.network_type)</span>
</span><span id="FFnetwork-82"><a href="#FFnetwork-82"><span class="linenos"> 82</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">network_type</span> <span class="ow">in</span> <span class="n">_valid_ffnet_types</span><span class="p">,</span> <span class="s2">&quot;ffnet_type &quot;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">network_type</span> <span class="o">+</span> <span class="s2">&quot; is unknown.&quot;</span>
</span><span id="FFnetwork-83"><a href="#FFnetwork-83"><span class="linenos"> 83</span></a>
</span><span id="FFnetwork-84"><a href="#FFnetwork-84"><span class="linenos"> 84</span></a>        <span class="c1"># Format and record inputs into ffnet</span>
</span><span id="FFnetwork-85"><a href="#FFnetwork-85"><span class="linenos"> 85</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layer_list</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">layer_list</span><span class="p">)</span>
</span><span id="FFnetwork-86"><a href="#FFnetwork-86"><span class="linenos"> 86</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layer_types</span> <span class="o">=</span> <span class="p">[]</span>   <span class="c1"># read from layer_list (if necessary at all)</span>
</span><span id="FFnetwork-87"><a href="#FFnetwork-87"><span class="linenos"> 87</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">xstim_n</span> <span class="o">=</span> <span class="n">xstim_n</span>
</span><span id="FFnetwork-88"><a href="#FFnetwork-88"><span class="linenos"> 88</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">ffnets_in</span> <span class="o">=</span> <span class="n">ffnet_n</span>
</span><span id="FFnetwork-89"><a href="#FFnetwork-89"><span class="linenos"> 89</span></a>
</span><span id="FFnetwork-90"><a href="#FFnetwork-90"><span class="linenos"> 90</span></a>        <span class="n">num_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_list</span><span class="p">)</span>
</span><span id="FFnetwork-91"><a href="#FFnetwork-91"><span class="linenos"> 91</span></a>
</span><span id="FFnetwork-92"><a href="#FFnetwork-92"><span class="linenos"> 92</span></a>        <span class="k">if</span> <span class="n">num_layers</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="FFnetwork-93"><a href="#FFnetwork-93"><span class="linenos"> 93</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
</span><span id="FFnetwork-94"><a href="#FFnetwork-94"><span class="linenos"> 94</span></a>            <span class="k">return</span>
</span><span id="FFnetwork-95"><a href="#FFnetwork-95"><span class="linenos"> 95</span></a>            
</span><span id="FFnetwork-96"><a href="#FFnetwork-96"><span class="linenos"> 96</span></a>        <span class="c1"># Establish input dims from the network</span>
</span><span id="FFnetwork-97"><a href="#FFnetwork-97"><span class="linenos"> 97</span></a>        <span class="k">if</span> <span class="n">input_dims_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FFnetwork-98"><a href="#FFnetwork-98"><span class="linenos"> 98</span></a>            <span class="c1"># then pull from first layer</span>
</span><span id="FFnetwork-99"><a href="#FFnetwork-99"><span class="linenos"> 99</span></a>            <span class="k">assert</span> <span class="n">layer_list</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;input_dims&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;If input_dims is not specified, it must be specified in layer-0&quot;</span>
</span><span id="FFnetwork-100"><a href="#FFnetwork-100"><span class="linenos">100</span></a>            <span class="n">input_dims_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">layer_list</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;input_dims&#39;</span><span class="p">])]</span>
</span><span id="FFnetwork-101"><a href="#FFnetwork-101"><span class="linenos">101</span></a>        
</span><span id="FFnetwork-102"><a href="#FFnetwork-102"><span class="linenos">102</span></a>        <span class="c1"># Build input_dims from sources</span>
</span><span id="FFnetwork-103"><a href="#FFnetwork-103"><span class="linenos">103</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">determine_input_dims</span><span class="p">(</span><span class="n">input_dims_list</span><span class="p">,</span> <span class="n">ffnet_type</span><span class="o">=</span><span class="n">ffnet_type</span><span class="p">),</span> <span class="s1">&#39;Invalid network inputs.&#39;</span>
</span><span id="FFnetwork-104"><a href="#FFnetwork-104"><span class="linenos">104</span></a>
</span><span id="FFnetwork-105"><a href="#FFnetwork-105"><span class="linenos">105</span></a>        <span class="c1"># Process regularization into layer-specific list. Will save at this level too</span>
</span><span id="FFnetwork-106"><a href="#FFnetwork-106"><span class="linenos">106</span></a>        <span class="c1">#if reg_list is not None:  # can also be entered into layers directly</span>
</span><span id="FFnetwork-107"><a href="#FFnetwork-107"><span class="linenos">107</span></a>        <span class="c1">#    reg_params = self.__reg_setup_ffnet( reg_list )</span>
</span><span id="FFnetwork-108"><a href="#FFnetwork-108"><span class="linenos">108</span></a>
</span><span id="FFnetwork-109"><a href="#FFnetwork-109"><span class="linenos">109</span></a>        <span class="c1"># Make each layer as part of an array</span>
</span><span id="FFnetwork-110"><a href="#FFnetwork-110"><span class="linenos">110</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
</span><span id="FFnetwork-111"><a href="#FFnetwork-111"><span class="linenos">111</span></a>        <span class="k">for</span> <span class="n">ll</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">):</span>
</span><span id="FFnetwork-112"><a href="#FFnetwork-112"><span class="linenos">112</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_list</span><span class="p">[</span><span class="n">ll</span><span class="p">][</span><span class="s1">&#39;input_dims&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FFnetwork-113"><a href="#FFnetwork-113"><span class="linenos">113</span></a>                <span class="k">if</span> <span class="n">ll</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="FFnetwork-114"><a href="#FFnetwork-114"><span class="linenos">114</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">layer_list</span><span class="p">[</span><span class="n">ll</span><span class="p">][</span><span class="s1">&#39;input_dims&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_dims</span><span class="p">)</span>
</span><span id="FFnetwork-115"><a href="#FFnetwork-115"><span class="linenos">115</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="FFnetwork-116"><a href="#FFnetwork-116"><span class="linenos">116</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">layer_list</span><span class="p">[</span><span class="n">ll</span><span class="p">][</span><span class="s1">&#39;input_dims&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">ll</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">output_dims</span><span class="p">)</span>
</span><span id="FFnetwork-117"><a href="#FFnetwork-117"><span class="linenos">117</span></a>            <span class="n">Ltype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_list</span><span class="p">[</span><span class="n">ll</span><span class="p">][</span><span class="s1">&#39;layer_type&#39;</span><span class="p">]</span>
</span><span id="FFnetwork-118"><a href="#FFnetwork-118"><span class="linenos">118</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">LayerTypes</span><span class="p">[</span><span class="n">Ltype</span><span class="p">](</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_list</span><span class="p">[</span><span class="n">ll</span><span class="p">])</span> <span class="p">)</span>
</span><span id="FFnetwork-119"><a href="#FFnetwork-119"><span class="linenos">119</span></a>
</span><span id="FFnetwork-120"><a href="#FFnetwork-120"><span class="linenos">120</span></a>        <span class="c1"># output dims determined by last layer</span>
</span><span id="FFnetwork-121"><a href="#FFnetwork-121"><span class="linenos">121</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">output_dims</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">output_dims</span>
</span><span id="FFnetwork-122"><a href="#FFnetwork-122"><span class="linenos">122</span></a>
</span><span id="FFnetwork-123"><a href="#FFnetwork-123"><span class="linenos">123</span></a>        <span class="c1"># Make scaffold output if requested</span>
</span><span id="FFnetwork-124"><a href="#FFnetwork-124"><span class="linenos">124</span></a>        <span class="k">if</span> <span class="n">scaffold_levels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FFnetwork-125"><a href="#FFnetwork-125"><span class="linenos">125</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># output last layer only</span>
</span><span id="FFnetwork-126"><a href="#FFnetwork-126"><span class="linenos">126</span></a>        <span class="k">else</span><span class="p">:</span> <span class="c1"># output specified layers concatenated together</span>
</span><span id="FFnetwork-127"><a href="#FFnetwork-127"><span class="linenos">127</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span> <span class="o">=</span> <span class="p">[</span><span class="o">*</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">)[</span><span class="n">scaffold_levels</span><span class="p">:]]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scaffold_levels</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">else</span> <span class="n">scaffold_levels</span>
</span><span id="FFnetwork-128"><a href="#FFnetwork-128"><span class="linenos">128</span></a>    <span class="c1"># END FFnetwork.__init__</span>
</span><span id="FFnetwork-129"><a href="#FFnetwork-129"><span class="linenos">129</span></a> 
</span><span id="FFnetwork-130"><a href="#FFnetwork-130"><span class="linenos">130</span></a>    <span class="nd">@property</span>
</span><span id="FFnetwork-131"><a href="#FFnetwork-131"><span class="linenos">131</span></a>    <span class="k">def</span> <span class="nf">num_outputs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="FFnetwork-132"><a href="#FFnetwork-132"><span class="linenos">132</span></a>        <span class="n">n</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="FFnetwork-133"><a href="#FFnetwork-133"><span class="linenos">133</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">:</span>
</span><span id="FFnetwork-134"><a href="#FFnetwork-134"><span class="linenos">134</span></a>            <span class="n">n</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">output_dims</span>
</span><span id="FFnetwork-135"><a href="#FFnetwork-135"><span class="linenos">135</span></a>        <span class="k">return</span> <span class="n">n</span>
</span><span id="FFnetwork-136"><a href="#FFnetwork-136"><span class="linenos">136</span></a>
</span><span id="FFnetwork-137"><a href="#FFnetwork-137"><span class="linenos">137</span></a>    <span class="k">def</span> <span class="nf">determine_input_dims</span><span class="p">(</span> <span class="bp">self</span><span class="p">,</span> <span class="n">input_dims_list</span><span class="p">,</span> <span class="n">ffnet_type</span><span class="o">=</span><span class="s1">&#39;normal&#39;</span> <span class="p">):</span>
</span><span id="FFnetwork-138"><a href="#FFnetwork-138"><span class="linenos">138</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnetwork-139"><a href="#FFnetwork-139"><span class="linenos">139</span></a><span class="sd">        Sets input_dims given network inputs. Can be overloaded depending on the network type. For this base class, there</span>
</span><span id="FFnetwork-140"><a href="#FFnetwork-140"><span class="linenos">140</span></a><span class="sd">        are two types of network input: external stimulus (xstim_n) or a list of internal (ffnet_in) networks:</span>
</span><span id="FFnetwork-141"><a href="#FFnetwork-141"><span class="linenos">141</span></a><span class="sd">            For external inputs, it just uses the passed-in input_dims</span>
</span><span id="FFnetwork-142"><a href="#FFnetwork-142"><span class="linenos">142</span></a><span class="sd">            For internal network inputs, it will concatenate inputs along the filter dimension, but MUST match other dims</span>
</span><span id="FFnetwork-143"><a href="#FFnetwork-143"><span class="linenos">143</span></a><span class="sd">        As currently designed, this can either external or internal, but not both</span>
</span><span id="FFnetwork-144"><a href="#FFnetwork-144"><span class="linenos">144</span></a><span class="sd">        </span>
</span><span id="FFnetwork-145"><a href="#FFnetwork-145"><span class="linenos">145</span></a><span class="sd">        This sets the following internal FFnetwork properties:</span>
</span><span id="FFnetwork-146"><a href="#FFnetwork-146"><span class="linenos">146</span></a><span class="sd">            self.input_dims</span>
</span><span id="FFnetwork-147"><a href="#FFnetwork-147"><span class="linenos">147</span></a><span class="sd">            self.input_dims_list</span>
</span><span id="FFnetwork-148"><a href="#FFnetwork-148"><span class="linenos">148</span></a><span class="sd">        and returns Boolean whether the passed in input dims are valid</span>
</span><span id="FFnetwork-149"><a href="#FFnetwork-149"><span class="linenos">149</span></a>
</span><span id="FFnetwork-150"><a href="#FFnetwork-150"><span class="linenos">150</span></a><span class="sd">        Args:</span>
</span><span id="FFnetwork-151"><a href="#FFnetwork-151"><span class="linenos">151</span></a><span class="sd">            input_dims_list (list): A list of input dimensions for each layer.</span>
</span><span id="FFnetwork-152"><a href="#FFnetwork-152"><span class="linenos">152</span></a><span class="sd">            ffnet_type (str): The type of the feedforward network.</span>
</span><span id="FFnetwork-153"><a href="#FFnetwork-153"><span class="linenos">153</span></a>
</span><span id="FFnetwork-154"><a href="#FFnetwork-154"><span class="linenos">154</span></a><span class="sd">        Returns:</span>
</span><span id="FFnetwork-155"><a href="#FFnetwork-155"><span class="linenos">155</span></a><span class="sd">            valid_input_dims (bool): Whether the passed in input dims are valid.</span>
</span><span id="FFnetwork-156"><a href="#FFnetwork-156"><span class="linenos">156</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FFnetwork-157"><a href="#FFnetwork-157"><span class="linenos">157</span></a>
</span><span id="FFnetwork-158"><a href="#FFnetwork-158"><span class="linenos">158</span></a>        <span class="n">valid_input_dims</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="FFnetwork-159"><a href="#FFnetwork-159"><span class="linenos">159</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffnets_in</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FFnetwork-160"><a href="#FFnetwork-160"><span class="linenos">160</span></a>            <span class="c1"># then external input (assume from one source)</span>
</span><span id="FFnetwork-161"><a href="#FFnetwork-161"><span class="linenos">161</span></a>            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_dims_list</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;FFnet constructor: Only one set of input dims can be specified.&quot;</span>
</span><span id="FFnetwork-162"><a href="#FFnetwork-162"><span class="linenos">162</span></a>            <span class="k">assert</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;FFnet constructor: External input dims must be specified.&quot;</span>
</span><span id="FFnetwork-163"><a href="#FFnetwork-163"><span class="linenos">163</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">input_dims</span> <span class="o">=</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="FFnetwork-164"><a href="#FFnetwork-164"><span class="linenos">164</span></a>        <span class="k">else</span><span class="p">:</span> 
</span><span id="FFnetwork-165"><a href="#FFnetwork-165"><span class="linenos">165</span></a>            <span class="n">num_input_networks</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ffnets_in</span><span class="p">)</span>
</span><span id="FFnetwork-166"><a href="#FFnetwork-166"><span class="linenos">166</span></a>            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_dims_list</span><span class="p">)</span> <span class="o">==</span> <span class="n">num_input_networks</span><span class="p">,</span> <span class="s1">&#39;Internal: misspecification of input_dims for FFnetwork.&#39;</span>
</span><span id="FFnetwork-167"><a href="#FFnetwork-167"><span class="linenos">167</span></a>
</span><span id="FFnetwork-168"><a href="#FFnetwork-168"><span class="linenos">168</span></a>            <span class="c1"># Go through the input dims of the other ffnetowrks to verify they are valid for the type of network</span>
</span><span id="FFnetwork-169"><a href="#FFnetwork-169"><span class="linenos">169</span></a>            <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_input_networks</span><span class="p">):</span>
</span><span id="FFnetwork-170"><a href="#FFnetwork-170"><span class="linenos">170</span></a>                <span class="k">if</span> <span class="n">ii</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="FFnetwork-171"><a href="#FFnetwork-171"><span class="linenos">171</span></a>                    <span class="n">num_cat_filters</span> <span class="o">=</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</span><span id="FFnetwork-172"><a href="#FFnetwork-172"><span class="linenos">172</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="FFnetwork-173"><a href="#FFnetwork-173"><span class="linenos">173</span></a>                    <span class="k">if</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="n">ii</span><span class="p">][</span><span class="mi">1</span><span class="p">:]</span> <span class="o">!=</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">:]:</span>
</span><span id="FFnetwork-174"><a href="#FFnetwork-174"><span class="linenos">174</span></a>                        <span class="k">if</span> <span class="n">ffnet_type</span> <span class="o">==</span> <span class="s1">&#39;add&#39;</span><span class="p">:</span>
</span><span id="FFnetwork-175"><a href="#FFnetwork-175"><span class="linenos">175</span></a>                            <span class="k">for</span> <span class="n">jj</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
</span><span id="FFnetwork-176"><a href="#FFnetwork-176"><span class="linenos">176</span></a>                                <span class="c1">#if (input_dims_list[ii][jj+1] &gt; 1) | (input_dims_list[0][jj+1] == 1):</span>
</span><span id="FFnetwork-177"><a href="#FFnetwork-177"><span class="linenos">177</span></a>                                <span class="k">if</span> <span class="p">(</span><span class="n">input_dims_list</span><span class="p">[</span><span class="n">ii</span><span class="p">][</span><span class="n">jj</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">input_dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">jj</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="FFnetwork-178"><a href="#FFnetwork-178"><span class="linenos">178</span></a>                                    <span class="n">valid_input_dims</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="FFnetwork-179"><a href="#FFnetwork-179"><span class="linenos">179</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="FFnetwork-180"><a href="#FFnetwork-180"><span class="linenos">180</span></a>                            <span class="n">valid_input_dims</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="FFnetwork-181"><a href="#FFnetwork-181"><span class="linenos">181</span></a>                    <span class="k">assert</span> <span class="n">valid_input_dims</span><span class="p">,</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;FFnet: invalid concatenation </span><span class="si">%d</span><span class="s2">:&quot;</span><span class="o">%</span><span class="n">ii</span><span class="p">,</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="n">ii</span><span class="p">][</span><span class="mi">1</span><span class="p">:],</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">:]</span> <span class="p">)</span>
</span><span id="FFnetwork-182"><a href="#FFnetwork-182"><span class="linenos">182</span></a>
</span><span id="FFnetwork-183"><a href="#FFnetwork-183"><span class="linenos">183</span></a>                    <span class="k">if</span> <span class="n">ffnet_type</span> <span class="o">==</span> <span class="s1">&#39;normal&#39;</span><span class="p">:</span> <span class="c1"># then inputs will be concatenated along &#39;filter&#39; dimension</span>
</span><span id="FFnetwork-184"><a href="#FFnetwork-184"><span class="linenos">184</span></a>                        <span class="n">num_cat_filters</span> <span class="o">+=</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="n">ii</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</span><span id="FFnetwork-185"><a href="#FFnetwork-185"><span class="linenos">185</span></a>                    <span class="k">elif</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="n">ii</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="FFnetwork-186"><a href="#FFnetwork-186"><span class="linenos">186</span></a>                        <span class="c1"># these are combined and input to first layer has same size as one input</span>
</span><span id="FFnetwork-187"><a href="#FFnetwork-187"><span class="linenos">187</span></a>                        <span class="k">assert</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="n">ii</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">num_cat_filters</span><span class="p">,</span> <span class="s1">&#39;Input dims must be the same for &#39;</span> <span class="o">+</span> <span class="n">ffnet_type</span> <span class="o">+</span> <span class="s1">&#39; ffnetwork&#39;</span>
</span><span id="FFnetwork-188"><a href="#FFnetwork-188"><span class="linenos">188</span></a>                    
</span><span id="FFnetwork-189"><a href="#FFnetwork-189"><span class="linenos">189</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">input_dims</span> <span class="o">=</span> <span class="p">[</span><span class="n">num_cat_filters</span><span class="p">]</span> <span class="o">+</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">:]</span>
</span><span id="FFnetwork-190"><a href="#FFnetwork-190"><span class="linenos">190</span></a>        
</span><span id="FFnetwork-191"><a href="#FFnetwork-191"><span class="linenos">191</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">input_dims_list</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">input_dims_list</span><span class="p">)</span>
</span><span id="FFnetwork-192"><a href="#FFnetwork-192"><span class="linenos">192</span></a>        <span class="k">return</span> <span class="n">valid_input_dims</span>
</span><span id="FFnetwork-193"><a href="#FFnetwork-193"><span class="linenos">193</span></a>    <span class="c1"># END FFnetwork.determine_input_dims</span>
</span><span id="FFnetwork-194"><a href="#FFnetwork-194"><span class="linenos">194</span></a>
</span><span id="FFnetwork-195"><a href="#FFnetwork-195"><span class="linenos">195</span></a>    <span class="k">def</span> <span class="nf">preprocess_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="FFnetwork-196"><a href="#FFnetwork-196"><span class="linenos">196</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnetwork-197"><a href="#FFnetwork-197"><span class="linenos">197</span></a><span class="sd">        Preprocess input to network.</span>
</span><span id="FFnetwork-198"><a href="#FFnetwork-198"><span class="linenos">198</span></a>
</span><span id="FFnetwork-199"><a href="#FFnetwork-199"><span class="linenos">199</span></a><span class="sd">        Args:</span>
</span><span id="FFnetwork-200"><a href="#FFnetwork-200"><span class="linenos">200</span></a><span class="sd">            inputs (list, torch.Tensor): The input to the network.</span>
</span><span id="FFnetwork-201"><a href="#FFnetwork-201"><span class="linenos">201</span></a>
</span><span id="FFnetwork-202"><a href="#FFnetwork-202"><span class="linenos">202</span></a><span class="sd">        Returns:</span>
</span><span id="FFnetwork-203"><a href="#FFnetwork-203"><span class="linenos">203</span></a><span class="sd">            x (torch.Tensor): The preprocessed input.</span>
</span><span id="FFnetwork-204"><a href="#FFnetwork-204"><span class="linenos">204</span></a>
</span><span id="FFnetwork-205"><a href="#FFnetwork-205"><span class="linenos">205</span></a><span class="sd">        Raises:</span>
</span><span id="FFnetwork-206"><a href="#FFnetwork-206"><span class="linenos">206</span></a><span class="sd">            ValueError: If no layers are defined.</span>
</span><span id="FFnetwork-207"><a href="#FFnetwork-207"><span class="linenos">207</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FFnetwork-208"><a href="#FFnetwork-208"><span class="linenos">208</span></a>
</span><span id="FFnetwork-209"><a href="#FFnetwork-209"><span class="linenos">209</span></a>        <span class="c1"># Combine network inputs (if relevant)</span>
</span><span id="FFnetwork-210"><a href="#FFnetwork-210"><span class="linenos">210</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="FFnetwork-211"><a href="#FFnetwork-211"><span class="linenos">211</span></a>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="FFnetwork-212"><a href="#FFnetwork-212"><span class="linenos">212</span></a>                <span class="n">x</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="FFnetwork-213"><a href="#FFnetwork-213"><span class="linenos">213</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="FFnetwork-214"><a href="#FFnetwork-214"><span class="linenos">214</span></a>                <span class="n">x</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">input_dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># this will allow for broadcasting</span>
</span><span id="FFnetwork-215"><a href="#FFnetwork-215"><span class="linenos">215</span></a>                <span class="n">nt</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="FFnetwork-216"><a href="#FFnetwork-216"><span class="linenos">216</span></a>                <span class="k">for</span> <span class="n">mm</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)):</span>
</span><span id="FFnetwork-217"><a href="#FFnetwork-217"><span class="linenos">217</span></a>                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">network_type</span> <span class="o">==</span> <span class="s1">&#39;normal&#39;</span><span class="p">:</span> <span class="c1"># concatentate inputs</span>
</span><span id="FFnetwork-218"><a href="#FFnetwork-218"><span class="linenos">218</span></a>                        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">inputs</span><span class="p">[</span><span class="n">mm</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">input_dims_list</span><span class="p">[</span><span class="n">mm</span><span class="p">])),</span> <span class="mi">1</span> <span class="p">)</span>
</span><span id="FFnetwork-219"><a href="#FFnetwork-219"><span class="linenos">219</span></a>                    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">network_type</span> <span class="o">==</span> <span class="s1">&#39;add&#39;</span><span class="p">:</span> <span class="c1"># add inputs</span>
</span><span id="FFnetwork-220"><a href="#FFnetwork-220"><span class="linenos">220</span></a>                        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">(</span> <span class="n">x</span><span class="p">,</span> <span class="n">inputs</span><span class="p">[</span><span class="n">mm</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">input_dims_list</span><span class="p">[</span><span class="n">mm</span><span class="p">])</span> <span class="p">)</span>
</span><span id="FFnetwork-221"><a href="#FFnetwork-221"><span class="linenos">221</span></a>                    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">network_type</span> <span class="o">==</span> <span class="s1">&#39;mult&#39;</span><span class="p">:</span> <span class="c1"># multiply: (input1) x (1+input2)</span>
</span><span id="FFnetwork-222"><a href="#FFnetwork-222"><span class="linenos">222</span></a>                        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span>
</span><span id="FFnetwork-223"><a href="#FFnetwork-223"><span class="linenos">223</span></a>                            <span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="n">mm</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">input_dims_list</span><span class="p">[</span><span class="n">mm</span><span class="p">]),</span> <span class="mf">1.0</span><span class="p">)</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span> <span class="p">)</span>
</span><span id="FFnetwork-224"><a href="#FFnetwork-224"><span class="linenos">224</span></a>                        <span class="c1"># Make sure multiplication is not negative</span>
</span><span id="FFnetwork-225"><a href="#FFnetwork-225"><span class="linenos">225</span></a>                <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="n">nt</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span><span id="FFnetwork-226"><a href="#FFnetwork-226"><span class="linenos">226</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FFnetwork-227"><a href="#FFnetwork-227"><span class="linenos">227</span></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">inputs</span>
</span><span id="FFnetwork-228"><a href="#FFnetwork-228"><span class="linenos">228</span></a>        <span class="k">return</span> <span class="n">x</span>
</span><span id="FFnetwork-229"><a href="#FFnetwork-229"><span class="linenos">229</span></a>
</span><span id="FFnetwork-230"><a href="#FFnetwork-230"><span class="linenos">230</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="FFnetwork-231"><a href="#FFnetwork-231"><span class="linenos">231</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnetwork-232"><a href="#FFnetwork-232"><span class="linenos">232</span></a><span class="sd">        Forward pass through the network.</span>
</span><span id="FFnetwork-233"><a href="#FFnetwork-233"><span class="linenos">233</span></a>
</span><span id="FFnetwork-234"><a href="#FFnetwork-234"><span class="linenos">234</span></a><span class="sd">        Args:</span>
</span><span id="FFnetwork-235"><a href="#FFnetwork-235"><span class="linenos">235</span></a><span class="sd">            inputs (list, torch.Tensor): The input to the network.</span>
</span><span id="FFnetwork-236"><a href="#FFnetwork-236"><span class="linenos">236</span></a>
</span><span id="FFnetwork-237"><a href="#FFnetwork-237"><span class="linenos">237</span></a><span class="sd">        Returns:</span>
</span><span id="FFnetwork-238"><a href="#FFnetwork-238"><span class="linenos">238</span></a><span class="sd">            x (torch.Tensor): The output of the network.</span>
</span><span id="FFnetwork-239"><a href="#FFnetwork-239"><span class="linenos">239</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FFnetwork-240"><a href="#FFnetwork-240"><span class="linenos">240</span></a>
</span><span id="FFnetwork-241"><a href="#FFnetwork-241"><span class="linenos">241</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FFnetwork-242"><a href="#FFnetwork-242"><span class="linenos">242</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;FFnet: no layers defined.&quot;</span><span class="p">)</span>
</span><span id="FFnetwork-243"><a href="#FFnetwork-243"><span class="linenos">243</span></a>        
</span><span id="FFnetwork-244"><a href="#FFnetwork-244"><span class="linenos">244</span></a>        <span class="n">out</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># returned </span>
</span><span id="FFnetwork-245"><a href="#FFnetwork-245"><span class="linenos">245</span></a>
</span><span id="FFnetwork-246"><a href="#FFnetwork-246"><span class="linenos">246</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess_input</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="FFnetwork-247"><a href="#FFnetwork-247"><span class="linenos">247</span></a>
</span><span id="FFnetwork-248"><a href="#FFnetwork-248"><span class="linenos">248</span></a>        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
</span><span id="FFnetwork-249"><a href="#FFnetwork-249"><span class="linenos">249</span></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="FFnetwork-250"><a href="#FFnetwork-250"><span class="linenos">250</span></a>            <span class="c1">#out.append(x)</span>
</span><span id="FFnetwork-251"><a href="#FFnetwork-251"><span class="linenos">251</span></a>
</span><span id="FFnetwork-252"><a href="#FFnetwork-252"><span class="linenos">252</span></a>        <span class="k">return</span> <span class="n">x</span>
</span><span id="FFnetwork-253"><a href="#FFnetwork-253"><span class="linenos">253</span></a>        <span class="c1">#return torch.cat([out[ind] for ind in self.scaffold_levels], dim=1)</span>
</span><span id="FFnetwork-254"><a href="#FFnetwork-254"><span class="linenos">254</span></a>    <span class="c1"># END FFnetwork.forward</span>
</span><span id="FFnetwork-255"><a href="#FFnetwork-255"><span class="linenos">255</span></a>
</span><span id="FFnetwork-256"><a href="#FFnetwork-256"><span class="linenos">256</span></a>    <span class="k">def</span> <span class="nf">__reg_setup_ffnet</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reg_params</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="FFnetwork-257"><a href="#FFnetwork-257"><span class="linenos">257</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnetwork-258"><a href="#FFnetwork-258"><span class="linenos">258</span></a><span class="sd">        Sets up the regularization params for the network.</span>
</span><span id="FFnetwork-259"><a href="#FFnetwork-259"><span class="linenos">259</span></a>
</span><span id="FFnetwork-260"><a href="#FFnetwork-260"><span class="linenos">260</span></a><span class="sd">        Args:</span>
</span><span id="FFnetwork-261"><a href="#FFnetwork-261"><span class="linenos">261</span></a><span class="sd">            reg_params (dict): The regularization parameters to use.</span>
</span><span id="FFnetwork-262"><a href="#FFnetwork-262"><span class="linenos">262</span></a>
</span><span id="FFnetwork-263"><a href="#FFnetwork-263"><span class="linenos">263</span></a><span class="sd">        Returns:</span>
</span><span id="FFnetwork-264"><a href="#FFnetwork-264"><span class="linenos">264</span></a><span class="sd">            layer_reg_list (list): The regularization parameters for each layer.</span>
</span><span id="FFnetwork-265"><a href="#FFnetwork-265"><span class="linenos">265</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FFnetwork-266"><a href="#FFnetwork-266"><span class="linenos">266</span></a>
</span><span id="FFnetwork-267"><a href="#FFnetwork-267"><span class="linenos">267</span></a>        <span class="c1"># Set all default values to none</span>
</span><span id="FFnetwork-268"><a href="#FFnetwork-268"><span class="linenos">268</span></a>        <span class="n">num_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_list</span><span class="p">)</span>
</span><span id="FFnetwork-269"><a href="#FFnetwork-269"><span class="linenos">269</span></a>        <span class="n">layer_reg_list</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="FFnetwork-270"><a href="#FFnetwork-270"><span class="linenos">270</span></a>        <span class="k">for</span> <span class="n">nn</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">):</span>
</span><span id="FFnetwork-271"><a href="#FFnetwork-271"><span class="linenos">271</span></a>            <span class="c1">#layer_reg_list.append(deepcopy(_allowed_reg_types))</span>
</span><span id="FFnetwork-272"><a href="#FFnetwork-272"><span class="linenos">272</span></a>            <span class="n">layer_reg_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">deepcopy</span><span class="p">({}))</span>  <span class="c1"># only put regs in that are there</span>
</span><span id="FFnetwork-273"><a href="#FFnetwork-273"><span class="linenos">273</span></a>
</span><span id="FFnetwork-274"><a href="#FFnetwork-274"><span class="linenos">274</span></a>        <span class="c1"># Set specific regularization</span>
</span><span id="FFnetwork-275"><a href="#FFnetwork-275"><span class="linenos">275</span></a>        <span class="k">if</span> <span class="n">reg_params</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FFnetwork-276"><a href="#FFnetwork-276"><span class="linenos">276</span></a>            <span class="k">for</span> <span class="n">kk</span><span class="p">,</span> <span class="n">vv</span> <span class="ow">in</span> <span class="n">reg_params</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="FFnetwork-277"><a href="#FFnetwork-277"><span class="linenos">277</span></a>                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">vv</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="FFnetwork-278"><a href="#FFnetwork-278"><span class="linenos">278</span></a>                    <span class="n">vv</span> <span class="o">=</span> <span class="p">[</span><span class="n">vv</span><span class="p">]</span>
</span><span id="FFnetwork-279"><a href="#FFnetwork-279"><span class="linenos">279</span></a>                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">vv</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">num_layers</span><span class="p">:</span>
</span><span id="FFnetwork-280"><a href="#FFnetwork-280"><span class="linenos">280</span></a>                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Warning: reg params too long for&quot;</span><span class="p">,</span> <span class="n">kk</span><span class="p">)</span>
</span><span id="FFnetwork-281"><a href="#FFnetwork-281"><span class="linenos">281</span></a>                <span class="k">for</span> <span class="n">nn</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">num_layers</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vv</span><span class="p">))):</span>
</span><span id="FFnetwork-282"><a href="#FFnetwork-282"><span class="linenos">282</span></a>                    <span class="n">layer_reg_list</span><span class="p">[</span><span class="n">nn</span><span class="p">][</span><span class="n">kk</span><span class="p">]</span> <span class="o">=</span> <span class="n">vv</span><span class="p">[</span><span class="n">nn</span><span class="p">]</span>
</span><span id="FFnetwork-283"><a href="#FFnetwork-283"><span class="linenos">283</span></a>        <span class="k">return</span> <span class="n">layer_reg_list</span>
</span><span id="FFnetwork-284"><a href="#FFnetwork-284"><span class="linenos">284</span></a>
</span><span id="FFnetwork-285"><a href="#FFnetwork-285"><span class="linenos">285</span></a>    <span class="k">def</span> <span class="nf">prepare_regularization</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="FFnetwork-286"><a href="#FFnetwork-286"><span class="linenos">286</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnetwork-287"><a href="#FFnetwork-287"><span class="linenos">287</span></a><span class="sd">        Makes regularization modules with current requested values.</span>
</span><span id="FFnetwork-288"><a href="#FFnetwork-288"><span class="linenos">288</span></a><span class="sd">        This is done immediately before training, because it can change during training and tuning.</span>
</span><span id="FFnetwork-289"><a href="#FFnetwork-289"><span class="linenos">289</span></a>
</span><span id="FFnetwork-290"><a href="#FFnetwork-290"><span class="linenos">290</span></a><span class="sd">        Args:</span>
</span><span id="FFnetwork-291"><a href="#FFnetwork-291"><span class="linenos">291</span></a><span class="sd">            device (str, optional): The device to use. Defaults to None.</span>
</span><span id="FFnetwork-292"><a href="#FFnetwork-292"><span class="linenos">292</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FFnetwork-293"><a href="#FFnetwork-293"><span class="linenos">293</span></a>
</span><span id="FFnetwork-294"><a href="#FFnetwork-294"><span class="linenos">294</span></a>        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
</span><span id="FFnetwork-295"><a href="#FFnetwork-295"><span class="linenos">295</span></a>            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;reg&#39;</span><span class="p">):</span>
</span><span id="FFnetwork-296"><a href="#FFnetwork-296"><span class="linenos">296</span></a>                <span class="n">layer</span><span class="o">.</span><span class="n">reg</span><span class="o">.</span><span class="n">build_reg_modules</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span><span id="FFnetwork-297"><a href="#FFnetwork-297"><span class="linenos">297</span></a>            
</span><span id="FFnetwork-298"><a href="#FFnetwork-298"><span class="linenos">298</span></a>    <span class="k">def</span> <span class="nf">compute_reg_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="FFnetwork-299"><a href="#FFnetwork-299"><span class="linenos">299</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnetwork-300"><a href="#FFnetwork-300"><span class="linenos">300</span></a><span class="sd">        Computes the regularization loss.</span>
</span><span id="FFnetwork-301"><a href="#FFnetwork-301"><span class="linenos">301</span></a>
</span><span id="FFnetwork-302"><a href="#FFnetwork-302"><span class="linenos">302</span></a><span class="sd">        Args:</span>
</span><span id="FFnetwork-303"><a href="#FFnetwork-303"><span class="linenos">303</span></a><span class="sd">            None</span>
</span><span id="FFnetwork-304"><a href="#FFnetwork-304"><span class="linenos">304</span></a>
</span><span id="FFnetwork-305"><a href="#FFnetwork-305"><span class="linenos">305</span></a><span class="sd">        Returns:</span>
</span><span id="FFnetwork-306"><a href="#FFnetwork-306"><span class="linenos">306</span></a><span class="sd">            rloss (torch.Tensor): The regularization loss.</span>
</span><span id="FFnetwork-307"><a href="#FFnetwork-307"><span class="linenos">307</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FFnetwork-308"><a href="#FFnetwork-308"><span class="linenos">308</span></a>
</span><span id="FFnetwork-309"><a href="#FFnetwork-309"><span class="linenos">309</span></a>        <span class="n">rloss</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="FFnetwork-310"><a href="#FFnetwork-310"><span class="linenos">310</span></a>        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
</span><span id="FFnetwork-311"><a href="#FFnetwork-311"><span class="linenos">311</span></a>            <span class="n">rloss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">compute_reg_loss</span><span class="p">())</span>
</span><span id="FFnetwork-312"><a href="#FFnetwork-312"><span class="linenos">312</span></a>        <span class="k">return</span> <span class="n">reduce</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">,</span> <span class="n">rloss</span><span class="p">)</span>
</span><span id="FFnetwork-313"><a href="#FFnetwork-313"><span class="linenos">313</span></a>
</span><span id="FFnetwork-314"><a href="#FFnetwork-314"><span class="linenos">314</span></a>    <span class="k">def</span> <span class="nf">list_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer_target</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="FFnetwork-315"><a href="#FFnetwork-315"><span class="linenos">315</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnetwork-316"><a href="#FFnetwork-316"><span class="linenos">316</span></a><span class="sd">        Lists the parameters for the network.</span>
</span><span id="FFnetwork-317"><a href="#FFnetwork-317"><span class="linenos">317</span></a>
</span><span id="FFnetwork-318"><a href="#FFnetwork-318"><span class="linenos">318</span></a><span class="sd">        Args:</span>
</span><span id="FFnetwork-319"><a href="#FFnetwork-319"><span class="linenos">319</span></a><span class="sd">            layer_target (int, optional): The layer to list the parameters for. Defaults to None.</span>
</span><span id="FFnetwork-320"><a href="#FFnetwork-320"><span class="linenos">320</span></a>
</span><span id="FFnetwork-321"><a href="#FFnetwork-321"><span class="linenos">321</span></a><span class="sd">        Returns:</span>
</span><span id="FFnetwork-322"><a href="#FFnetwork-322"><span class="linenos">322</span></a><span class="sd">            None</span>
</span><span id="FFnetwork-323"><a href="#FFnetwork-323"><span class="linenos">323</span></a>
</span><span id="FFnetwork-324"><a href="#FFnetwork-324"><span class="linenos">324</span></a><span class="sd">        Raises:</span>
</span><span id="FFnetwork-325"><a href="#FFnetwork-325"><span class="linenos">325</span></a><span class="sd">            AssertionError: If the layer target is invalid.</span>
</span><span id="FFnetwork-326"><a href="#FFnetwork-326"><span class="linenos">326</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FFnetwork-327"><a href="#FFnetwork-327"><span class="linenos">327</span></a>
</span><span id="FFnetwork-328"><a href="#FFnetwork-328"><span class="linenos">328</span></a>        <span class="k">if</span> <span class="n">layer_target</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FFnetwork-329"><a href="#FFnetwork-329"><span class="linenos">329</span></a>            <span class="n">layer_target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;int32&#39;</span><span class="p">)</span>
</span><span id="FFnetwork-330"><a href="#FFnetwork-330"><span class="linenos">330</span></a>        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer_target</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="FFnetwork-331"><a href="#FFnetwork-331"><span class="linenos">331</span></a>            <span class="n">layer_target</span> <span class="o">=</span> <span class="p">[</span><span class="n">layer_target</span><span class="p">]</span>
</span><span id="FFnetwork-332"><a href="#FFnetwork-332"><span class="linenos">332</span></a>        <span class="k">for</span> <span class="n">nn</span> <span class="ow">in</span> <span class="n">layer_target</span><span class="p">:</span>
</span><span id="FFnetwork-333"><a href="#FFnetwork-333"><span class="linenos">333</span></a>            <span class="k">assert</span> <span class="n">nn</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">),</span> <span class="s1">&#39;  Invalid layer </span><span class="si">%d</span><span class="s1">.&#39;</span><span class="o">%</span><span class="n">nn</span>
</span><span id="FFnetwork-334"><a href="#FFnetwork-334"><span class="linenos">334</span></a>            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  Layer </span><span class="si">%d</span><span class="s2">:&quot;</span><span class="o">%</span><span class="n">nn</span><span class="p">)</span>
</span><span id="FFnetwork-335"><a href="#FFnetwork-335"><span class="linenos">335</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">nn</span><span class="p">]</span><span class="o">.</span><span class="n">list_parameters</span><span class="p">()</span>
</span><span id="FFnetwork-336"><a href="#FFnetwork-336"><span class="linenos">336</span></a>
</span><span id="FFnetwork-337"><a href="#FFnetwork-337"><span class="linenos">337</span></a>    <span class="k">def</span> <span class="nf">set_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer_target</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">val</span><span class="o">=</span><span class="kc">None</span> <span class="p">):</span>
</span><span id="FFnetwork-338"><a href="#FFnetwork-338"><span class="linenos">338</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnetwork-339"><a href="#FFnetwork-339"><span class="linenos">339</span></a><span class="sd">        Sets the parameters for the listed layer or for all layers.</span>
</span><span id="FFnetwork-340"><a href="#FFnetwork-340"><span class="linenos">340</span></a>
</span><span id="FFnetwork-341"><a href="#FFnetwork-341"><span class="linenos">341</span></a><span class="sd">        Args:</span>
</span><span id="FFnetwork-342"><a href="#FFnetwork-342"><span class="linenos">342</span></a><span class="sd">            layer_target (int, optional): The layer to set the parameters for. Defaults to None.</span>
</span><span id="FFnetwork-343"><a href="#FFnetwork-343"><span class="linenos">343</span></a><span class="sd">            name (str): The name of the parameter.</span>
</span><span id="FFnetwork-344"><a href="#FFnetwork-344"><span class="linenos">344</span></a><span class="sd">            val (bool): The value to set the parameter to.</span>
</span><span id="FFnetwork-345"><a href="#FFnetwork-345"><span class="linenos">345</span></a>
</span><span id="FFnetwork-346"><a href="#FFnetwork-346"><span class="linenos">346</span></a><span class="sd">        Returns:</span>
</span><span id="FFnetwork-347"><a href="#FFnetwork-347"><span class="linenos">347</span></a><span class="sd">            None</span>
</span><span id="FFnetwork-348"><a href="#FFnetwork-348"><span class="linenos">348</span></a>
</span><span id="FFnetwork-349"><a href="#FFnetwork-349"><span class="linenos">349</span></a><span class="sd">        Raises:</span>
</span><span id="FFnetwork-350"><a href="#FFnetwork-350"><span class="linenos">350</span></a><span class="sd">            AssertionError: If the layer target is invalid.</span>
</span><span id="FFnetwork-351"><a href="#FFnetwork-351"><span class="linenos">351</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FFnetwork-352"><a href="#FFnetwork-352"><span class="linenos">352</span></a>        <span class="k">if</span> <span class="n">layer_target</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FFnetwork-353"><a href="#FFnetwork-353"><span class="linenos">353</span></a>            <span class="n">layer_target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;int32&#39;</span><span class="p">)</span>
</span><span id="FFnetwork-354"><a href="#FFnetwork-354"><span class="linenos">354</span></a>        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer_target</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="FFnetwork-355"><a href="#FFnetwork-355"><span class="linenos">355</span></a>            <span class="n">layer_target</span> <span class="o">=</span> <span class="p">[</span><span class="n">layer_target</span><span class="p">]</span>
</span><span id="FFnetwork-356"><a href="#FFnetwork-356"><span class="linenos">356</span></a>        <span class="k">for</span> <span class="n">nn</span> <span class="ow">in</span> <span class="n">layer_target</span><span class="p">:</span>
</span><span id="FFnetwork-357"><a href="#FFnetwork-357"><span class="linenos">357</span></a>            <span class="k">assert</span> <span class="n">nn</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">),</span> <span class="s1">&#39;  Invalid layer </span><span class="si">%d</span><span class="s1">.&#39;</span><span class="o">%</span><span class="n">nn</span>
</span><span id="FFnetwork-358"><a href="#FFnetwork-358"><span class="linenos">358</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">nn</span><span class="p">]</span><span class="o">.</span><span class="n">set_parameters</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">val</span><span class="o">=</span><span class="n">val</span><span class="p">)</span>
</span><span id="FFnetwork-359"><a href="#FFnetwork-359"><span class="linenos">359</span></a>
</span><span id="FFnetwork-360"><a href="#FFnetwork-360"><span class="linenos">360</span></a>    <span class="k">def</span> <span class="nf">set_reg_val</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reg_type</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reg_val</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">layer_target</span><span class="o">=</span><span class="kc">None</span> <span class="p">):</span>
</span><span id="FFnetwork-361"><a href="#FFnetwork-361"><span class="linenos">361</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnetwork-362"><a href="#FFnetwork-362"><span class="linenos">362</span></a><span class="sd">        Set reg_values for listed layer or for all layers.</span>
</span><span id="FFnetwork-363"><a href="#FFnetwork-363"><span class="linenos">363</span></a><span class="sd">        </span>
</span><span id="FFnetwork-364"><a href="#FFnetwork-364"><span class="linenos">364</span></a><span class="sd">        Args:</span>
</span><span id="FFnetwork-365"><a href="#FFnetwork-365"><span class="linenos">365</span></a><span class="sd">            reg_type (str): The type of regularization to set.</span>
</span><span id="FFnetwork-366"><a href="#FFnetwork-366"><span class="linenos">366</span></a><span class="sd">            reg_val (float): The value to set the regularization to.</span>
</span><span id="FFnetwork-367"><a href="#FFnetwork-367"><span class="linenos">367</span></a><span class="sd">            layer_target (int, optional): The layer to set the regularization for. Defaults to None.</span>
</span><span id="FFnetwork-368"><a href="#FFnetwork-368"><span class="linenos">368</span></a>
</span><span id="FFnetwork-369"><a href="#FFnetwork-369"><span class="linenos">369</span></a><span class="sd">        Returns:</span>
</span><span id="FFnetwork-370"><a href="#FFnetwork-370"><span class="linenos">370</span></a><span class="sd">            None</span>
</span><span id="FFnetwork-371"><a href="#FFnetwork-371"><span class="linenos">371</span></a>
</span><span id="FFnetwork-372"><a href="#FFnetwork-372"><span class="linenos">372</span></a><span class="sd">        Raises:</span>
</span><span id="FFnetwork-373"><a href="#FFnetwork-373"><span class="linenos">373</span></a><span class="sd">            AssertionError: If the layer target is invalid.</span>
</span><span id="FFnetwork-374"><a href="#FFnetwork-374"><span class="linenos">374</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FFnetwork-375"><a href="#FFnetwork-375"><span class="linenos">375</span></a>        <span class="k">if</span> <span class="n">layer_target</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FFnetwork-376"><a href="#FFnetwork-376"><span class="linenos">376</span></a>            <span class="n">layer_target</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="FFnetwork-377"><a href="#FFnetwork-377"><span class="linenos">377</span></a>        <span class="k">assert</span> <span class="n">layer_target</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">),</span> <span class="s2">&quot;layer target too large (max = </span><span class="si">%d</span><span class="s2">)&quot;</span><span class="o">%</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span>
</span><span id="FFnetwork-378"><a href="#FFnetwork-378"><span class="linenos">378</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">layer_target</span><span class="p">]</span><span class="o">.</span><span class="n">set_reg_val</span><span class="p">(</span> <span class="n">reg_type</span><span class="o">=</span><span class="n">reg_type</span><span class="p">,</span> <span class="n">reg_val</span><span class="o">=</span><span class="n">reg_val</span> <span class="p">)</span>
</span><span id="FFnetwork-379"><a href="#FFnetwork-379"><span class="linenos">379</span></a>
</span><span id="FFnetwork-380"><a href="#FFnetwork-380"><span class="linenos">380</span></a>    <span class="k">def</span> <span class="nf">plot_filters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer_target</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="FFnetwork-381"><a href="#FFnetwork-381"><span class="linenos">381</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnetwork-382"><a href="#FFnetwork-382"><span class="linenos">382</span></a><span class="sd">        Plots the filters for the listed layer.</span>
</span><span id="FFnetwork-383"><a href="#FFnetwork-383"><span class="linenos">383</span></a>
</span><span id="FFnetwork-384"><a href="#FFnetwork-384"><span class="linenos">384</span></a><span class="sd">        Args:</span>
</span><span id="FFnetwork-385"><a href="#FFnetwork-385"><span class="linenos">385</span></a><span class="sd">            layer_target (int, optional): The layer to plot the filters for. Defaults to 0.</span>
</span><span id="FFnetwork-386"><a href="#FFnetwork-386"><span class="linenos">386</span></a><span class="sd">            **kwargs: Additional keyword arguments.</span>
</span><span id="FFnetwork-387"><a href="#FFnetwork-387"><span class="linenos">387</span></a>
</span><span id="FFnetwork-388"><a href="#FFnetwork-388"><span class="linenos">388</span></a><span class="sd">        Returns:</span>
</span><span id="FFnetwork-389"><a href="#FFnetwork-389"><span class="linenos">389</span></a><span class="sd">            None</span>
</span><span id="FFnetwork-390"><a href="#FFnetwork-390"><span class="linenos">390</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FFnetwork-391"><a href="#FFnetwork-391"><span class="linenos">391</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">layer_target</span><span class="p">]</span><span class="o">.</span><span class="n">plot_filters</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="FFnetwork-392"><a href="#FFnetwork-392"><span class="linenos">392</span></a>
</span><span id="FFnetwork-393"><a href="#FFnetwork-393"><span class="linenos">393</span></a>    <span class="k">def</span> <span class="nf">get_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer_target</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="FFnetwork-394"><a href="#FFnetwork-394"><span class="linenos">394</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnetwork-395"><a href="#FFnetwork-395"><span class="linenos">395</span></a><span class="sd">        Passed down to layer call, with optional arguments conveyed.</span>
</span><span id="FFnetwork-396"><a href="#FFnetwork-396"><span class="linenos">396</span></a><span class="sd">        </span>
</span><span id="FFnetwork-397"><a href="#FFnetwork-397"><span class="linenos">397</span></a><span class="sd">        Args:</span>
</span><span id="FFnetwork-398"><a href="#FFnetwork-398"><span class="linenos">398</span></a><span class="sd">            layer_target (int): The layer to get the weights for.</span>
</span><span id="FFnetwork-399"><a href="#FFnetwork-399"><span class="linenos">399</span></a><span class="sd">            **kwargs: Additional keyword arguments.</span>
</span><span id="FFnetwork-400"><a href="#FFnetwork-400"><span class="linenos">400</span></a>
</span><span id="FFnetwork-401"><a href="#FFnetwork-401"><span class="linenos">401</span></a><span class="sd">        Returns:</span>
</span><span id="FFnetwork-402"><a href="#FFnetwork-402"><span class="linenos">402</span></a><span class="sd">            The weights for the specified layer.</span>
</span><span id="FFnetwork-403"><a href="#FFnetwork-403"><span class="linenos">403</span></a>
</span><span id="FFnetwork-404"><a href="#FFnetwork-404"><span class="linenos">404</span></a><span class="sd">        Raises:</span>
</span><span id="FFnetwork-405"><a href="#FFnetwork-405"><span class="linenos">405</span></a><span class="sd">            AssertionError: If the layer target is invalid.</span>
</span><span id="FFnetwork-406"><a href="#FFnetwork-406"><span class="linenos">406</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FFnetwork-407"><a href="#FFnetwork-407"><span class="linenos">407</span></a>        <span class="k">assert</span> <span class="n">layer_target</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">),</span> <span class="s2">&quot;Invalid layer_target </span><span class="si">%d</span><span class="s2">&quot;</span><span class="o">%</span><span class="n">layer_target</span>
</span><span id="FFnetwork-408"><a href="#FFnetwork-408"><span class="linenos">408</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">layer_target</span><span class="p">]</span><span class="o">.</span><span class="n">get_weights</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="FFnetwork-409"><a href="#FFnetwork-409"><span class="linenos">409</span></a>
</span><span id="FFnetwork-410"><a href="#FFnetwork-410"><span class="linenos">410</span></a>    <span class="nd">@classmethod</span>
</span><span id="FFnetwork-411"><a href="#FFnetwork-411"><span class="linenos">411</span></a>    <span class="k">def</span> <span class="nf">ffnet_dict</span><span class="p">(</span> <span class="bp">cls</span><span class="p">,</span> <span class="n">layer_list</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">xstim_n</span> <span class="o">=</span><span class="s1">&#39;stim&#39;</span><span class="p">,</span> <span class="n">ffnet_n</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ffnet_type</span><span class="o">=</span><span class="s1">&#39;normal&#39;</span><span class="p">,</span> <span class="n">scaffold_levels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_lags_out</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="FFnetwork-412"><a href="#FFnetwork-412"><span class="linenos">412</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnetwork-413"><a href="#FFnetwork-413"><span class="linenos">413</span></a><span class="sd">        Returns a dictionary of the feedforward network.</span>
</span><span id="FFnetwork-414"><a href="#FFnetwork-414"><span class="linenos">414</span></a>
</span><span id="FFnetwork-415"><a href="#FFnetwork-415"><span class="linenos">415</span></a><span class="sd">        Args:</span>
</span><span id="FFnetwork-416"><a href="#FFnetwork-416"><span class="linenos">416</span></a><span class="sd">            layer_list (list): A list of dictionaries representing the layers of the network.</span>
</span><span id="FFnetwork-417"><a href="#FFnetwork-417"><span class="linenos">417</span></a><span class="sd">            xstim_n (str): The name of the stimulus input.</span>
</span><span id="FFnetwork-418"><a href="#FFnetwork-418"><span class="linenos">418</span></a><span class="sd">            ffnet_n (list): A list of feedforward networks.</span>
</span><span id="FFnetwork-419"><a href="#FFnetwork-419"><span class="linenos">419</span></a><span class="sd">            ffnet_type (str): The type of the feedforward network.</span>
</span><span id="FFnetwork-420"><a href="#FFnetwork-420"><span class="linenos">420</span></a><span class="sd">            scaffold_levels (list): A list of scaffold levels.</span>
</span><span id="FFnetwork-421"><a href="#FFnetwork-421"><span class="linenos">421</span></a><span class="sd">            num_lags_out (int): The number of lags out.</span>
</span><span id="FFnetwork-422"><a href="#FFnetwork-422"><span class="linenos">422</span></a><span class="sd">            **kwargs: Additional keyword arguments.</span>
</span><span id="FFnetwork-423"><a href="#FFnetwork-423"><span class="linenos">423</span></a>
</span><span id="FFnetwork-424"><a href="#FFnetwork-424"><span class="linenos">424</span></a><span class="sd">        Returns:</span>
</span><span id="FFnetwork-425"><a href="#FFnetwork-425"><span class="linenos">425</span></a><span class="sd">            ffnet_dict (dict): The dictionary of the feedforward network.</span>
</span><span id="FFnetwork-426"><a href="#FFnetwork-426"><span class="linenos">426</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FFnetwork-427"><a href="#FFnetwork-427"><span class="linenos">427</span></a>        <span class="k">return</span> <span class="p">{</span>
</span><span id="FFnetwork-428"><a href="#FFnetwork-428"><span class="linenos">428</span></a>            <span class="s1">&#39;ffnet_type&#39;</span><span class="p">:</span> <span class="n">ffnet_type</span><span class="p">,</span>
</span><span id="FFnetwork-429"><a href="#FFnetwork-429"><span class="linenos">429</span></a>            <span class="s1">&#39;xstim_n&#39;</span><span class="p">:</span><span class="n">xstim_n</span><span class="p">,</span> <span class="s1">&#39;ffnet_n&#39;</span><span class="p">:</span><span class="n">ffnet_n</span><span class="p">,</span>
</span><span id="FFnetwork-430"><a href="#FFnetwork-430"><span class="linenos">430</span></a>            <span class="s1">&#39;layer_list&#39;</span><span class="p">:</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">layer_list</span><span class="p">),</span>
</span><span id="FFnetwork-431"><a href="#FFnetwork-431"><span class="linenos">431</span></a>            <span class="s1">&#39;scaffold_levels&#39;</span><span class="p">:</span> <span class="n">scaffold_levels</span><span class="p">,</span>
</span><span id="FFnetwork-432"><a href="#FFnetwork-432"><span class="linenos">432</span></a>            <span class="s1">&#39;num_lags_out&#39;</span><span class="p">:</span> <span class="n">num_lags_out</span><span class="p">}</span>
</span><span id="FFnetwork-433"><a href="#FFnetwork-433"><span class="linenos">433</span></a>    <span class="c1"># END FFnetwork class</span>
</span></pre></div>


            <div class="docstring"><p>Initializes an instance of the network.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>layer_list (list, optional):</strong>  A list of dictionaries representing the layers of the network. Defaults to None.</li>
<li><strong>ffnet_type (str, optional):</strong>  The type of the feedforward network. Defaults to 'normal'.</li>
<li><strong>xstim_n (str, optional):</strong>  The name of the stimulus input. Defaults to 'stim'.</li>
<li><strong>ffnet_n (list, optional):</strong>  A list of feedforward networks. Defaults to None.</li>
<li><strong>input_dims_list (list, optional):</strong>  A list of input dimensions for each layer. Defaults to None.</li>
<li><strong>reg_list (list, optional):</strong>  A list of regularization parameters. Defaults to None.</li>
<li><strong>scaffold_levels (list, optional):</strong>  A list of scaffold levels. Defaults to None.</li>
<li><strong>**kwargs:</strong>  Additional keyword arguments.</li>
</ul>

<h6 id="raises">Raises:</h6>

<ul>
<li><strong>AssertionError:</strong>  If layer_list is not provided.</li>
</ul>
</div>


                            <div id="FFnetwork.__init__" class="classattr">
                                        <input id="FFnetwork.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">FFnetwork</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">layer_list</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">ffnet_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;normal&#39;</span>,</span><span class="param">	<span class="n">xstim_n</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;stim&#39;</span>,</span><span class="param">	<span class="n">ffnet_n</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">input_dims_list</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">reg_list</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="n">scaffold_levels</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="kc">None</span>,</span><span class="param">	<span class="o">**</span><span class="n">kwargs</span></span>)</span>

                <label class="view-source-button" for="FFnetwork.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FFnetwork.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FFnetwork.__init__-64"><a href="#FFnetwork.__init__-64"><span class="linenos"> 64</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
</span><span id="FFnetwork.__init__-65"><a href="#FFnetwork.__init__-65"><span class="linenos"> 65</span></a>                <span class="n">layer_list</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="FFnetwork.__init__-66"><a href="#FFnetwork.__init__-66"><span class="linenos"> 66</span></a>                <span class="n">ffnet_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;normal&#39;</span><span class="p">,</span>
</span><span id="FFnetwork.__init__-67"><a href="#FFnetwork.__init__-67"><span class="linenos"> 67</span></a>                <span class="n">xstim_n</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;stim&#39;</span><span class="p">,</span>
</span><span id="FFnetwork.__init__-68"><a href="#FFnetwork.__init__-68"><span class="linenos"> 68</span></a>                <span class="n">ffnet_n</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="FFnetwork.__init__-69"><a href="#FFnetwork.__init__-69"><span class="linenos"> 69</span></a>                <span class="n">input_dims_list</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="FFnetwork.__init__-70"><a href="#FFnetwork.__init__-70"><span class="linenos"> 70</span></a>                <span class="n">reg_list</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="FFnetwork.__init__-71"><a href="#FFnetwork.__init__-71"><span class="linenos"> 71</span></a>                <span class="n">scaffold_levels</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="FFnetwork.__init__-72"><a href="#FFnetwork.__init__-72"><span class="linenos"> 72</span></a>                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
</span><span id="FFnetwork.__init__-73"><a href="#FFnetwork.__init__-73"><span class="linenos"> 73</span></a>                <span class="p">):</span>
</span><span id="FFnetwork.__init__-74"><a href="#FFnetwork.__init__-74"><span class="linenos"> 74</span></a>        <span class="c1"># if len(kwargs) &gt; 0:</span>
</span><span id="FFnetwork.__init__-75"><a href="#FFnetwork.__init__-75"><span class="linenos"> 75</span></a>        <span class="c1">#     print(&quot;FFnet: unknown kwargs:&quot;, kwargs)</span>
</span><span id="FFnetwork.__init__-76"><a href="#FFnetwork.__init__-76"><span class="linenos"> 76</span></a>        <span class="k">assert</span> <span class="n">layer_list</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;FFnetwork: Must supply a layer_list.&quot;</span>
</span><span id="FFnetwork.__init__-77"><a href="#FFnetwork.__init__-77"><span class="linenos"> 77</span></a>        
</span><span id="FFnetwork.__init__-78"><a href="#FFnetwork.__init__-78"><span class="linenos"> 78</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="FFnetwork.__init__-79"><a href="#FFnetwork.__init__-79"><span class="linenos"> 79</span></a>        
</span><span id="FFnetwork.__init__-80"><a href="#FFnetwork.__init__-80"><span class="linenos"> 80</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">network_type</span> <span class="o">=</span> <span class="n">ffnet_type</span>
</span><span id="FFnetwork.__init__-81"><a href="#FFnetwork.__init__-81"><span class="linenos"> 81</span></a>        <span class="c1">#print(&quot;FFnet: network type:&quot;, self.network_type)</span>
</span><span id="FFnetwork.__init__-82"><a href="#FFnetwork.__init__-82"><span class="linenos"> 82</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">network_type</span> <span class="ow">in</span> <span class="n">_valid_ffnet_types</span><span class="p">,</span> <span class="s2">&quot;ffnet_type &quot;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">network_type</span> <span class="o">+</span> <span class="s2">&quot; is unknown.&quot;</span>
</span><span id="FFnetwork.__init__-83"><a href="#FFnetwork.__init__-83"><span class="linenos"> 83</span></a>
</span><span id="FFnetwork.__init__-84"><a href="#FFnetwork.__init__-84"><span class="linenos"> 84</span></a>        <span class="c1"># Format and record inputs into ffnet</span>
</span><span id="FFnetwork.__init__-85"><a href="#FFnetwork.__init__-85"><span class="linenos"> 85</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layer_list</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">layer_list</span><span class="p">)</span>
</span><span id="FFnetwork.__init__-86"><a href="#FFnetwork.__init__-86"><span class="linenos"> 86</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layer_types</span> <span class="o">=</span> <span class="p">[]</span>   <span class="c1"># read from layer_list (if necessary at all)</span>
</span><span id="FFnetwork.__init__-87"><a href="#FFnetwork.__init__-87"><span class="linenos"> 87</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">xstim_n</span> <span class="o">=</span> <span class="n">xstim_n</span>
</span><span id="FFnetwork.__init__-88"><a href="#FFnetwork.__init__-88"><span class="linenos"> 88</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">ffnets_in</span> <span class="o">=</span> <span class="n">ffnet_n</span>
</span><span id="FFnetwork.__init__-89"><a href="#FFnetwork.__init__-89"><span class="linenos"> 89</span></a>
</span><span id="FFnetwork.__init__-90"><a href="#FFnetwork.__init__-90"><span class="linenos"> 90</span></a>        <span class="n">num_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_list</span><span class="p">)</span>
</span><span id="FFnetwork.__init__-91"><a href="#FFnetwork.__init__-91"><span class="linenos"> 91</span></a>
</span><span id="FFnetwork.__init__-92"><a href="#FFnetwork.__init__-92"><span class="linenos"> 92</span></a>        <span class="k">if</span> <span class="n">num_layers</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="FFnetwork.__init__-93"><a href="#FFnetwork.__init__-93"><span class="linenos"> 93</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
</span><span id="FFnetwork.__init__-94"><a href="#FFnetwork.__init__-94"><span class="linenos"> 94</span></a>            <span class="k">return</span>
</span><span id="FFnetwork.__init__-95"><a href="#FFnetwork.__init__-95"><span class="linenos"> 95</span></a>            
</span><span id="FFnetwork.__init__-96"><a href="#FFnetwork.__init__-96"><span class="linenos"> 96</span></a>        <span class="c1"># Establish input dims from the network</span>
</span><span id="FFnetwork.__init__-97"><a href="#FFnetwork.__init__-97"><span class="linenos"> 97</span></a>        <span class="k">if</span> <span class="n">input_dims_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FFnetwork.__init__-98"><a href="#FFnetwork.__init__-98"><span class="linenos"> 98</span></a>            <span class="c1"># then pull from first layer</span>
</span><span id="FFnetwork.__init__-99"><a href="#FFnetwork.__init__-99"><span class="linenos"> 99</span></a>            <span class="k">assert</span> <span class="n">layer_list</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;input_dims&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;If input_dims is not specified, it must be specified in layer-0&quot;</span>
</span><span id="FFnetwork.__init__-100"><a href="#FFnetwork.__init__-100"><span class="linenos">100</span></a>            <span class="n">input_dims_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">layer_list</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;input_dims&#39;</span><span class="p">])]</span>
</span><span id="FFnetwork.__init__-101"><a href="#FFnetwork.__init__-101"><span class="linenos">101</span></a>        
</span><span id="FFnetwork.__init__-102"><a href="#FFnetwork.__init__-102"><span class="linenos">102</span></a>        <span class="c1"># Build input_dims from sources</span>
</span><span id="FFnetwork.__init__-103"><a href="#FFnetwork.__init__-103"><span class="linenos">103</span></a>        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">determine_input_dims</span><span class="p">(</span><span class="n">input_dims_list</span><span class="p">,</span> <span class="n">ffnet_type</span><span class="o">=</span><span class="n">ffnet_type</span><span class="p">),</span> <span class="s1">&#39;Invalid network inputs.&#39;</span>
</span><span id="FFnetwork.__init__-104"><a href="#FFnetwork.__init__-104"><span class="linenos">104</span></a>
</span><span id="FFnetwork.__init__-105"><a href="#FFnetwork.__init__-105"><span class="linenos">105</span></a>        <span class="c1"># Process regularization into layer-specific list. Will save at this level too</span>
</span><span id="FFnetwork.__init__-106"><a href="#FFnetwork.__init__-106"><span class="linenos">106</span></a>        <span class="c1">#if reg_list is not None:  # can also be entered into layers directly</span>
</span><span id="FFnetwork.__init__-107"><a href="#FFnetwork.__init__-107"><span class="linenos">107</span></a>        <span class="c1">#    reg_params = self.__reg_setup_ffnet( reg_list )</span>
</span><span id="FFnetwork.__init__-108"><a href="#FFnetwork.__init__-108"><span class="linenos">108</span></a>
</span><span id="FFnetwork.__init__-109"><a href="#FFnetwork.__init__-109"><span class="linenos">109</span></a>        <span class="c1"># Make each layer as part of an array</span>
</span><span id="FFnetwork.__init__-110"><a href="#FFnetwork.__init__-110"><span class="linenos">110</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
</span><span id="FFnetwork.__init__-111"><a href="#FFnetwork.__init__-111"><span class="linenos">111</span></a>        <span class="k">for</span> <span class="n">ll</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">):</span>
</span><span id="FFnetwork.__init__-112"><a href="#FFnetwork.__init__-112"><span class="linenos">112</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_list</span><span class="p">[</span><span class="n">ll</span><span class="p">][</span><span class="s1">&#39;input_dims&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FFnetwork.__init__-113"><a href="#FFnetwork.__init__-113"><span class="linenos">113</span></a>                <span class="k">if</span> <span class="n">ll</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="FFnetwork.__init__-114"><a href="#FFnetwork.__init__-114"><span class="linenos">114</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">layer_list</span><span class="p">[</span><span class="n">ll</span><span class="p">][</span><span class="s1">&#39;input_dims&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_dims</span><span class="p">)</span>
</span><span id="FFnetwork.__init__-115"><a href="#FFnetwork.__init__-115"><span class="linenos">115</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="FFnetwork.__init__-116"><a href="#FFnetwork.__init__-116"><span class="linenos">116</span></a>                    <span class="bp">self</span><span class="o">.</span><span class="n">layer_list</span><span class="p">[</span><span class="n">ll</span><span class="p">][</span><span class="s1">&#39;input_dims&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">ll</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">output_dims</span><span class="p">)</span>
</span><span id="FFnetwork.__init__-117"><a href="#FFnetwork.__init__-117"><span class="linenos">117</span></a>            <span class="n">Ltype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_list</span><span class="p">[</span><span class="n">ll</span><span class="p">][</span><span class="s1">&#39;layer_type&#39;</span><span class="p">]</span>
</span><span id="FFnetwork.__init__-118"><a href="#FFnetwork.__init__-118"><span class="linenos">118</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">LayerTypes</span><span class="p">[</span><span class="n">Ltype</span><span class="p">](</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_list</span><span class="p">[</span><span class="n">ll</span><span class="p">])</span> <span class="p">)</span>
</span><span id="FFnetwork.__init__-119"><a href="#FFnetwork.__init__-119"><span class="linenos">119</span></a>
</span><span id="FFnetwork.__init__-120"><a href="#FFnetwork.__init__-120"><span class="linenos">120</span></a>        <span class="c1"># output dims determined by last layer</span>
</span><span id="FFnetwork.__init__-121"><a href="#FFnetwork.__init__-121"><span class="linenos">121</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">output_dims</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">output_dims</span>
</span><span id="FFnetwork.__init__-122"><a href="#FFnetwork.__init__-122"><span class="linenos">122</span></a>
</span><span id="FFnetwork.__init__-123"><a href="#FFnetwork.__init__-123"><span class="linenos">123</span></a>        <span class="c1"># Make scaffold output if requested</span>
</span><span id="FFnetwork.__init__-124"><a href="#FFnetwork.__init__-124"><span class="linenos">124</span></a>        <span class="k">if</span> <span class="n">scaffold_levels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FFnetwork.__init__-125"><a href="#FFnetwork.__init__-125"><span class="linenos">125</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># output last layer only</span>
</span><span id="FFnetwork.__init__-126"><a href="#FFnetwork.__init__-126"><span class="linenos">126</span></a>        <span class="k">else</span><span class="p">:</span> <span class="c1"># output specified layers concatenated together</span>
</span><span id="FFnetwork.__init__-127"><a href="#FFnetwork.__init__-127"><span class="linenos">127</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span> <span class="o">=</span> <span class="p">[</span><span class="o">*</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">)[</span><span class="n">scaffold_levels</span><span class="p">:]]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scaffold_levels</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">else</span> <span class="n">scaffold_levels</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="FFnetwork.network_type" class="classattr">
                                <div class="attr variable">
            <span class="name">network_type</span>

        
    </div>
    <a class="headerlink" href="#FFnetwork.network_type"></a>
    
    

                            </div>
                            <div id="FFnetwork.layer_list" class="classattr">
                                <div class="attr variable">
            <span class="name">layer_list</span>

        
    </div>
    <a class="headerlink" href="#FFnetwork.layer_list"></a>
    
    

                            </div>
                            <div id="FFnetwork.layer_types" class="classattr">
                                <div class="attr variable">
            <span class="name">layer_types</span>

        
    </div>
    <a class="headerlink" href="#FFnetwork.layer_types"></a>
    
    

                            </div>
                            <div id="FFnetwork.xstim_n" class="classattr">
                                <div class="attr variable">
            <span class="name">xstim_n</span>

        
    </div>
    <a class="headerlink" href="#FFnetwork.xstim_n"></a>
    
    

                            </div>
                            <div id="FFnetwork.ffnets_in" class="classattr">
                                <div class="attr variable">
            <span class="name">ffnets_in</span>

        
    </div>
    <a class="headerlink" href="#FFnetwork.ffnets_in"></a>
    
    

                            </div>
                            <div id="FFnetwork.layers" class="classattr">
                                <div class="attr variable">
            <span class="name">layers</span>

        
    </div>
    <a class="headerlink" href="#FFnetwork.layers"></a>
    
    

                            </div>
                            <div id="FFnetwork.output_dims" class="classattr">
                                <div class="attr variable">
            <span class="name">output_dims</span>

        
    </div>
    <a class="headerlink" href="#FFnetwork.output_dims"></a>
    
    

                            </div>
                            <div id="FFnetwork.num_outputs" class="classattr">
                                        <input id="FFnetwork.num_outputs-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr variable">
            <span class="name">num_outputs</span>

                <label class="view-source-button" for="FFnetwork.num_outputs-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FFnetwork.num_outputs"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FFnetwork.num_outputs-130"><a href="#FFnetwork.num_outputs-130"><span class="linenos">130</span></a>    <span class="nd">@property</span>
</span><span id="FFnetwork.num_outputs-131"><a href="#FFnetwork.num_outputs-131"><span class="linenos">131</span></a>    <span class="k">def</span> <span class="nf">num_outputs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="FFnetwork.num_outputs-132"><a href="#FFnetwork.num_outputs-132"><span class="linenos">132</span></a>        <span class="n">n</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="FFnetwork.num_outputs-133"><a href="#FFnetwork.num_outputs-133"><span class="linenos">133</span></a>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">:</span>
</span><span id="FFnetwork.num_outputs-134"><a href="#FFnetwork.num_outputs-134"><span class="linenos">134</span></a>            <span class="n">n</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">output_dims</span>
</span><span id="FFnetwork.num_outputs-135"><a href="#FFnetwork.num_outputs-135"><span class="linenos">135</span></a>        <span class="k">return</span> <span class="n">n</span>
</span></pre></div>


    

                            </div>
                            <div id="FFnetwork.determine_input_dims" class="classattr">
                                        <input id="FFnetwork.determine_input_dims-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">determine_input_dims</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">input_dims_list</span>, </span><span class="param"><span class="n">ffnet_type</span><span class="o">=</span><span class="s1">&#39;normal&#39;</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="FFnetwork.determine_input_dims-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FFnetwork.determine_input_dims"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FFnetwork.determine_input_dims-137"><a href="#FFnetwork.determine_input_dims-137"><span class="linenos">137</span></a>    <span class="k">def</span> <span class="nf">determine_input_dims</span><span class="p">(</span> <span class="bp">self</span><span class="p">,</span> <span class="n">input_dims_list</span><span class="p">,</span> <span class="n">ffnet_type</span><span class="o">=</span><span class="s1">&#39;normal&#39;</span> <span class="p">):</span>
</span><span id="FFnetwork.determine_input_dims-138"><a href="#FFnetwork.determine_input_dims-138"><span class="linenos">138</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnetwork.determine_input_dims-139"><a href="#FFnetwork.determine_input_dims-139"><span class="linenos">139</span></a><span class="sd">        Sets input_dims given network inputs. Can be overloaded depending on the network type. For this base class, there</span>
</span><span id="FFnetwork.determine_input_dims-140"><a href="#FFnetwork.determine_input_dims-140"><span class="linenos">140</span></a><span class="sd">        are two types of network input: external stimulus (xstim_n) or a list of internal (ffnet_in) networks:</span>
</span><span id="FFnetwork.determine_input_dims-141"><a href="#FFnetwork.determine_input_dims-141"><span class="linenos">141</span></a><span class="sd">            For external inputs, it just uses the passed-in input_dims</span>
</span><span id="FFnetwork.determine_input_dims-142"><a href="#FFnetwork.determine_input_dims-142"><span class="linenos">142</span></a><span class="sd">            For internal network inputs, it will concatenate inputs along the filter dimension, but MUST match other dims</span>
</span><span id="FFnetwork.determine_input_dims-143"><a href="#FFnetwork.determine_input_dims-143"><span class="linenos">143</span></a><span class="sd">        As currently designed, this can either external or internal, but not both</span>
</span><span id="FFnetwork.determine_input_dims-144"><a href="#FFnetwork.determine_input_dims-144"><span class="linenos">144</span></a><span class="sd">        </span>
</span><span id="FFnetwork.determine_input_dims-145"><a href="#FFnetwork.determine_input_dims-145"><span class="linenos">145</span></a><span class="sd">        This sets the following internal FFnetwork properties:</span>
</span><span id="FFnetwork.determine_input_dims-146"><a href="#FFnetwork.determine_input_dims-146"><span class="linenos">146</span></a><span class="sd">            self.input_dims</span>
</span><span id="FFnetwork.determine_input_dims-147"><a href="#FFnetwork.determine_input_dims-147"><span class="linenos">147</span></a><span class="sd">            self.input_dims_list</span>
</span><span id="FFnetwork.determine_input_dims-148"><a href="#FFnetwork.determine_input_dims-148"><span class="linenos">148</span></a><span class="sd">        and returns Boolean whether the passed in input dims are valid</span>
</span><span id="FFnetwork.determine_input_dims-149"><a href="#FFnetwork.determine_input_dims-149"><span class="linenos">149</span></a>
</span><span id="FFnetwork.determine_input_dims-150"><a href="#FFnetwork.determine_input_dims-150"><span class="linenos">150</span></a><span class="sd">        Args:</span>
</span><span id="FFnetwork.determine_input_dims-151"><a href="#FFnetwork.determine_input_dims-151"><span class="linenos">151</span></a><span class="sd">            input_dims_list (list): A list of input dimensions for each layer.</span>
</span><span id="FFnetwork.determine_input_dims-152"><a href="#FFnetwork.determine_input_dims-152"><span class="linenos">152</span></a><span class="sd">            ffnet_type (str): The type of the feedforward network.</span>
</span><span id="FFnetwork.determine_input_dims-153"><a href="#FFnetwork.determine_input_dims-153"><span class="linenos">153</span></a>
</span><span id="FFnetwork.determine_input_dims-154"><a href="#FFnetwork.determine_input_dims-154"><span class="linenos">154</span></a><span class="sd">        Returns:</span>
</span><span id="FFnetwork.determine_input_dims-155"><a href="#FFnetwork.determine_input_dims-155"><span class="linenos">155</span></a><span class="sd">            valid_input_dims (bool): Whether the passed in input dims are valid.</span>
</span><span id="FFnetwork.determine_input_dims-156"><a href="#FFnetwork.determine_input_dims-156"><span class="linenos">156</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FFnetwork.determine_input_dims-157"><a href="#FFnetwork.determine_input_dims-157"><span class="linenos">157</span></a>
</span><span id="FFnetwork.determine_input_dims-158"><a href="#FFnetwork.determine_input_dims-158"><span class="linenos">158</span></a>        <span class="n">valid_input_dims</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="FFnetwork.determine_input_dims-159"><a href="#FFnetwork.determine_input_dims-159"><span class="linenos">159</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffnets_in</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FFnetwork.determine_input_dims-160"><a href="#FFnetwork.determine_input_dims-160"><span class="linenos">160</span></a>            <span class="c1"># then external input (assume from one source)</span>
</span><span id="FFnetwork.determine_input_dims-161"><a href="#FFnetwork.determine_input_dims-161"><span class="linenos">161</span></a>            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_dims_list</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;FFnet constructor: Only one set of input dims can be specified.&quot;</span>
</span><span id="FFnetwork.determine_input_dims-162"><a href="#FFnetwork.determine_input_dims-162"><span class="linenos">162</span></a>            <span class="k">assert</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;FFnet constructor: External input dims must be specified.&quot;</span>
</span><span id="FFnetwork.determine_input_dims-163"><a href="#FFnetwork.determine_input_dims-163"><span class="linenos">163</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">input_dims</span> <span class="o">=</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="FFnetwork.determine_input_dims-164"><a href="#FFnetwork.determine_input_dims-164"><span class="linenos">164</span></a>        <span class="k">else</span><span class="p">:</span> 
</span><span id="FFnetwork.determine_input_dims-165"><a href="#FFnetwork.determine_input_dims-165"><span class="linenos">165</span></a>            <span class="n">num_input_networks</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ffnets_in</span><span class="p">)</span>
</span><span id="FFnetwork.determine_input_dims-166"><a href="#FFnetwork.determine_input_dims-166"><span class="linenos">166</span></a>            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_dims_list</span><span class="p">)</span> <span class="o">==</span> <span class="n">num_input_networks</span><span class="p">,</span> <span class="s1">&#39;Internal: misspecification of input_dims for FFnetwork.&#39;</span>
</span><span id="FFnetwork.determine_input_dims-167"><a href="#FFnetwork.determine_input_dims-167"><span class="linenos">167</span></a>
</span><span id="FFnetwork.determine_input_dims-168"><a href="#FFnetwork.determine_input_dims-168"><span class="linenos">168</span></a>            <span class="c1"># Go through the input dims of the other ffnetowrks to verify they are valid for the type of network</span>
</span><span id="FFnetwork.determine_input_dims-169"><a href="#FFnetwork.determine_input_dims-169"><span class="linenos">169</span></a>            <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_input_networks</span><span class="p">):</span>
</span><span id="FFnetwork.determine_input_dims-170"><a href="#FFnetwork.determine_input_dims-170"><span class="linenos">170</span></a>                <span class="k">if</span> <span class="n">ii</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span id="FFnetwork.determine_input_dims-171"><a href="#FFnetwork.determine_input_dims-171"><span class="linenos">171</span></a>                    <span class="n">num_cat_filters</span> <span class="o">=</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</span><span id="FFnetwork.determine_input_dims-172"><a href="#FFnetwork.determine_input_dims-172"><span class="linenos">172</span></a>                <span class="k">else</span><span class="p">:</span>
</span><span id="FFnetwork.determine_input_dims-173"><a href="#FFnetwork.determine_input_dims-173"><span class="linenos">173</span></a>                    <span class="k">if</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="n">ii</span><span class="p">][</span><span class="mi">1</span><span class="p">:]</span> <span class="o">!=</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">:]:</span>
</span><span id="FFnetwork.determine_input_dims-174"><a href="#FFnetwork.determine_input_dims-174"><span class="linenos">174</span></a>                        <span class="k">if</span> <span class="n">ffnet_type</span> <span class="o">==</span> <span class="s1">&#39;add&#39;</span><span class="p">:</span>
</span><span id="FFnetwork.determine_input_dims-175"><a href="#FFnetwork.determine_input_dims-175"><span class="linenos">175</span></a>                            <span class="k">for</span> <span class="n">jj</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
</span><span id="FFnetwork.determine_input_dims-176"><a href="#FFnetwork.determine_input_dims-176"><span class="linenos">176</span></a>                                <span class="c1">#if (input_dims_list[ii][jj+1] &gt; 1) | (input_dims_list[0][jj+1] == 1):</span>
</span><span id="FFnetwork.determine_input_dims-177"><a href="#FFnetwork.determine_input_dims-177"><span class="linenos">177</span></a>                                <span class="k">if</span> <span class="p">(</span><span class="n">input_dims_list</span><span class="p">[</span><span class="n">ii</span><span class="p">][</span><span class="n">jj</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">input_dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">jj</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
</span><span id="FFnetwork.determine_input_dims-178"><a href="#FFnetwork.determine_input_dims-178"><span class="linenos">178</span></a>                                    <span class="n">valid_input_dims</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="FFnetwork.determine_input_dims-179"><a href="#FFnetwork.determine_input_dims-179"><span class="linenos">179</span></a>                        <span class="k">else</span><span class="p">:</span>
</span><span id="FFnetwork.determine_input_dims-180"><a href="#FFnetwork.determine_input_dims-180"><span class="linenos">180</span></a>                            <span class="n">valid_input_dims</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="FFnetwork.determine_input_dims-181"><a href="#FFnetwork.determine_input_dims-181"><span class="linenos">181</span></a>                    <span class="k">assert</span> <span class="n">valid_input_dims</span><span class="p">,</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;FFnet: invalid concatenation </span><span class="si">%d</span><span class="s2">:&quot;</span><span class="o">%</span><span class="n">ii</span><span class="p">,</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="n">ii</span><span class="p">][</span><span class="mi">1</span><span class="p">:],</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">:]</span> <span class="p">)</span>
</span><span id="FFnetwork.determine_input_dims-182"><a href="#FFnetwork.determine_input_dims-182"><span class="linenos">182</span></a>
</span><span id="FFnetwork.determine_input_dims-183"><a href="#FFnetwork.determine_input_dims-183"><span class="linenos">183</span></a>                    <span class="k">if</span> <span class="n">ffnet_type</span> <span class="o">==</span> <span class="s1">&#39;normal&#39;</span><span class="p">:</span> <span class="c1"># then inputs will be concatenated along &#39;filter&#39; dimension</span>
</span><span id="FFnetwork.determine_input_dims-184"><a href="#FFnetwork.determine_input_dims-184"><span class="linenos">184</span></a>                        <span class="n">num_cat_filters</span> <span class="o">+=</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="n">ii</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</span><span id="FFnetwork.determine_input_dims-185"><a href="#FFnetwork.determine_input_dims-185"><span class="linenos">185</span></a>                    <span class="k">elif</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="n">ii</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="FFnetwork.determine_input_dims-186"><a href="#FFnetwork.determine_input_dims-186"><span class="linenos">186</span></a>                        <span class="c1"># these are combined and input to first layer has same size as one input</span>
</span><span id="FFnetwork.determine_input_dims-187"><a href="#FFnetwork.determine_input_dims-187"><span class="linenos">187</span></a>                        <span class="k">assert</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="n">ii</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">num_cat_filters</span><span class="p">,</span> <span class="s1">&#39;Input dims must be the same for &#39;</span> <span class="o">+</span> <span class="n">ffnet_type</span> <span class="o">+</span> <span class="s1">&#39; ffnetwork&#39;</span>
</span><span id="FFnetwork.determine_input_dims-188"><a href="#FFnetwork.determine_input_dims-188"><span class="linenos">188</span></a>                    
</span><span id="FFnetwork.determine_input_dims-189"><a href="#FFnetwork.determine_input_dims-189"><span class="linenos">189</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">input_dims</span> <span class="o">=</span> <span class="p">[</span><span class="n">num_cat_filters</span><span class="p">]</span> <span class="o">+</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">:]</span>
</span><span id="FFnetwork.determine_input_dims-190"><a href="#FFnetwork.determine_input_dims-190"><span class="linenos">190</span></a>        
</span><span id="FFnetwork.determine_input_dims-191"><a href="#FFnetwork.determine_input_dims-191"><span class="linenos">191</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">input_dims_list</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">input_dims_list</span><span class="p">)</span>
</span><span id="FFnetwork.determine_input_dims-192"><a href="#FFnetwork.determine_input_dims-192"><span class="linenos">192</span></a>        <span class="k">return</span> <span class="n">valid_input_dims</span>
</span></pre></div>


            <div class="docstring"><p>Sets input_dims given network inputs. Can be overloaded depending on the network type. For this base class, there
are two types of network input: external stimulus (xstim_n) or a list of internal (ffnet_in) networks:
    For external inputs, it just uses the passed-in input_dims
    For internal network inputs, it will concatenate inputs along the filter dimension, but MUST match other dims
As currently designed, this can either external or internal, but not both</p>

<h6 id="this-sets-the-following-internal-ffnetwork-properties">This sets the following internal FFnetwork properties:</h6>

<blockquote>
  <p>self.input_dims
  self.input_dims_list</p>
</blockquote>

<p>and returns Boolean whether the passed in input dims are valid</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>input_dims_list (list):</strong>  A list of input dimensions for each layer.</li>
<li><strong>ffnet_type (str):</strong>  The type of the feedforward network.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>valid_input_dims (bool): Whether the passed in input dims are valid.</p>
</blockquote>
</div>


                            </div>
                            <div id="FFnetwork.preprocess_input" class="classattr">
                                        <input id="FFnetwork.preprocess_input-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">preprocess_input</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">inputs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="FFnetwork.preprocess_input-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FFnetwork.preprocess_input"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FFnetwork.preprocess_input-195"><a href="#FFnetwork.preprocess_input-195"><span class="linenos">195</span></a>    <span class="k">def</span> <span class="nf">preprocess_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="FFnetwork.preprocess_input-196"><a href="#FFnetwork.preprocess_input-196"><span class="linenos">196</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnetwork.preprocess_input-197"><a href="#FFnetwork.preprocess_input-197"><span class="linenos">197</span></a><span class="sd">        Preprocess input to network.</span>
</span><span id="FFnetwork.preprocess_input-198"><a href="#FFnetwork.preprocess_input-198"><span class="linenos">198</span></a>
</span><span id="FFnetwork.preprocess_input-199"><a href="#FFnetwork.preprocess_input-199"><span class="linenos">199</span></a><span class="sd">        Args:</span>
</span><span id="FFnetwork.preprocess_input-200"><a href="#FFnetwork.preprocess_input-200"><span class="linenos">200</span></a><span class="sd">            inputs (list, torch.Tensor): The input to the network.</span>
</span><span id="FFnetwork.preprocess_input-201"><a href="#FFnetwork.preprocess_input-201"><span class="linenos">201</span></a>
</span><span id="FFnetwork.preprocess_input-202"><a href="#FFnetwork.preprocess_input-202"><span class="linenos">202</span></a><span class="sd">        Returns:</span>
</span><span id="FFnetwork.preprocess_input-203"><a href="#FFnetwork.preprocess_input-203"><span class="linenos">203</span></a><span class="sd">            x (torch.Tensor): The preprocessed input.</span>
</span><span id="FFnetwork.preprocess_input-204"><a href="#FFnetwork.preprocess_input-204"><span class="linenos">204</span></a>
</span><span id="FFnetwork.preprocess_input-205"><a href="#FFnetwork.preprocess_input-205"><span class="linenos">205</span></a><span class="sd">        Raises:</span>
</span><span id="FFnetwork.preprocess_input-206"><a href="#FFnetwork.preprocess_input-206"><span class="linenos">206</span></a><span class="sd">            ValueError: If no layers are defined.</span>
</span><span id="FFnetwork.preprocess_input-207"><a href="#FFnetwork.preprocess_input-207"><span class="linenos">207</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FFnetwork.preprocess_input-208"><a href="#FFnetwork.preprocess_input-208"><span class="linenos">208</span></a>
</span><span id="FFnetwork.preprocess_input-209"><a href="#FFnetwork.preprocess_input-209"><span class="linenos">209</span></a>        <span class="c1"># Combine network inputs (if relevant)</span>
</span><span id="FFnetwork.preprocess_input-210"><a href="#FFnetwork.preprocess_input-210"><span class="linenos">210</span></a>        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="FFnetwork.preprocess_input-211"><a href="#FFnetwork.preprocess_input-211"><span class="linenos">211</span></a>            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="FFnetwork.preprocess_input-212"><a href="#FFnetwork.preprocess_input-212"><span class="linenos">212</span></a>                <span class="n">x</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="FFnetwork.preprocess_input-213"><a href="#FFnetwork.preprocess_input-213"><span class="linenos">213</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="FFnetwork.preprocess_input-214"><a href="#FFnetwork.preprocess_input-214"><span class="linenos">214</span></a>                <span class="n">x</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">input_dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># this will allow for broadcasting</span>
</span><span id="FFnetwork.preprocess_input-215"><a href="#FFnetwork.preprocess_input-215"><span class="linenos">215</span></a>                <span class="n">nt</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="FFnetwork.preprocess_input-216"><a href="#FFnetwork.preprocess_input-216"><span class="linenos">216</span></a>                <span class="k">for</span> <span class="n">mm</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)):</span>
</span><span id="FFnetwork.preprocess_input-217"><a href="#FFnetwork.preprocess_input-217"><span class="linenos">217</span></a>                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">network_type</span> <span class="o">==</span> <span class="s1">&#39;normal&#39;</span><span class="p">:</span> <span class="c1"># concatentate inputs</span>
</span><span id="FFnetwork.preprocess_input-218"><a href="#FFnetwork.preprocess_input-218"><span class="linenos">218</span></a>                        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">inputs</span><span class="p">[</span><span class="n">mm</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">input_dims_list</span><span class="p">[</span><span class="n">mm</span><span class="p">])),</span> <span class="mi">1</span> <span class="p">)</span>
</span><span id="FFnetwork.preprocess_input-219"><a href="#FFnetwork.preprocess_input-219"><span class="linenos">219</span></a>                    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">network_type</span> <span class="o">==</span> <span class="s1">&#39;add&#39;</span><span class="p">:</span> <span class="c1"># add inputs</span>
</span><span id="FFnetwork.preprocess_input-220"><a href="#FFnetwork.preprocess_input-220"><span class="linenos">220</span></a>                        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">(</span> <span class="n">x</span><span class="p">,</span> <span class="n">inputs</span><span class="p">[</span><span class="n">mm</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">input_dims_list</span><span class="p">[</span><span class="n">mm</span><span class="p">])</span> <span class="p">)</span>
</span><span id="FFnetwork.preprocess_input-221"><a href="#FFnetwork.preprocess_input-221"><span class="linenos">221</span></a>                    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">network_type</span> <span class="o">==</span> <span class="s1">&#39;mult&#39;</span><span class="p">:</span> <span class="c1"># multiply: (input1) x (1+input2)</span>
</span><span id="FFnetwork.preprocess_input-222"><a href="#FFnetwork.preprocess_input-222"><span class="linenos">222</span></a>                        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span>
</span><span id="FFnetwork.preprocess_input-223"><a href="#FFnetwork.preprocess_input-223"><span class="linenos">223</span></a>                            <span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="n">mm</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">input_dims_list</span><span class="p">[</span><span class="n">mm</span><span class="p">]),</span> <span class="mf">1.0</span><span class="p">)</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span> <span class="p">)</span>
</span><span id="FFnetwork.preprocess_input-224"><a href="#FFnetwork.preprocess_input-224"><span class="linenos">224</span></a>                        <span class="c1"># Make sure multiplication is not negative</span>
</span><span id="FFnetwork.preprocess_input-225"><a href="#FFnetwork.preprocess_input-225"><span class="linenos">225</span></a>                <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">([</span><span class="n">nt</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span><span id="FFnetwork.preprocess_input-226"><a href="#FFnetwork.preprocess_input-226"><span class="linenos">226</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="FFnetwork.preprocess_input-227"><a href="#FFnetwork.preprocess_input-227"><span class="linenos">227</span></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">inputs</span>
</span><span id="FFnetwork.preprocess_input-228"><a href="#FFnetwork.preprocess_input-228"><span class="linenos">228</span></a>        <span class="k">return</span> <span class="n">x</span>
</span></pre></div>


            <div class="docstring"><p>Preprocess input to network.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>inputs (list, torch.Tensor):</strong>  The input to the network.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>x (torch.Tensor): The preprocessed input.</p>
</blockquote>

<h6 id="raises">Raises:</h6>

<ul>
<li><strong>ValueError:</strong>  If no layers are defined.</li>
</ul>
</div>


                            </div>
                            <div id="FFnetwork.forward" class="classattr">
                                        <input id="FFnetwork.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">inputs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="FFnetwork.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FFnetwork.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FFnetwork.forward-230"><a href="#FFnetwork.forward-230"><span class="linenos">230</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="FFnetwork.forward-231"><a href="#FFnetwork.forward-231"><span class="linenos">231</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnetwork.forward-232"><a href="#FFnetwork.forward-232"><span class="linenos">232</span></a><span class="sd">        Forward pass through the network.</span>
</span><span id="FFnetwork.forward-233"><a href="#FFnetwork.forward-233"><span class="linenos">233</span></a>
</span><span id="FFnetwork.forward-234"><a href="#FFnetwork.forward-234"><span class="linenos">234</span></a><span class="sd">        Args:</span>
</span><span id="FFnetwork.forward-235"><a href="#FFnetwork.forward-235"><span class="linenos">235</span></a><span class="sd">            inputs (list, torch.Tensor): The input to the network.</span>
</span><span id="FFnetwork.forward-236"><a href="#FFnetwork.forward-236"><span class="linenos">236</span></a>
</span><span id="FFnetwork.forward-237"><a href="#FFnetwork.forward-237"><span class="linenos">237</span></a><span class="sd">        Returns:</span>
</span><span id="FFnetwork.forward-238"><a href="#FFnetwork.forward-238"><span class="linenos">238</span></a><span class="sd">            x (torch.Tensor): The output of the network.</span>
</span><span id="FFnetwork.forward-239"><a href="#FFnetwork.forward-239"><span class="linenos">239</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FFnetwork.forward-240"><a href="#FFnetwork.forward-240"><span class="linenos">240</span></a>
</span><span id="FFnetwork.forward-241"><a href="#FFnetwork.forward-241"><span class="linenos">241</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FFnetwork.forward-242"><a href="#FFnetwork.forward-242"><span class="linenos">242</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;FFnet: no layers defined.&quot;</span><span class="p">)</span>
</span><span id="FFnetwork.forward-243"><a href="#FFnetwork.forward-243"><span class="linenos">243</span></a>        
</span><span id="FFnetwork.forward-244"><a href="#FFnetwork.forward-244"><span class="linenos">244</span></a>        <span class="n">out</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># returned </span>
</span><span id="FFnetwork.forward-245"><a href="#FFnetwork.forward-245"><span class="linenos">245</span></a>
</span><span id="FFnetwork.forward-246"><a href="#FFnetwork.forward-246"><span class="linenos">246</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess_input</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="FFnetwork.forward-247"><a href="#FFnetwork.forward-247"><span class="linenos">247</span></a>
</span><span id="FFnetwork.forward-248"><a href="#FFnetwork.forward-248"><span class="linenos">248</span></a>        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
</span><span id="FFnetwork.forward-249"><a href="#FFnetwork.forward-249"><span class="linenos">249</span></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="FFnetwork.forward-250"><a href="#FFnetwork.forward-250"><span class="linenos">250</span></a>            <span class="c1">#out.append(x)</span>
</span><span id="FFnetwork.forward-251"><a href="#FFnetwork.forward-251"><span class="linenos">251</span></a>
</span><span id="FFnetwork.forward-252"><a href="#FFnetwork.forward-252"><span class="linenos">252</span></a>        <span class="k">return</span> <span class="n">x</span>
</span><span id="FFnetwork.forward-253"><a href="#FFnetwork.forward-253"><span class="linenos">253</span></a>        <span class="c1">#return torch.cat([out[ind] for ind in self.scaffold_levels], dim=1)</span>
</span></pre></div>


            <div class="docstring"><p>Forward pass through the network.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>inputs (list, torch.Tensor):</strong>  The input to the network.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>x (torch.Tensor): The output of the network.</p>
</blockquote>
</div>


                            </div>
                            <div id="FFnetwork.prepare_regularization" class="classattr">
                                        <input id="FFnetwork.prepare_regularization-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">prepare_regularization</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">device</span><span class="o">=</span><span class="kc">None</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="FFnetwork.prepare_regularization-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FFnetwork.prepare_regularization"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FFnetwork.prepare_regularization-285"><a href="#FFnetwork.prepare_regularization-285"><span class="linenos">285</span></a>    <span class="k">def</span> <span class="nf">prepare_regularization</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="FFnetwork.prepare_regularization-286"><a href="#FFnetwork.prepare_regularization-286"><span class="linenos">286</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnetwork.prepare_regularization-287"><a href="#FFnetwork.prepare_regularization-287"><span class="linenos">287</span></a><span class="sd">        Makes regularization modules with current requested values.</span>
</span><span id="FFnetwork.prepare_regularization-288"><a href="#FFnetwork.prepare_regularization-288"><span class="linenos">288</span></a><span class="sd">        This is done immediately before training, because it can change during training and tuning.</span>
</span><span id="FFnetwork.prepare_regularization-289"><a href="#FFnetwork.prepare_regularization-289"><span class="linenos">289</span></a>
</span><span id="FFnetwork.prepare_regularization-290"><a href="#FFnetwork.prepare_regularization-290"><span class="linenos">290</span></a><span class="sd">        Args:</span>
</span><span id="FFnetwork.prepare_regularization-291"><a href="#FFnetwork.prepare_regularization-291"><span class="linenos">291</span></a><span class="sd">            device (str, optional): The device to use. Defaults to None.</span>
</span><span id="FFnetwork.prepare_regularization-292"><a href="#FFnetwork.prepare_regularization-292"><span class="linenos">292</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FFnetwork.prepare_regularization-293"><a href="#FFnetwork.prepare_regularization-293"><span class="linenos">293</span></a>
</span><span id="FFnetwork.prepare_regularization-294"><a href="#FFnetwork.prepare_regularization-294"><span class="linenos">294</span></a>        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
</span><span id="FFnetwork.prepare_regularization-295"><a href="#FFnetwork.prepare_regularization-295"><span class="linenos">295</span></a>            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;reg&#39;</span><span class="p">):</span>
</span><span id="FFnetwork.prepare_regularization-296"><a href="#FFnetwork.prepare_regularization-296"><span class="linenos">296</span></a>                <span class="n">layer</span><span class="o">.</span><span class="n">reg</span><span class="o">.</span><span class="n">build_reg_modules</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Makes regularization modules with current requested values.
This is done immediately before training, because it can change during training and tuning.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>device (str, optional):</strong>  The device to use. Defaults to None.</li>
</ul>
</div>


                            </div>
                            <div id="FFnetwork.compute_reg_loss" class="classattr">
                                        <input id="FFnetwork.compute_reg_loss-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">compute_reg_loss</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="FFnetwork.compute_reg_loss-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FFnetwork.compute_reg_loss"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FFnetwork.compute_reg_loss-298"><a href="#FFnetwork.compute_reg_loss-298"><span class="linenos">298</span></a>    <span class="k">def</span> <span class="nf">compute_reg_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="FFnetwork.compute_reg_loss-299"><a href="#FFnetwork.compute_reg_loss-299"><span class="linenos">299</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnetwork.compute_reg_loss-300"><a href="#FFnetwork.compute_reg_loss-300"><span class="linenos">300</span></a><span class="sd">        Computes the regularization loss.</span>
</span><span id="FFnetwork.compute_reg_loss-301"><a href="#FFnetwork.compute_reg_loss-301"><span class="linenos">301</span></a>
</span><span id="FFnetwork.compute_reg_loss-302"><a href="#FFnetwork.compute_reg_loss-302"><span class="linenos">302</span></a><span class="sd">        Args:</span>
</span><span id="FFnetwork.compute_reg_loss-303"><a href="#FFnetwork.compute_reg_loss-303"><span class="linenos">303</span></a><span class="sd">            None</span>
</span><span id="FFnetwork.compute_reg_loss-304"><a href="#FFnetwork.compute_reg_loss-304"><span class="linenos">304</span></a>
</span><span id="FFnetwork.compute_reg_loss-305"><a href="#FFnetwork.compute_reg_loss-305"><span class="linenos">305</span></a><span class="sd">        Returns:</span>
</span><span id="FFnetwork.compute_reg_loss-306"><a href="#FFnetwork.compute_reg_loss-306"><span class="linenos">306</span></a><span class="sd">            rloss (torch.Tensor): The regularization loss.</span>
</span><span id="FFnetwork.compute_reg_loss-307"><a href="#FFnetwork.compute_reg_loss-307"><span class="linenos">307</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FFnetwork.compute_reg_loss-308"><a href="#FFnetwork.compute_reg_loss-308"><span class="linenos">308</span></a>
</span><span id="FFnetwork.compute_reg_loss-309"><a href="#FFnetwork.compute_reg_loss-309"><span class="linenos">309</span></a>        <span class="n">rloss</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="FFnetwork.compute_reg_loss-310"><a href="#FFnetwork.compute_reg_loss-310"><span class="linenos">310</span></a>        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
</span><span id="FFnetwork.compute_reg_loss-311"><a href="#FFnetwork.compute_reg_loss-311"><span class="linenos">311</span></a>            <span class="n">rloss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">compute_reg_loss</span><span class="p">())</span>
</span><span id="FFnetwork.compute_reg_loss-312"><a href="#FFnetwork.compute_reg_loss-312"><span class="linenos">312</span></a>        <span class="k">return</span> <span class="n">reduce</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">,</span> <span class="n">rloss</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Computes the regularization loss.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li>None</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>rloss (torch.Tensor): The regularization loss.</p>
</blockquote>
</div>


                            </div>
                            <div id="FFnetwork.list_parameters" class="classattr">
                                        <input id="FFnetwork.list_parameters-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">list_parameters</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">layer_target</span><span class="o">=</span><span class="kc">None</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="FFnetwork.list_parameters-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FFnetwork.list_parameters"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FFnetwork.list_parameters-314"><a href="#FFnetwork.list_parameters-314"><span class="linenos">314</span></a>    <span class="k">def</span> <span class="nf">list_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer_target</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="FFnetwork.list_parameters-315"><a href="#FFnetwork.list_parameters-315"><span class="linenos">315</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnetwork.list_parameters-316"><a href="#FFnetwork.list_parameters-316"><span class="linenos">316</span></a><span class="sd">        Lists the parameters for the network.</span>
</span><span id="FFnetwork.list_parameters-317"><a href="#FFnetwork.list_parameters-317"><span class="linenos">317</span></a>
</span><span id="FFnetwork.list_parameters-318"><a href="#FFnetwork.list_parameters-318"><span class="linenos">318</span></a><span class="sd">        Args:</span>
</span><span id="FFnetwork.list_parameters-319"><a href="#FFnetwork.list_parameters-319"><span class="linenos">319</span></a><span class="sd">            layer_target (int, optional): The layer to list the parameters for. Defaults to None.</span>
</span><span id="FFnetwork.list_parameters-320"><a href="#FFnetwork.list_parameters-320"><span class="linenos">320</span></a>
</span><span id="FFnetwork.list_parameters-321"><a href="#FFnetwork.list_parameters-321"><span class="linenos">321</span></a><span class="sd">        Returns:</span>
</span><span id="FFnetwork.list_parameters-322"><a href="#FFnetwork.list_parameters-322"><span class="linenos">322</span></a><span class="sd">            None</span>
</span><span id="FFnetwork.list_parameters-323"><a href="#FFnetwork.list_parameters-323"><span class="linenos">323</span></a>
</span><span id="FFnetwork.list_parameters-324"><a href="#FFnetwork.list_parameters-324"><span class="linenos">324</span></a><span class="sd">        Raises:</span>
</span><span id="FFnetwork.list_parameters-325"><a href="#FFnetwork.list_parameters-325"><span class="linenos">325</span></a><span class="sd">            AssertionError: If the layer target is invalid.</span>
</span><span id="FFnetwork.list_parameters-326"><a href="#FFnetwork.list_parameters-326"><span class="linenos">326</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FFnetwork.list_parameters-327"><a href="#FFnetwork.list_parameters-327"><span class="linenos">327</span></a>
</span><span id="FFnetwork.list_parameters-328"><a href="#FFnetwork.list_parameters-328"><span class="linenos">328</span></a>        <span class="k">if</span> <span class="n">layer_target</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FFnetwork.list_parameters-329"><a href="#FFnetwork.list_parameters-329"><span class="linenos">329</span></a>            <span class="n">layer_target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;int32&#39;</span><span class="p">)</span>
</span><span id="FFnetwork.list_parameters-330"><a href="#FFnetwork.list_parameters-330"><span class="linenos">330</span></a>        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer_target</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="FFnetwork.list_parameters-331"><a href="#FFnetwork.list_parameters-331"><span class="linenos">331</span></a>            <span class="n">layer_target</span> <span class="o">=</span> <span class="p">[</span><span class="n">layer_target</span><span class="p">]</span>
</span><span id="FFnetwork.list_parameters-332"><a href="#FFnetwork.list_parameters-332"><span class="linenos">332</span></a>        <span class="k">for</span> <span class="n">nn</span> <span class="ow">in</span> <span class="n">layer_target</span><span class="p">:</span>
</span><span id="FFnetwork.list_parameters-333"><a href="#FFnetwork.list_parameters-333"><span class="linenos">333</span></a>            <span class="k">assert</span> <span class="n">nn</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">),</span> <span class="s1">&#39;  Invalid layer </span><span class="si">%d</span><span class="s1">.&#39;</span><span class="o">%</span><span class="n">nn</span>
</span><span id="FFnetwork.list_parameters-334"><a href="#FFnetwork.list_parameters-334"><span class="linenos">334</span></a>            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  Layer </span><span class="si">%d</span><span class="s2">:&quot;</span><span class="o">%</span><span class="n">nn</span><span class="p">)</span>
</span><span id="FFnetwork.list_parameters-335"><a href="#FFnetwork.list_parameters-335"><span class="linenos">335</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">nn</span><span class="p">]</span><span class="o">.</span><span class="n">list_parameters</span><span class="p">()</span>
</span></pre></div>


            <div class="docstring"><p>Lists the parameters for the network.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>layer_target (int, optional):</strong>  The layer to list the parameters for. Defaults to None.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>None</p>
</blockquote>

<h6 id="raises">Raises:</h6>

<ul>
<li><strong>AssertionError:</strong>  If the layer target is invalid.</li>
</ul>
</div>


                            </div>
                            <div id="FFnetwork.set_parameters" class="classattr">
                                        <input id="FFnetwork.set_parameters-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">set_parameters</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">layer_target</span><span class="o">=</span><span class="kc">None</span>, </span><span class="param"><span class="n">name</span><span class="o">=</span><span class="kc">None</span>, </span><span class="param"><span class="n">val</span><span class="o">=</span><span class="kc">None</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="FFnetwork.set_parameters-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FFnetwork.set_parameters"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FFnetwork.set_parameters-337"><a href="#FFnetwork.set_parameters-337"><span class="linenos">337</span></a>    <span class="k">def</span> <span class="nf">set_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer_target</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">val</span><span class="o">=</span><span class="kc">None</span> <span class="p">):</span>
</span><span id="FFnetwork.set_parameters-338"><a href="#FFnetwork.set_parameters-338"><span class="linenos">338</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnetwork.set_parameters-339"><a href="#FFnetwork.set_parameters-339"><span class="linenos">339</span></a><span class="sd">        Sets the parameters for the listed layer or for all layers.</span>
</span><span id="FFnetwork.set_parameters-340"><a href="#FFnetwork.set_parameters-340"><span class="linenos">340</span></a>
</span><span id="FFnetwork.set_parameters-341"><a href="#FFnetwork.set_parameters-341"><span class="linenos">341</span></a><span class="sd">        Args:</span>
</span><span id="FFnetwork.set_parameters-342"><a href="#FFnetwork.set_parameters-342"><span class="linenos">342</span></a><span class="sd">            layer_target (int, optional): The layer to set the parameters for. Defaults to None.</span>
</span><span id="FFnetwork.set_parameters-343"><a href="#FFnetwork.set_parameters-343"><span class="linenos">343</span></a><span class="sd">            name (str): The name of the parameter.</span>
</span><span id="FFnetwork.set_parameters-344"><a href="#FFnetwork.set_parameters-344"><span class="linenos">344</span></a><span class="sd">            val (bool): The value to set the parameter to.</span>
</span><span id="FFnetwork.set_parameters-345"><a href="#FFnetwork.set_parameters-345"><span class="linenos">345</span></a>
</span><span id="FFnetwork.set_parameters-346"><a href="#FFnetwork.set_parameters-346"><span class="linenos">346</span></a><span class="sd">        Returns:</span>
</span><span id="FFnetwork.set_parameters-347"><a href="#FFnetwork.set_parameters-347"><span class="linenos">347</span></a><span class="sd">            None</span>
</span><span id="FFnetwork.set_parameters-348"><a href="#FFnetwork.set_parameters-348"><span class="linenos">348</span></a>
</span><span id="FFnetwork.set_parameters-349"><a href="#FFnetwork.set_parameters-349"><span class="linenos">349</span></a><span class="sd">        Raises:</span>
</span><span id="FFnetwork.set_parameters-350"><a href="#FFnetwork.set_parameters-350"><span class="linenos">350</span></a><span class="sd">            AssertionError: If the layer target is invalid.</span>
</span><span id="FFnetwork.set_parameters-351"><a href="#FFnetwork.set_parameters-351"><span class="linenos">351</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FFnetwork.set_parameters-352"><a href="#FFnetwork.set_parameters-352"><span class="linenos">352</span></a>        <span class="k">if</span> <span class="n">layer_target</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FFnetwork.set_parameters-353"><a href="#FFnetwork.set_parameters-353"><span class="linenos">353</span></a>            <span class="n">layer_target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;int32&#39;</span><span class="p">)</span>
</span><span id="FFnetwork.set_parameters-354"><a href="#FFnetwork.set_parameters-354"><span class="linenos">354</span></a>        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer_target</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="FFnetwork.set_parameters-355"><a href="#FFnetwork.set_parameters-355"><span class="linenos">355</span></a>            <span class="n">layer_target</span> <span class="o">=</span> <span class="p">[</span><span class="n">layer_target</span><span class="p">]</span>
</span><span id="FFnetwork.set_parameters-356"><a href="#FFnetwork.set_parameters-356"><span class="linenos">356</span></a>        <span class="k">for</span> <span class="n">nn</span> <span class="ow">in</span> <span class="n">layer_target</span><span class="p">:</span>
</span><span id="FFnetwork.set_parameters-357"><a href="#FFnetwork.set_parameters-357"><span class="linenos">357</span></a>            <span class="k">assert</span> <span class="n">nn</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">),</span> <span class="s1">&#39;  Invalid layer </span><span class="si">%d</span><span class="s1">.&#39;</span><span class="o">%</span><span class="n">nn</span>
</span><span id="FFnetwork.set_parameters-358"><a href="#FFnetwork.set_parameters-358"><span class="linenos">358</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">nn</span><span class="p">]</span><span class="o">.</span><span class="n">set_parameters</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">val</span><span class="o">=</span><span class="n">val</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Sets the parameters for the listed layer or for all layers.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>layer_target (int, optional):</strong>  The layer to set the parameters for. Defaults to None.</li>
<li><strong>name (str):</strong>  The name of the parameter.</li>
<li><strong>val (bool):</strong>  The value to set the parameter to.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>None</p>
</blockquote>

<h6 id="raises">Raises:</h6>

<ul>
<li><strong>AssertionError:</strong>  If the layer target is invalid.</li>
</ul>
</div>


                            </div>
                            <div id="FFnetwork.set_reg_val" class="classattr">
                                        <input id="FFnetwork.set_reg_val-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">set_reg_val</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">reg_type</span><span class="o">=</span><span class="kc">None</span>, </span><span class="param"><span class="n">reg_val</span><span class="o">=</span><span class="kc">None</span>, </span><span class="param"><span class="n">layer_target</span><span class="o">=</span><span class="kc">None</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="FFnetwork.set_reg_val-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FFnetwork.set_reg_val"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FFnetwork.set_reg_val-360"><a href="#FFnetwork.set_reg_val-360"><span class="linenos">360</span></a>    <span class="k">def</span> <span class="nf">set_reg_val</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reg_type</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reg_val</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">layer_target</span><span class="o">=</span><span class="kc">None</span> <span class="p">):</span>
</span><span id="FFnetwork.set_reg_val-361"><a href="#FFnetwork.set_reg_val-361"><span class="linenos">361</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnetwork.set_reg_val-362"><a href="#FFnetwork.set_reg_val-362"><span class="linenos">362</span></a><span class="sd">        Set reg_values for listed layer or for all layers.</span>
</span><span id="FFnetwork.set_reg_val-363"><a href="#FFnetwork.set_reg_val-363"><span class="linenos">363</span></a><span class="sd">        </span>
</span><span id="FFnetwork.set_reg_val-364"><a href="#FFnetwork.set_reg_val-364"><span class="linenos">364</span></a><span class="sd">        Args:</span>
</span><span id="FFnetwork.set_reg_val-365"><a href="#FFnetwork.set_reg_val-365"><span class="linenos">365</span></a><span class="sd">            reg_type (str): The type of regularization to set.</span>
</span><span id="FFnetwork.set_reg_val-366"><a href="#FFnetwork.set_reg_val-366"><span class="linenos">366</span></a><span class="sd">            reg_val (float): The value to set the regularization to.</span>
</span><span id="FFnetwork.set_reg_val-367"><a href="#FFnetwork.set_reg_val-367"><span class="linenos">367</span></a><span class="sd">            layer_target (int, optional): The layer to set the regularization for. Defaults to None.</span>
</span><span id="FFnetwork.set_reg_val-368"><a href="#FFnetwork.set_reg_val-368"><span class="linenos">368</span></a>
</span><span id="FFnetwork.set_reg_val-369"><a href="#FFnetwork.set_reg_val-369"><span class="linenos">369</span></a><span class="sd">        Returns:</span>
</span><span id="FFnetwork.set_reg_val-370"><a href="#FFnetwork.set_reg_val-370"><span class="linenos">370</span></a><span class="sd">            None</span>
</span><span id="FFnetwork.set_reg_val-371"><a href="#FFnetwork.set_reg_val-371"><span class="linenos">371</span></a>
</span><span id="FFnetwork.set_reg_val-372"><a href="#FFnetwork.set_reg_val-372"><span class="linenos">372</span></a><span class="sd">        Raises:</span>
</span><span id="FFnetwork.set_reg_val-373"><a href="#FFnetwork.set_reg_val-373"><span class="linenos">373</span></a><span class="sd">            AssertionError: If the layer target is invalid.</span>
</span><span id="FFnetwork.set_reg_val-374"><a href="#FFnetwork.set_reg_val-374"><span class="linenos">374</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FFnetwork.set_reg_val-375"><a href="#FFnetwork.set_reg_val-375"><span class="linenos">375</span></a>        <span class="k">if</span> <span class="n">layer_target</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FFnetwork.set_reg_val-376"><a href="#FFnetwork.set_reg_val-376"><span class="linenos">376</span></a>            <span class="n">layer_target</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="FFnetwork.set_reg_val-377"><a href="#FFnetwork.set_reg_val-377"><span class="linenos">377</span></a>        <span class="k">assert</span> <span class="n">layer_target</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">),</span> <span class="s2">&quot;layer target too large (max = </span><span class="si">%d</span><span class="s2">)&quot;</span><span class="o">%</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span>
</span><span id="FFnetwork.set_reg_val-378"><a href="#FFnetwork.set_reg_val-378"><span class="linenos">378</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">layer_target</span><span class="p">]</span><span class="o">.</span><span class="n">set_reg_val</span><span class="p">(</span> <span class="n">reg_type</span><span class="o">=</span><span class="n">reg_type</span><span class="p">,</span> <span class="n">reg_val</span><span class="o">=</span><span class="n">reg_val</span> <span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Set reg_values for listed layer or for all layers.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>reg_type (str):</strong>  The type of regularization to set.</li>
<li><strong>reg_val (float):</strong>  The value to set the regularization to.</li>
<li><strong>layer_target (int, optional):</strong>  The layer to set the regularization for. Defaults to None.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>None</p>
</blockquote>

<h6 id="raises">Raises:</h6>

<ul>
<li><strong>AssertionError:</strong>  If the layer target is invalid.</li>
</ul>
</div>


                            </div>
                            <div id="FFnetwork.plot_filters" class="classattr">
                                        <input id="FFnetwork.plot_filters-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">plot_filters</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">layer_target</span><span class="o">=</span><span class="mi">0</span>, </span><span class="param"><span class="o">**</span><span class="n">kwargs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="FFnetwork.plot_filters-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FFnetwork.plot_filters"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FFnetwork.plot_filters-380"><a href="#FFnetwork.plot_filters-380"><span class="linenos">380</span></a>    <span class="k">def</span> <span class="nf">plot_filters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer_target</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="FFnetwork.plot_filters-381"><a href="#FFnetwork.plot_filters-381"><span class="linenos">381</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnetwork.plot_filters-382"><a href="#FFnetwork.plot_filters-382"><span class="linenos">382</span></a><span class="sd">        Plots the filters for the listed layer.</span>
</span><span id="FFnetwork.plot_filters-383"><a href="#FFnetwork.plot_filters-383"><span class="linenos">383</span></a>
</span><span id="FFnetwork.plot_filters-384"><a href="#FFnetwork.plot_filters-384"><span class="linenos">384</span></a><span class="sd">        Args:</span>
</span><span id="FFnetwork.plot_filters-385"><a href="#FFnetwork.plot_filters-385"><span class="linenos">385</span></a><span class="sd">            layer_target (int, optional): The layer to plot the filters for. Defaults to 0.</span>
</span><span id="FFnetwork.plot_filters-386"><a href="#FFnetwork.plot_filters-386"><span class="linenos">386</span></a><span class="sd">            **kwargs: Additional keyword arguments.</span>
</span><span id="FFnetwork.plot_filters-387"><a href="#FFnetwork.plot_filters-387"><span class="linenos">387</span></a>
</span><span id="FFnetwork.plot_filters-388"><a href="#FFnetwork.plot_filters-388"><span class="linenos">388</span></a><span class="sd">        Returns:</span>
</span><span id="FFnetwork.plot_filters-389"><a href="#FFnetwork.plot_filters-389"><span class="linenos">389</span></a><span class="sd">            None</span>
</span><span id="FFnetwork.plot_filters-390"><a href="#FFnetwork.plot_filters-390"><span class="linenos">390</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FFnetwork.plot_filters-391"><a href="#FFnetwork.plot_filters-391"><span class="linenos">391</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">layer_target</span><span class="p">]</span><span class="o">.</span><span class="n">plot_filters</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Plots the filters for the listed layer.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>layer_target (int, optional):</strong>  The layer to plot the filters for. Defaults to 0.</li>
<li><strong>**kwargs:</strong>  Additional keyword arguments.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>None</p>
</blockquote>
</div>


                            </div>
                            <div id="FFnetwork.get_weights" class="classattr">
                                        <input id="FFnetwork.get_weights-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">get_weights</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">layer_target</span><span class="o">=</span><span class="mi">0</span>, </span><span class="param"><span class="o">**</span><span class="n">kwargs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="FFnetwork.get_weights-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FFnetwork.get_weights"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FFnetwork.get_weights-393"><a href="#FFnetwork.get_weights-393"><span class="linenos">393</span></a>    <span class="k">def</span> <span class="nf">get_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer_target</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="FFnetwork.get_weights-394"><a href="#FFnetwork.get_weights-394"><span class="linenos">394</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnetwork.get_weights-395"><a href="#FFnetwork.get_weights-395"><span class="linenos">395</span></a><span class="sd">        Passed down to layer call, with optional arguments conveyed.</span>
</span><span id="FFnetwork.get_weights-396"><a href="#FFnetwork.get_weights-396"><span class="linenos">396</span></a><span class="sd">        </span>
</span><span id="FFnetwork.get_weights-397"><a href="#FFnetwork.get_weights-397"><span class="linenos">397</span></a><span class="sd">        Args:</span>
</span><span id="FFnetwork.get_weights-398"><a href="#FFnetwork.get_weights-398"><span class="linenos">398</span></a><span class="sd">            layer_target (int): The layer to get the weights for.</span>
</span><span id="FFnetwork.get_weights-399"><a href="#FFnetwork.get_weights-399"><span class="linenos">399</span></a><span class="sd">            **kwargs: Additional keyword arguments.</span>
</span><span id="FFnetwork.get_weights-400"><a href="#FFnetwork.get_weights-400"><span class="linenos">400</span></a>
</span><span id="FFnetwork.get_weights-401"><a href="#FFnetwork.get_weights-401"><span class="linenos">401</span></a><span class="sd">        Returns:</span>
</span><span id="FFnetwork.get_weights-402"><a href="#FFnetwork.get_weights-402"><span class="linenos">402</span></a><span class="sd">            The weights for the specified layer.</span>
</span><span id="FFnetwork.get_weights-403"><a href="#FFnetwork.get_weights-403"><span class="linenos">403</span></a>
</span><span id="FFnetwork.get_weights-404"><a href="#FFnetwork.get_weights-404"><span class="linenos">404</span></a><span class="sd">        Raises:</span>
</span><span id="FFnetwork.get_weights-405"><a href="#FFnetwork.get_weights-405"><span class="linenos">405</span></a><span class="sd">            AssertionError: If the layer target is invalid.</span>
</span><span id="FFnetwork.get_weights-406"><a href="#FFnetwork.get_weights-406"><span class="linenos">406</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FFnetwork.get_weights-407"><a href="#FFnetwork.get_weights-407"><span class="linenos">407</span></a>        <span class="k">assert</span> <span class="n">layer_target</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">),</span> <span class="s2">&quot;Invalid layer_target </span><span class="si">%d</span><span class="s2">&quot;</span><span class="o">%</span><span class="n">layer_target</span>
</span><span id="FFnetwork.get_weights-408"><a href="#FFnetwork.get_weights-408"><span class="linenos">408</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">layer_target</span><span class="p">]</span><span class="o">.</span><span class="n">get_weights</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Passed down to layer call, with optional arguments conveyed.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>layer_target (int):</strong>  The layer to get the weights for.</li>
<li><strong>**kwargs:</strong>  Additional keyword arguments.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>The weights for the specified layer.</p>
</blockquote>

<h6 id="raises">Raises:</h6>

<ul>
<li><strong>AssertionError:</strong>  If the layer target is invalid.</li>
</ul>
</div>


                            </div>
                            <div id="FFnetwork.ffnet_dict" class="classattr">
                                        <input id="FFnetwork.ffnet_dict-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator">@classmethod</div>

        <span class="def">def</span>
        <span class="name">ffnet_dict</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">cls</span>,</span><span class="param">	<span class="n">layer_list</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">xstim_n</span><span class="o">=</span><span class="s1">&#39;stim&#39;</span>,</span><span class="param">	<span class="n">ffnet_n</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">ffnet_type</span><span class="o">=</span><span class="s1">&#39;normal&#39;</span>,</span><span class="param">	<span class="n">scaffold_levels</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">num_lags_out</span><span class="o">=</span><span class="mi">1</span>,</span><span class="param">	<span class="o">**</span><span class="n">kwargs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="FFnetwork.ffnet_dict-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FFnetwork.ffnet_dict"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FFnetwork.ffnet_dict-410"><a href="#FFnetwork.ffnet_dict-410"><span class="linenos">410</span></a>    <span class="nd">@classmethod</span>
</span><span id="FFnetwork.ffnet_dict-411"><a href="#FFnetwork.ffnet_dict-411"><span class="linenos">411</span></a>    <span class="k">def</span> <span class="nf">ffnet_dict</span><span class="p">(</span> <span class="bp">cls</span><span class="p">,</span> <span class="n">layer_list</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">xstim_n</span> <span class="o">=</span><span class="s1">&#39;stim&#39;</span><span class="p">,</span> <span class="n">ffnet_n</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ffnet_type</span><span class="o">=</span><span class="s1">&#39;normal&#39;</span><span class="p">,</span> <span class="n">scaffold_levels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_lags_out</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="FFnetwork.ffnet_dict-412"><a href="#FFnetwork.ffnet_dict-412"><span class="linenos">412</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnetwork.ffnet_dict-413"><a href="#FFnetwork.ffnet_dict-413"><span class="linenos">413</span></a><span class="sd">        Returns a dictionary of the feedforward network.</span>
</span><span id="FFnetwork.ffnet_dict-414"><a href="#FFnetwork.ffnet_dict-414"><span class="linenos">414</span></a>
</span><span id="FFnetwork.ffnet_dict-415"><a href="#FFnetwork.ffnet_dict-415"><span class="linenos">415</span></a><span class="sd">        Args:</span>
</span><span id="FFnetwork.ffnet_dict-416"><a href="#FFnetwork.ffnet_dict-416"><span class="linenos">416</span></a><span class="sd">            layer_list (list): A list of dictionaries representing the layers of the network.</span>
</span><span id="FFnetwork.ffnet_dict-417"><a href="#FFnetwork.ffnet_dict-417"><span class="linenos">417</span></a><span class="sd">            xstim_n (str): The name of the stimulus input.</span>
</span><span id="FFnetwork.ffnet_dict-418"><a href="#FFnetwork.ffnet_dict-418"><span class="linenos">418</span></a><span class="sd">            ffnet_n (list): A list of feedforward networks.</span>
</span><span id="FFnetwork.ffnet_dict-419"><a href="#FFnetwork.ffnet_dict-419"><span class="linenos">419</span></a><span class="sd">            ffnet_type (str): The type of the feedforward network.</span>
</span><span id="FFnetwork.ffnet_dict-420"><a href="#FFnetwork.ffnet_dict-420"><span class="linenos">420</span></a><span class="sd">            scaffold_levels (list): A list of scaffold levels.</span>
</span><span id="FFnetwork.ffnet_dict-421"><a href="#FFnetwork.ffnet_dict-421"><span class="linenos">421</span></a><span class="sd">            num_lags_out (int): The number of lags out.</span>
</span><span id="FFnetwork.ffnet_dict-422"><a href="#FFnetwork.ffnet_dict-422"><span class="linenos">422</span></a><span class="sd">            **kwargs: Additional keyword arguments.</span>
</span><span id="FFnetwork.ffnet_dict-423"><a href="#FFnetwork.ffnet_dict-423"><span class="linenos">423</span></a>
</span><span id="FFnetwork.ffnet_dict-424"><a href="#FFnetwork.ffnet_dict-424"><span class="linenos">424</span></a><span class="sd">        Returns:</span>
</span><span id="FFnetwork.ffnet_dict-425"><a href="#FFnetwork.ffnet_dict-425"><span class="linenos">425</span></a><span class="sd">            ffnet_dict (dict): The dictionary of the feedforward network.</span>
</span><span id="FFnetwork.ffnet_dict-426"><a href="#FFnetwork.ffnet_dict-426"><span class="linenos">426</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FFnetwork.ffnet_dict-427"><a href="#FFnetwork.ffnet_dict-427"><span class="linenos">427</span></a>        <span class="k">return</span> <span class="p">{</span>
</span><span id="FFnetwork.ffnet_dict-428"><a href="#FFnetwork.ffnet_dict-428"><span class="linenos">428</span></a>            <span class="s1">&#39;ffnet_type&#39;</span><span class="p">:</span> <span class="n">ffnet_type</span><span class="p">,</span>
</span><span id="FFnetwork.ffnet_dict-429"><a href="#FFnetwork.ffnet_dict-429"><span class="linenos">429</span></a>            <span class="s1">&#39;xstim_n&#39;</span><span class="p">:</span><span class="n">xstim_n</span><span class="p">,</span> <span class="s1">&#39;ffnet_n&#39;</span><span class="p">:</span><span class="n">ffnet_n</span><span class="p">,</span>
</span><span id="FFnetwork.ffnet_dict-430"><a href="#FFnetwork.ffnet_dict-430"><span class="linenos">430</span></a>            <span class="s1">&#39;layer_list&#39;</span><span class="p">:</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">layer_list</span><span class="p">),</span>
</span><span id="FFnetwork.ffnet_dict-431"><a href="#FFnetwork.ffnet_dict-431"><span class="linenos">431</span></a>            <span class="s1">&#39;scaffold_levels&#39;</span><span class="p">:</span> <span class="n">scaffold_levels</span><span class="p">,</span>
</span><span id="FFnetwork.ffnet_dict-432"><a href="#FFnetwork.ffnet_dict-432"><span class="linenos">432</span></a>            <span class="s1">&#39;num_lags_out&#39;</span><span class="p">:</span> <span class="n">num_lags_out</span><span class="p">}</span>
</span></pre></div>


            <div class="docstring"><p>Returns a dictionary of the feedforward network.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>layer_list (list):</strong>  A list of dictionaries representing the layers of the network.</li>
<li><strong>xstim_n (str):</strong>  The name of the stimulus input.</li>
<li><strong>ffnet_n (list):</strong>  A list of feedforward networks.</li>
<li><strong>ffnet_type (str):</strong>  The type of the feedforward network.</li>
<li><strong>scaffold_levels (list):</strong>  A list of scaffold levels.</li>
<li><strong>num_lags_out (int):</strong>  The number of lags out.</li>
<li><strong>**kwargs:</strong>  Additional keyword arguments.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>ffnet_dict (dict): The dictionary of the feedforward network.</p>
</blockquote>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="FFnetwork.dump_patches" class="variable">dump_patches</dd>
                <dd id="FFnetwork.training" class="variable">training</dd>
                <dd id="FFnetwork.call_super_init" class="variable">call_super_init</dd>
                <dd id="FFnetwork.register_buffer" class="function">register_buffer</dd>
                <dd id="FFnetwork.register_parameter" class="function">register_parameter</dd>
                <dd id="FFnetwork.add_module" class="function">add_module</dd>
                <dd id="FFnetwork.register_module" class="function">register_module</dd>
                <dd id="FFnetwork.get_submodule" class="function">get_submodule</dd>
                <dd id="FFnetwork.get_parameter" class="function">get_parameter</dd>
                <dd id="FFnetwork.get_buffer" class="function">get_buffer</dd>
                <dd id="FFnetwork.get_extra_state" class="function">get_extra_state</dd>
                <dd id="FFnetwork.set_extra_state" class="function">set_extra_state</dd>
                <dd id="FFnetwork.apply" class="function">apply</dd>
                <dd id="FFnetwork.cuda" class="function">cuda</dd>
                <dd id="FFnetwork.ipu" class="function">ipu</dd>
                <dd id="FFnetwork.xpu" class="function">xpu</dd>
                <dd id="FFnetwork.cpu" class="function">cpu</dd>
                <dd id="FFnetwork.type" class="function">type</dd>
                <dd id="FFnetwork.float" class="function">float</dd>
                <dd id="FFnetwork.double" class="function">double</dd>
                <dd id="FFnetwork.half" class="function">half</dd>
                <dd id="FFnetwork.bfloat16" class="function">bfloat16</dd>
                <dd id="FFnetwork.to_empty" class="function">to_empty</dd>
                <dd id="FFnetwork.to" class="function">to</dd>
                <dd id="FFnetwork.register_full_backward_pre_hook" class="function">register_full_backward_pre_hook</dd>
                <dd id="FFnetwork.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="FFnetwork.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="FFnetwork.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="FFnetwork.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="FFnetwork.register_state_dict_pre_hook" class="function">register_state_dict_pre_hook</dd>
                <dd id="FFnetwork.state_dict" class="function">state_dict</dd>
                <dd id="FFnetwork.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="FFnetwork.load_state_dict" class="function">load_state_dict</dd>
                <dd id="FFnetwork.parameters" class="function">parameters</dd>
                <dd id="FFnetwork.named_parameters" class="function">named_parameters</dd>
                <dd id="FFnetwork.buffers" class="function">buffers</dd>
                <dd id="FFnetwork.named_buffers" class="function">named_buffers</dd>
                <dd id="FFnetwork.children" class="function">children</dd>
                <dd id="FFnetwork.named_children" class="function">named_children</dd>
                <dd id="FFnetwork.modules" class="function">modules</dd>
                <dd id="FFnetwork.named_modules" class="function">named_modules</dd>
                <dd id="FFnetwork.train" class="function">train</dd>
                <dd id="FFnetwork.eval" class="function">eval</dd>
                <dd id="FFnetwork.requires_grad_" class="function">requires_grad_</dd>
                <dd id="FFnetwork.zero_grad" class="function">zero_grad</dd>
                <dd id="FFnetwork.share_memory" class="function">share_memory</dd>
                <dd id="FFnetwork.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="ScaffoldNetwork">
                            <input id="ScaffoldNetwork-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">ScaffoldNetwork</span><wbr>(<span class="base"><a href="#FFnetwork">FFnetwork</a></span>):

                <label class="view-source-button" for="ScaffoldNetwork-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ScaffoldNetwork"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ScaffoldNetwork-436"><a href="#ScaffoldNetwork-436"><span class="linenos">436</span></a><span class="k">class</span> <span class="nc">ScaffoldNetwork</span><span class="p">(</span><span class="n">FFnetwork</span><span class="p">):</span>
</span><span id="ScaffoldNetwork-437"><a href="#ScaffoldNetwork-437"><span class="linenos">437</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ScaffoldNetwork-438"><a href="#ScaffoldNetwork-438"><span class="linenos">438</span></a><span class="sd">    Concatenates output of all layers together in filter dimension, preserving spatial dims.</span>
</span><span id="ScaffoldNetwork-439"><a href="#ScaffoldNetwork-439"><span class="linenos">439</span></a>
</span><span id="ScaffoldNetwork-440"><a href="#ScaffoldNetwork-440"><span class="linenos">440</span></a><span class="sd">    This essentially used the constructor for Point1DGaussian, with dicationary input.</span>
</span><span id="ScaffoldNetwork-441"><a href="#ScaffoldNetwork-441"><span class="linenos">441</span></a><span class="sd">    Currently there is no extra code required at the network level. I think the constructor</span>
</span><span id="ScaffoldNetwork-442"><a href="#ScaffoldNetwork-442"><span class="linenos">442</span></a><span class="sd">    can be left off entirely, but leaving in in case want to add something.</span>
</span><span id="ScaffoldNetwork-443"><a href="#ScaffoldNetwork-443"><span class="linenos">443</span></a>
</span><span id="ScaffoldNetwork-444"><a href="#ScaffoldNetwork-444"><span class="linenos">444</span></a><span class="sd">    Args:</span>
</span><span id="ScaffoldNetwork-445"><a href="#ScaffoldNetwork-445"><span class="linenos">445</span></a><span class="sd">        scaffold_levels (list): A list of scaffold levels.</span>
</span><span id="ScaffoldNetwork-446"><a href="#ScaffoldNetwork-446"><span class="linenos">446</span></a><span class="sd">        num_lags_out (int): The number of lags out.</span>
</span><span id="ScaffoldNetwork-447"><a href="#ScaffoldNetwork-447"><span class="linenos">447</span></a>
</span><span id="ScaffoldNetwork-448"><a href="#ScaffoldNetwork-448"><span class="linenos">448</span></a><span class="sd">    Raises:</span>
</span><span id="ScaffoldNetwork-449"><a href="#ScaffoldNetwork-449"><span class="linenos">449</span></a><span class="sd">        AssertionError: If the scaffold levels are invalid.</span>
</span><span id="ScaffoldNetwork-450"><a href="#ScaffoldNetwork-450"><span class="linenos">450</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="ScaffoldNetwork-451"><a href="#ScaffoldNetwork-451"><span class="linenos">451</span></a>
</span><span id="ScaffoldNetwork-452"><a href="#ScaffoldNetwork-452"><span class="linenos">452</span></a>    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="ScaffoldNetwork-453"><a href="#ScaffoldNetwork-453"><span class="linenos">453</span></a>        <span class="n">s</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__repr__</span><span class="p">()</span>
</span><span id="ScaffoldNetwork-454"><a href="#ScaffoldNetwork-454"><span class="linenos">454</span></a>        <span class="c1"># Add information about module to print out</span>
</span><span id="ScaffoldNetwork-455"><a href="#ScaffoldNetwork-455"><span class="linenos">455</span></a>        <span class="n">s</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
</span><span id="ScaffoldNetwork-456"><a href="#ScaffoldNetwork-456"><span class="linenos">456</span></a>        <span class="k">return</span> <span class="n">s</span>
</span><span id="ScaffoldNetwork-457"><a href="#ScaffoldNetwork-457"><span class="linenos">457</span></a>
</span><span id="ScaffoldNetwork-458"><a href="#ScaffoldNetwork-458"><span class="linenos">458</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scaffold_levels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_lags_out</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="ScaffoldNetwork-459"><a href="#ScaffoldNetwork-459"><span class="linenos">459</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="ScaffoldNetwork-460"><a href="#ScaffoldNetwork-460"><span class="linenos">460</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">network_type</span> <span class="o">=</span> <span class="s1">&#39;scaffold&#39;</span>
</span><span id="ScaffoldNetwork-461"><a href="#ScaffoldNetwork-461"><span class="linenos">461</span></a>
</span><span id="ScaffoldNetwork-462"><a href="#ScaffoldNetwork-462"><span class="linenos">462</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_lags_out</span> <span class="o">=</span> <span class="n">num_lags_out</span>
</span><span id="ScaffoldNetwork-463"><a href="#ScaffoldNetwork-463"><span class="linenos">463</span></a>
</span><span id="ScaffoldNetwork-464"><a href="#ScaffoldNetwork-464"><span class="linenos">464</span></a>        <span class="n">num_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span>
</span><span id="ScaffoldNetwork-465"><a href="#ScaffoldNetwork-465"><span class="linenos">465</span></a>        <span class="k">if</span> <span class="n">scaffold_levels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ScaffoldNetwork-466"><a href="#ScaffoldNetwork-466"><span class="linenos">466</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)</span>
</span><span id="ScaffoldNetwork-467"><a href="#ScaffoldNetwork-467"><span class="linenos">467</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="ScaffoldNetwork-468"><a href="#ScaffoldNetwork-468"><span class="linenos">468</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scaffold_levels</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="ScaffoldNetwork-469"><a href="#ScaffoldNetwork-469"><span class="linenos">469</span></a>                <span class="n">scaffold_levels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">scaffold_levels</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
</span><span id="ScaffoldNetwork-470"><a href="#ScaffoldNetwork-470"><span class="linenos">470</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span> <span class="o">=</span> <span class="n">scaffold_levels</span> 
</span><span id="ScaffoldNetwork-471"><a href="#ScaffoldNetwork-471"><span class="linenos">471</span></a>        <span class="c1"># Determine output dimensions</span>
</span><span id="ScaffoldNetwork-472"><a href="#ScaffoldNetwork-472"><span class="linenos">472</span></a>        <span class="c1">#assert self.layers[self.scaffold_levels[0]].output_dims[3] == 1, &quot;Scaffold: cannot currently handle lag dimensions&quot;</span>
</span><span id="ScaffoldNetwork-473"><a href="#ScaffoldNetwork-473"><span class="linenos">473</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">spatial_dims</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">output_dims</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span>
</span><span id="ScaffoldNetwork-474"><a href="#ScaffoldNetwork-474"><span class="linenos">474</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">filter_count</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">))</span>
</span><span id="ScaffoldNetwork-475"><a href="#ScaffoldNetwork-475"><span class="linenos">475</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">filter_count</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">output_dims</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ScaffoldNetwork-476"><a href="#ScaffoldNetwork-476"><span class="linenos">476</span></a>
</span><span id="ScaffoldNetwork-477"><a href="#ScaffoldNetwork-477"><span class="linenos">477</span></a>        <span class="c1">#Tchomps = np.zeros(self.scaffold_levels)</span>
</span><span id="ScaffoldNetwork-478"><a href="#ScaffoldNetwork-478"><span class="linenos">478</span></a>        <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">)):</span>
</span><span id="ScaffoldNetwork-479"><a href="#ScaffoldNetwork-479"><span class="linenos">479</span></a>            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">[</span><span class="n">ii</span><span class="p">]]</span><span class="o">.</span><span class="n">output_dims</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">spatial_dims</span><span class="p">,</span> <span class="s2">&quot;Spatial dims problem layer </span><span class="si">%d</span><span class="s2">&quot;</span><span class="o">%</span><span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span> 
</span><span id="ScaffoldNetwork-480"><a href="#ScaffoldNetwork-480"><span class="linenos">480</span></a>            <span class="c1">#assert self.layers[self.scaffold_levels[ii]].output_dims[3] == 1, &quot;Scaffold: cannot currently handle lag dimensions&quot;</span>
</span><span id="ScaffoldNetwork-481"><a href="#ScaffoldNetwork-481"><span class="linenos">481</span></a>            <span class="c1">#if self.layers[self.scaffold_levels[ii]].output_dims[3] &gt; 1:</span>
</span><span id="ScaffoldNetwork-482"><a href="#ScaffoldNetwork-482"><span class="linenos">482</span></a>            <span class="c1">#    Tchomps[ii] = self.layers[self.scaffold_levels[ii]].output_dims[3]-1</span>
</span><span id="ScaffoldNetwork-483"><a href="#ScaffoldNetwork-483"><span class="linenos">483</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">filter_count</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">[</span><span class="n">ii</span><span class="p">]]</span><span class="o">.</span><span class="n">output_dims</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ScaffoldNetwork-484"><a href="#ScaffoldNetwork-484"><span class="linenos">484</span></a>
</span><span id="ScaffoldNetwork-485"><a href="#ScaffoldNetwork-485"><span class="linenos">485</span></a>        <span class="c1"># Construct output dimensions</span>
</span><span id="ScaffoldNetwork-486"><a href="#ScaffoldNetwork-486"><span class="linenos">486</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_lags_out</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ScaffoldNetwork-487"><a href="#ScaffoldNetwork-487"><span class="linenos">487</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">output_dims</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filter_count</span><span class="p">))]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">spatial_dims</span> <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">num_lags_out</span><span class="p">]</span>
</span><span id="ScaffoldNetwork-488"><a href="#ScaffoldNetwork-488"><span class="linenos">488</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="ScaffoldNetwork-489"><a href="#ScaffoldNetwork-489"><span class="linenos">489</span></a>            <span class="n">scaffold_lags</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">[</span><span class="n">ii</span><span class="p">]]</span><span class="o">.</span><span class="n">output_dims</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">))]</span>
</span><span id="ScaffoldNetwork-490"><a href="#ScaffoldNetwork-490"><span class="linenos">490</span></a>            <span class="c1"># assert that all scaffold_lags are the same</span>
</span><span id="ScaffoldNetwork-491"><a href="#ScaffoldNetwork-491"><span class="linenos">491</span></a>            <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">scaffold_lags</span><span class="p">)</span> <span class="o">==</span> <span class="n">scaffold_lags</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="s2">&quot;Scaffold: cannot currently handle different lag dimensions&quot;</span>
</span><span id="ScaffoldNetwork-492"><a href="#ScaffoldNetwork-492"><span class="linenos">492</span></a>            <span class="n">filter_x_lag</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filter_count</span><span class="p">))</span> <span class="o">*</span> <span class="n">scaffold_lags</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ScaffoldNetwork-493"><a href="#ScaffoldNetwork-493"><span class="linenos">493</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">output_dims</span> <span class="o">=</span> <span class="p">[</span><span class="n">filter_x_lag</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">spatial_dims</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="ScaffoldNetwork-494"><a href="#ScaffoldNetwork-494"><span class="linenos">494</span></a>    <span class="c1"># END ScaffoldNetwork.__init__</span>
</span><span id="ScaffoldNetwork-495"><a href="#ScaffoldNetwork-495"><span class="linenos">495</span></a>
</span><span id="ScaffoldNetwork-496"><a href="#ScaffoldNetwork-496"><span class="linenos">496</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="ScaffoldNetwork-497"><a href="#ScaffoldNetwork-497"><span class="linenos">497</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ScaffoldNetwork-498"><a href="#ScaffoldNetwork-498"><span class="linenos">498</span></a><span class="sd">        Forward pass through the network.</span>
</span><span id="ScaffoldNetwork-499"><a href="#ScaffoldNetwork-499"><span class="linenos">499</span></a>
</span><span id="ScaffoldNetwork-500"><a href="#ScaffoldNetwork-500"><span class="linenos">500</span></a><span class="sd">        Args:</span>
</span><span id="ScaffoldNetwork-501"><a href="#ScaffoldNetwork-501"><span class="linenos">501</span></a><span class="sd">            inputs (list, torch.Tensor): The input to the network.</span>
</span><span id="ScaffoldNetwork-502"><a href="#ScaffoldNetwork-502"><span class="linenos">502</span></a>
</span><span id="ScaffoldNetwork-503"><a href="#ScaffoldNetwork-503"><span class="linenos">503</span></a><span class="sd">        Returns:</span>
</span><span id="ScaffoldNetwork-504"><a href="#ScaffoldNetwork-504"><span class="linenos">504</span></a><span class="sd">            x (torch.Tensor): The output of the network.</span>
</span><span id="ScaffoldNetwork-505"><a href="#ScaffoldNetwork-505"><span class="linenos">505</span></a>
</span><span id="ScaffoldNetwork-506"><a href="#ScaffoldNetwork-506"><span class="linenos">506</span></a><span class="sd">        Raises:</span>
</span><span id="ScaffoldNetwork-507"><a href="#ScaffoldNetwork-507"><span class="linenos">507</span></a><span class="sd">            ValueError: If no layers are defined.</span>
</span><span id="ScaffoldNetwork-508"><a href="#ScaffoldNetwork-508"><span class="linenos">508</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ScaffoldNetwork-509"><a href="#ScaffoldNetwork-509"><span class="linenos">509</span></a>
</span><span id="ScaffoldNetwork-510"><a href="#ScaffoldNetwork-510"><span class="linenos">510</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ScaffoldNetwork-511"><a href="#ScaffoldNetwork-511"><span class="linenos">511</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Scaffold: no layers defined.&quot;</span><span class="p">)</span>
</span><span id="ScaffoldNetwork-512"><a href="#ScaffoldNetwork-512"><span class="linenos">512</span></a>        
</span><span id="ScaffoldNetwork-513"><a href="#ScaffoldNetwork-513"><span class="linenos">513</span></a>        <span class="n">out</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># returned </span>
</span><span id="ScaffoldNetwork-514"><a href="#ScaffoldNetwork-514"><span class="linenos">514</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess_input</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="ScaffoldNetwork-515"><a href="#ScaffoldNetwork-515"><span class="linenos">515</span></a>
</span><span id="ScaffoldNetwork-516"><a href="#ScaffoldNetwork-516"><span class="linenos">516</span></a>        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
</span><span id="ScaffoldNetwork-517"><a href="#ScaffoldNetwork-517"><span class="linenos">517</span></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="ScaffoldNetwork-518"><a href="#ScaffoldNetwork-518"><span class="linenos">518</span></a>            <span class="n">nt</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ScaffoldNetwork-519"><a href="#ScaffoldNetwork-519"><span class="linenos">519</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_lags_out</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">layer</span><span class="o">.</span><span class="n">output_dims</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="ScaffoldNetwork-520"><a href="#ScaffoldNetwork-520"><span class="linenos">520</span></a>                <span class="c1"># reshape y to combine the filters and lags in the second dimension</span>
</span><span id="ScaffoldNetwork-521"><a href="#ScaffoldNetwork-521"><span class="linenos">521</span></a>                <span class="c1"># batch x filters x (width x height) x lags</span>
</span><span id="ScaffoldNetwork-522"><a href="#ScaffoldNetwork-522"><span class="linenos">522</span></a>                <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="n">nt</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">output_dims</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">output_dims</span><span class="p">[</span><span class="mi">3</span><span class="p">]])</span>
</span><span id="ScaffoldNetwork-523"><a href="#ScaffoldNetwork-523"><span class="linenos">523</span></a>                <span class="c1"># move the lag dimension after the filters (batch, filter, lag, width x height)</span>
</span><span id="ScaffoldNetwork-524"><a href="#ScaffoldNetwork-524"><span class="linenos">524</span></a>                <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span><span id="ScaffoldNetwork-525"><a href="#ScaffoldNetwork-525"><span class="linenos">525</span></a>                <span class="c1"># flatten the filter and lag dimensions to be filters x lags</span>
</span><span id="ScaffoldNetwork-526"><a href="#ScaffoldNetwork-526"><span class="linenos">526</span></a>                <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="n">nt</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span><span id="ScaffoldNetwork-527"><a href="#ScaffoldNetwork-527"><span class="linenos">527</span></a>                <span class="n">out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span><span id="ScaffoldNetwork-528"><a href="#ScaffoldNetwork-528"><span class="linenos">528</span></a>            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_lags_out</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">layer</span><span class="o">.</span><span class="n">output_dims</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_lags_out</span><span class="p">:</span>
</span><span id="ScaffoldNetwork-529"><a href="#ScaffoldNetwork-529"><span class="linenos">529</span></a>                <span class="c1"># Need to return just first lag (lag0) -- &#39;chomp&#39;</span>
</span><span id="ScaffoldNetwork-530"><a href="#ScaffoldNetwork-530"><span class="linenos">530</span></a>                <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="n">nt</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">output_dims</span><span class="p">[</span><span class="mi">3</span><span class="p">]])[</span><span class="o">...</span><span class="p">,</span> <span class="p">:(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_lags_out</span><span class="p">)]</span>
</span><span id="ScaffoldNetwork-531"><a href="#ScaffoldNetwork-531"><span class="linenos">531</span></a>                <span class="n">out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">nt</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="p">))</span>
</span><span id="ScaffoldNetwork-532"><a href="#ScaffoldNetwork-532"><span class="linenos">532</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="ScaffoldNetwork-533"><a href="#ScaffoldNetwork-533"><span class="linenos">533</span></a>                <span class="n">out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="ScaffoldNetwork-534"><a href="#ScaffoldNetwork-534"><span class="linenos">534</span></a>        
</span><span id="ScaffoldNetwork-535"><a href="#ScaffoldNetwork-535"><span class="linenos">535</span></a>        <span class="c1"># this concatentates across the filter dimension</span>
</span><span id="ScaffoldNetwork-536"><a href="#ScaffoldNetwork-536"><span class="linenos">536</span></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">out</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="ScaffoldNetwork-537"><a href="#ScaffoldNetwork-537"><span class="linenos">537</span></a>    <span class="c1"># END ScaffoldNetwork.forward()</span>
</span><span id="ScaffoldNetwork-538"><a href="#ScaffoldNetwork-538"><span class="linenos">538</span></a>
</span><span id="ScaffoldNetwork-539"><a href="#ScaffoldNetwork-539"><span class="linenos">539</span></a>    <span class="nd">@classmethod</span>
</span><span id="ScaffoldNetwork-540"><a href="#ScaffoldNetwork-540"><span class="linenos">540</span></a>    <span class="k">def</span> <span class="nf">ffnet_dict</span><span class="p">(</span> <span class="bp">cls</span><span class="p">,</span> <span class="n">scaffold_levels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_lags_out</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="ScaffoldNetwork-541"><a href="#ScaffoldNetwork-541"><span class="linenos">541</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ScaffoldNetwork-542"><a href="#ScaffoldNetwork-542"><span class="linenos">542</span></a><span class="sd">        Returns a dictionary of the scaffold network.</span>
</span><span id="ScaffoldNetwork-543"><a href="#ScaffoldNetwork-543"><span class="linenos">543</span></a>
</span><span id="ScaffoldNetwork-544"><a href="#ScaffoldNetwork-544"><span class="linenos">544</span></a><span class="sd">        Args:</span>
</span><span id="ScaffoldNetwork-545"><a href="#ScaffoldNetwork-545"><span class="linenos">545</span></a><span class="sd">            scaffold_levels (list): A list of scaffold levels.</span>
</span><span id="ScaffoldNetwork-546"><a href="#ScaffoldNetwork-546"><span class="linenos">546</span></a><span class="sd">            num_lags_out (int): The number of lags out.</span>
</span><span id="ScaffoldNetwork-547"><a href="#ScaffoldNetwork-547"><span class="linenos">547</span></a><span class="sd">            **kwargs: Additional keyword arguments.</span>
</span><span id="ScaffoldNetwork-548"><a href="#ScaffoldNetwork-548"><span class="linenos">548</span></a>
</span><span id="ScaffoldNetwork-549"><a href="#ScaffoldNetwork-549"><span class="linenos">549</span></a><span class="sd">        Returns:</span>
</span><span id="ScaffoldNetwork-550"><a href="#ScaffoldNetwork-550"><span class="linenos">550</span></a><span class="sd">            ffnet_dict (dict): The dictionary of the scaffold network.</span>
</span><span id="ScaffoldNetwork-551"><a href="#ScaffoldNetwork-551"><span class="linenos">551</span></a>
</span><span id="ScaffoldNetwork-552"><a href="#ScaffoldNetwork-552"><span class="linenos">552</span></a><span class="sd">        Raises:</span>
</span><span id="ScaffoldNetwork-553"><a href="#ScaffoldNetwork-553"><span class="linenos">553</span></a><span class="sd">            AssertionError: If the scaffold levels are invalid.</span>
</span><span id="ScaffoldNetwork-554"><a href="#ScaffoldNetwork-554"><span class="linenos">554</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ScaffoldNetwork-555"><a href="#ScaffoldNetwork-555"><span class="linenos">555</span></a>        <span class="n">ffnet_dict</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">ffnet_dict</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="ScaffoldNetwork-556"><a href="#ScaffoldNetwork-556"><span class="linenos">556</span></a>        <span class="n">ffnet_dict</span><span class="p">[</span><span class="s1">&#39;ffnet_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;scaffold&#39;</span>
</span><span id="ScaffoldNetwork-557"><a href="#ScaffoldNetwork-557"><span class="linenos">557</span></a>        <span class="n">ffnet_dict</span><span class="p">[</span><span class="s1">&#39;scaffold_levels&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaffold_levels</span>
</span><span id="ScaffoldNetwork-558"><a href="#ScaffoldNetwork-558"><span class="linenos">558</span></a>        <span class="n">ffnet_dict</span><span class="p">[</span><span class="s1">&#39;num_lags_out&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_lags_out</span>
</span><span id="ScaffoldNetwork-559"><a href="#ScaffoldNetwork-559"><span class="linenos">559</span></a>        <span class="k">return</span> <span class="n">ffnet_dict</span>
</span></pre></div>


            <div class="docstring"><p>Concatenates output of all layers together in filter dimension, preserving spatial dims.</p>

<p>This essentially used the constructor for Point1DGaussian, with dicationary input.
Currently there is no extra code required at the network level. I think the constructor
can be left off entirely, but leaving in in case want to add something.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>scaffold_levels (list):</strong>  A list of scaffold levels.</li>
<li><strong>num_lags_out (int):</strong>  The number of lags out.</li>
</ul>

<h6 id="raises">Raises:</h6>

<ul>
<li><strong>AssertionError:</strong>  If the scaffold levels are invalid.</li>
</ul>
</div>


                            <div id="ScaffoldNetwork.__init__" class="classattr">
                                        <input id="ScaffoldNetwork.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">ScaffoldNetwork</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">scaffold_levels</span><span class="o">=</span><span class="kc">None</span>, </span><span class="param"><span class="n">num_lags_out</span><span class="o">=</span><span class="mi">1</span>, </span><span class="param"><span class="o">**</span><span class="n">kwargs</span></span>)</span>

                <label class="view-source-button" for="ScaffoldNetwork.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ScaffoldNetwork.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ScaffoldNetwork.__init__-458"><a href="#ScaffoldNetwork.__init__-458"><span class="linenos">458</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">scaffold_levels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_lags_out</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="ScaffoldNetwork.__init__-459"><a href="#ScaffoldNetwork.__init__-459"><span class="linenos">459</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="ScaffoldNetwork.__init__-460"><a href="#ScaffoldNetwork.__init__-460"><span class="linenos">460</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">network_type</span> <span class="o">=</span> <span class="s1">&#39;scaffold&#39;</span>
</span><span id="ScaffoldNetwork.__init__-461"><a href="#ScaffoldNetwork.__init__-461"><span class="linenos">461</span></a>
</span><span id="ScaffoldNetwork.__init__-462"><a href="#ScaffoldNetwork.__init__-462"><span class="linenos">462</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_lags_out</span> <span class="o">=</span> <span class="n">num_lags_out</span>
</span><span id="ScaffoldNetwork.__init__-463"><a href="#ScaffoldNetwork.__init__-463"><span class="linenos">463</span></a>
</span><span id="ScaffoldNetwork.__init__-464"><a href="#ScaffoldNetwork.__init__-464"><span class="linenos">464</span></a>        <span class="n">num_layers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span>
</span><span id="ScaffoldNetwork.__init__-465"><a href="#ScaffoldNetwork.__init__-465"><span class="linenos">465</span></a>        <span class="k">if</span> <span class="n">scaffold_levels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ScaffoldNetwork.__init__-466"><a href="#ScaffoldNetwork.__init__-466"><span class="linenos">466</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)</span>
</span><span id="ScaffoldNetwork.__init__-467"><a href="#ScaffoldNetwork.__init__-467"><span class="linenos">467</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="ScaffoldNetwork.__init__-468"><a href="#ScaffoldNetwork.__init__-468"><span class="linenos">468</span></a>            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scaffold_levels</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="ScaffoldNetwork.__init__-469"><a href="#ScaffoldNetwork.__init__-469"><span class="linenos">469</span></a>                <span class="n">scaffold_levels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">scaffold_levels</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
</span><span id="ScaffoldNetwork.__init__-470"><a href="#ScaffoldNetwork.__init__-470"><span class="linenos">470</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span> <span class="o">=</span> <span class="n">scaffold_levels</span> 
</span><span id="ScaffoldNetwork.__init__-471"><a href="#ScaffoldNetwork.__init__-471"><span class="linenos">471</span></a>        <span class="c1"># Determine output dimensions</span>
</span><span id="ScaffoldNetwork.__init__-472"><a href="#ScaffoldNetwork.__init__-472"><span class="linenos">472</span></a>        <span class="c1">#assert self.layers[self.scaffold_levels[0]].output_dims[3] == 1, &quot;Scaffold: cannot currently handle lag dimensions&quot;</span>
</span><span id="ScaffoldNetwork.__init__-473"><a href="#ScaffoldNetwork.__init__-473"><span class="linenos">473</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">spatial_dims</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">output_dims</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span>
</span><span id="ScaffoldNetwork.__init__-474"><a href="#ScaffoldNetwork.__init__-474"><span class="linenos">474</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">filter_count</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">))</span>
</span><span id="ScaffoldNetwork.__init__-475"><a href="#ScaffoldNetwork.__init__-475"><span class="linenos">475</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">filter_count</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">output_dims</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ScaffoldNetwork.__init__-476"><a href="#ScaffoldNetwork.__init__-476"><span class="linenos">476</span></a>
</span><span id="ScaffoldNetwork.__init__-477"><a href="#ScaffoldNetwork.__init__-477"><span class="linenos">477</span></a>        <span class="c1">#Tchomps = np.zeros(self.scaffold_levels)</span>
</span><span id="ScaffoldNetwork.__init__-478"><a href="#ScaffoldNetwork.__init__-478"><span class="linenos">478</span></a>        <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">)):</span>
</span><span id="ScaffoldNetwork.__init__-479"><a href="#ScaffoldNetwork.__init__-479"><span class="linenos">479</span></a>            <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">[</span><span class="n">ii</span><span class="p">]]</span><span class="o">.</span><span class="n">output_dims</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">spatial_dims</span><span class="p">,</span> <span class="s2">&quot;Spatial dims problem layer </span><span class="si">%d</span><span class="s2">&quot;</span><span class="o">%</span><span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span> 
</span><span id="ScaffoldNetwork.__init__-480"><a href="#ScaffoldNetwork.__init__-480"><span class="linenos">480</span></a>            <span class="c1">#assert self.layers[self.scaffold_levels[ii]].output_dims[3] == 1, &quot;Scaffold: cannot currently handle lag dimensions&quot;</span>
</span><span id="ScaffoldNetwork.__init__-481"><a href="#ScaffoldNetwork.__init__-481"><span class="linenos">481</span></a>            <span class="c1">#if self.layers[self.scaffold_levels[ii]].output_dims[3] &gt; 1:</span>
</span><span id="ScaffoldNetwork.__init__-482"><a href="#ScaffoldNetwork.__init__-482"><span class="linenos">482</span></a>            <span class="c1">#    Tchomps[ii] = self.layers[self.scaffold_levels[ii]].output_dims[3]-1</span>
</span><span id="ScaffoldNetwork.__init__-483"><a href="#ScaffoldNetwork.__init__-483"><span class="linenos">483</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">filter_count</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">[</span><span class="n">ii</span><span class="p">]]</span><span class="o">.</span><span class="n">output_dims</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ScaffoldNetwork.__init__-484"><a href="#ScaffoldNetwork.__init__-484"><span class="linenos">484</span></a>
</span><span id="ScaffoldNetwork.__init__-485"><a href="#ScaffoldNetwork.__init__-485"><span class="linenos">485</span></a>        <span class="c1"># Construct output dimensions</span>
</span><span id="ScaffoldNetwork.__init__-486"><a href="#ScaffoldNetwork.__init__-486"><span class="linenos">486</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_lags_out</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ScaffoldNetwork.__init__-487"><a href="#ScaffoldNetwork.__init__-487"><span class="linenos">487</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">output_dims</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filter_count</span><span class="p">))]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">spatial_dims</span> <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">num_lags_out</span><span class="p">]</span>
</span><span id="ScaffoldNetwork.__init__-488"><a href="#ScaffoldNetwork.__init__-488"><span class="linenos">488</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="ScaffoldNetwork.__init__-489"><a href="#ScaffoldNetwork.__init__-489"><span class="linenos">489</span></a>            <span class="n">scaffold_lags</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">[</span><span class="n">ii</span><span class="p">]]</span><span class="o">.</span><span class="n">output_dims</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">))]</span>
</span><span id="ScaffoldNetwork.__init__-490"><a href="#ScaffoldNetwork.__init__-490"><span class="linenos">490</span></a>            <span class="c1"># assert that all scaffold_lags are the same</span>
</span><span id="ScaffoldNetwork.__init__-491"><a href="#ScaffoldNetwork.__init__-491"><span class="linenos">491</span></a>            <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">scaffold_lags</span><span class="p">)</span> <span class="o">==</span> <span class="n">scaffold_lags</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="s2">&quot;Scaffold: cannot currently handle different lag dimensions&quot;</span>
</span><span id="ScaffoldNetwork.__init__-492"><a href="#ScaffoldNetwork.__init__-492"><span class="linenos">492</span></a>            <span class="n">filter_x_lag</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filter_count</span><span class="p">))</span> <span class="o">*</span> <span class="n">scaffold_lags</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ScaffoldNetwork.__init__-493"><a href="#ScaffoldNetwork.__init__-493"><span class="linenos">493</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">output_dims</span> <span class="o">=</span> <span class="p">[</span><span class="n">filter_x_lag</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">spatial_dims</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="ScaffoldNetwork.network_type" class="classattr">
                                <div class="attr variable">
            <span class="name">network_type</span>

        
    </div>
    <a class="headerlink" href="#ScaffoldNetwork.network_type"></a>
    
    

                            </div>
                            <div id="ScaffoldNetwork.num_lags_out" class="classattr">
                                <div class="attr variable">
            <span class="name">num_lags_out</span>

        
    </div>
    <a class="headerlink" href="#ScaffoldNetwork.num_lags_out"></a>
    
    

                            </div>
                            <div id="ScaffoldNetwork.spatial_dims" class="classattr">
                                <div class="attr variable">
            <span class="name">spatial_dims</span>

        
    </div>
    <a class="headerlink" href="#ScaffoldNetwork.spatial_dims"></a>
    
    

                            </div>
                            <div id="ScaffoldNetwork.filter_count" class="classattr">
                                <div class="attr variable">
            <span class="name">filter_count</span>

        
    </div>
    <a class="headerlink" href="#ScaffoldNetwork.filter_count"></a>
    
    

                            </div>
                            <div id="ScaffoldNetwork.forward" class="classattr">
                                        <input id="ScaffoldNetwork.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">inputs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="ScaffoldNetwork.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ScaffoldNetwork.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ScaffoldNetwork.forward-496"><a href="#ScaffoldNetwork.forward-496"><span class="linenos">496</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="ScaffoldNetwork.forward-497"><a href="#ScaffoldNetwork.forward-497"><span class="linenos">497</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ScaffoldNetwork.forward-498"><a href="#ScaffoldNetwork.forward-498"><span class="linenos">498</span></a><span class="sd">        Forward pass through the network.</span>
</span><span id="ScaffoldNetwork.forward-499"><a href="#ScaffoldNetwork.forward-499"><span class="linenos">499</span></a>
</span><span id="ScaffoldNetwork.forward-500"><a href="#ScaffoldNetwork.forward-500"><span class="linenos">500</span></a><span class="sd">        Args:</span>
</span><span id="ScaffoldNetwork.forward-501"><a href="#ScaffoldNetwork.forward-501"><span class="linenos">501</span></a><span class="sd">            inputs (list, torch.Tensor): The input to the network.</span>
</span><span id="ScaffoldNetwork.forward-502"><a href="#ScaffoldNetwork.forward-502"><span class="linenos">502</span></a>
</span><span id="ScaffoldNetwork.forward-503"><a href="#ScaffoldNetwork.forward-503"><span class="linenos">503</span></a><span class="sd">        Returns:</span>
</span><span id="ScaffoldNetwork.forward-504"><a href="#ScaffoldNetwork.forward-504"><span class="linenos">504</span></a><span class="sd">            x (torch.Tensor): The output of the network.</span>
</span><span id="ScaffoldNetwork.forward-505"><a href="#ScaffoldNetwork.forward-505"><span class="linenos">505</span></a>
</span><span id="ScaffoldNetwork.forward-506"><a href="#ScaffoldNetwork.forward-506"><span class="linenos">506</span></a><span class="sd">        Raises:</span>
</span><span id="ScaffoldNetwork.forward-507"><a href="#ScaffoldNetwork.forward-507"><span class="linenos">507</span></a><span class="sd">            ValueError: If no layers are defined.</span>
</span><span id="ScaffoldNetwork.forward-508"><a href="#ScaffoldNetwork.forward-508"><span class="linenos">508</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ScaffoldNetwork.forward-509"><a href="#ScaffoldNetwork.forward-509"><span class="linenos">509</span></a>
</span><span id="ScaffoldNetwork.forward-510"><a href="#ScaffoldNetwork.forward-510"><span class="linenos">510</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ScaffoldNetwork.forward-511"><a href="#ScaffoldNetwork.forward-511"><span class="linenos">511</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Scaffold: no layers defined.&quot;</span><span class="p">)</span>
</span><span id="ScaffoldNetwork.forward-512"><a href="#ScaffoldNetwork.forward-512"><span class="linenos">512</span></a>        
</span><span id="ScaffoldNetwork.forward-513"><a href="#ScaffoldNetwork.forward-513"><span class="linenos">513</span></a>        <span class="n">out</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># returned </span>
</span><span id="ScaffoldNetwork.forward-514"><a href="#ScaffoldNetwork.forward-514"><span class="linenos">514</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess_input</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="ScaffoldNetwork.forward-515"><a href="#ScaffoldNetwork.forward-515"><span class="linenos">515</span></a>
</span><span id="ScaffoldNetwork.forward-516"><a href="#ScaffoldNetwork.forward-516"><span class="linenos">516</span></a>        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
</span><span id="ScaffoldNetwork.forward-517"><a href="#ScaffoldNetwork.forward-517"><span class="linenos">517</span></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="ScaffoldNetwork.forward-518"><a href="#ScaffoldNetwork.forward-518"><span class="linenos">518</span></a>            <span class="n">nt</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ScaffoldNetwork.forward-519"><a href="#ScaffoldNetwork.forward-519"><span class="linenos">519</span></a>            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_lags_out</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">layer</span><span class="o">.</span><span class="n">output_dims</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="ScaffoldNetwork.forward-520"><a href="#ScaffoldNetwork.forward-520"><span class="linenos">520</span></a>                <span class="c1"># reshape y to combine the filters and lags in the second dimension</span>
</span><span id="ScaffoldNetwork.forward-521"><a href="#ScaffoldNetwork.forward-521"><span class="linenos">521</span></a>                <span class="c1"># batch x filters x (width x height) x lags</span>
</span><span id="ScaffoldNetwork.forward-522"><a href="#ScaffoldNetwork.forward-522"><span class="linenos">522</span></a>                <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="n">nt</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">output_dims</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">output_dims</span><span class="p">[</span><span class="mi">3</span><span class="p">]])</span>
</span><span id="ScaffoldNetwork.forward-523"><a href="#ScaffoldNetwork.forward-523"><span class="linenos">523</span></a>                <span class="c1"># move the lag dimension after the filters (batch, filter, lag, width x height)</span>
</span><span id="ScaffoldNetwork.forward-524"><a href="#ScaffoldNetwork.forward-524"><span class="linenos">524</span></a>                <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span><span id="ScaffoldNetwork.forward-525"><a href="#ScaffoldNetwork.forward-525"><span class="linenos">525</span></a>                <span class="c1"># flatten the filter and lag dimensions to be filters x lags</span>
</span><span id="ScaffoldNetwork.forward-526"><a href="#ScaffoldNetwork.forward-526"><span class="linenos">526</span></a>                <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="n">nt</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span><span id="ScaffoldNetwork.forward-527"><a href="#ScaffoldNetwork.forward-527"><span class="linenos">527</span></a>                <span class="n">out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span><span id="ScaffoldNetwork.forward-528"><a href="#ScaffoldNetwork.forward-528"><span class="linenos">528</span></a>            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_lags_out</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">layer</span><span class="o">.</span><span class="n">output_dims</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_lags_out</span><span class="p">:</span>
</span><span id="ScaffoldNetwork.forward-529"><a href="#ScaffoldNetwork.forward-529"><span class="linenos">529</span></a>                <span class="c1"># Need to return just first lag (lag0) -- &#39;chomp&#39;</span>
</span><span id="ScaffoldNetwork.forward-530"><a href="#ScaffoldNetwork.forward-530"><span class="linenos">530</span></a>                <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="n">nt</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">output_dims</span><span class="p">[</span><span class="mi">3</span><span class="p">]])[</span><span class="o">...</span><span class="p">,</span> <span class="p">:(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_lags_out</span><span class="p">)]</span>
</span><span id="ScaffoldNetwork.forward-531"><a href="#ScaffoldNetwork.forward-531"><span class="linenos">531</span></a>                <span class="n">out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">nt</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="p">))</span>
</span><span id="ScaffoldNetwork.forward-532"><a href="#ScaffoldNetwork.forward-532"><span class="linenos">532</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="ScaffoldNetwork.forward-533"><a href="#ScaffoldNetwork.forward-533"><span class="linenos">533</span></a>                <span class="n">out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="ScaffoldNetwork.forward-534"><a href="#ScaffoldNetwork.forward-534"><span class="linenos">534</span></a>        
</span><span id="ScaffoldNetwork.forward-535"><a href="#ScaffoldNetwork.forward-535"><span class="linenos">535</span></a>        <span class="c1"># this concatentates across the filter dimension</span>
</span><span id="ScaffoldNetwork.forward-536"><a href="#ScaffoldNetwork.forward-536"><span class="linenos">536</span></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">out</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Forward pass through the network.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>inputs (list, torch.Tensor):</strong>  The input to the network.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>x (torch.Tensor): The output of the network.</p>
</blockquote>

<h6 id="raises">Raises:</h6>

<ul>
<li><strong>ValueError:</strong>  If no layers are defined.</li>
</ul>
</div>


                            </div>
                            <div id="ScaffoldNetwork.ffnet_dict" class="classattr">
                                        <input id="ScaffoldNetwork.ffnet_dict-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator">@classmethod</div>

        <span class="def">def</span>
        <span class="name">ffnet_dict</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">cls</span>, </span><span class="param"><span class="n">scaffold_levels</span><span class="o">=</span><span class="kc">None</span>, </span><span class="param"><span class="n">num_lags_out</span><span class="o">=</span><span class="mi">1</span>, </span><span class="param"><span class="o">**</span><span class="n">kwargs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="ScaffoldNetwork.ffnet_dict-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ScaffoldNetwork.ffnet_dict"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ScaffoldNetwork.ffnet_dict-539"><a href="#ScaffoldNetwork.ffnet_dict-539"><span class="linenos">539</span></a>    <span class="nd">@classmethod</span>
</span><span id="ScaffoldNetwork.ffnet_dict-540"><a href="#ScaffoldNetwork.ffnet_dict-540"><span class="linenos">540</span></a>    <span class="k">def</span> <span class="nf">ffnet_dict</span><span class="p">(</span> <span class="bp">cls</span><span class="p">,</span> <span class="n">scaffold_levels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_lags_out</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="ScaffoldNetwork.ffnet_dict-541"><a href="#ScaffoldNetwork.ffnet_dict-541"><span class="linenos">541</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ScaffoldNetwork.ffnet_dict-542"><a href="#ScaffoldNetwork.ffnet_dict-542"><span class="linenos">542</span></a><span class="sd">        Returns a dictionary of the scaffold network.</span>
</span><span id="ScaffoldNetwork.ffnet_dict-543"><a href="#ScaffoldNetwork.ffnet_dict-543"><span class="linenos">543</span></a>
</span><span id="ScaffoldNetwork.ffnet_dict-544"><a href="#ScaffoldNetwork.ffnet_dict-544"><span class="linenos">544</span></a><span class="sd">        Args:</span>
</span><span id="ScaffoldNetwork.ffnet_dict-545"><a href="#ScaffoldNetwork.ffnet_dict-545"><span class="linenos">545</span></a><span class="sd">            scaffold_levels (list): A list of scaffold levels.</span>
</span><span id="ScaffoldNetwork.ffnet_dict-546"><a href="#ScaffoldNetwork.ffnet_dict-546"><span class="linenos">546</span></a><span class="sd">            num_lags_out (int): The number of lags out.</span>
</span><span id="ScaffoldNetwork.ffnet_dict-547"><a href="#ScaffoldNetwork.ffnet_dict-547"><span class="linenos">547</span></a><span class="sd">            **kwargs: Additional keyword arguments.</span>
</span><span id="ScaffoldNetwork.ffnet_dict-548"><a href="#ScaffoldNetwork.ffnet_dict-548"><span class="linenos">548</span></a>
</span><span id="ScaffoldNetwork.ffnet_dict-549"><a href="#ScaffoldNetwork.ffnet_dict-549"><span class="linenos">549</span></a><span class="sd">        Returns:</span>
</span><span id="ScaffoldNetwork.ffnet_dict-550"><a href="#ScaffoldNetwork.ffnet_dict-550"><span class="linenos">550</span></a><span class="sd">            ffnet_dict (dict): The dictionary of the scaffold network.</span>
</span><span id="ScaffoldNetwork.ffnet_dict-551"><a href="#ScaffoldNetwork.ffnet_dict-551"><span class="linenos">551</span></a>
</span><span id="ScaffoldNetwork.ffnet_dict-552"><a href="#ScaffoldNetwork.ffnet_dict-552"><span class="linenos">552</span></a><span class="sd">        Raises:</span>
</span><span id="ScaffoldNetwork.ffnet_dict-553"><a href="#ScaffoldNetwork.ffnet_dict-553"><span class="linenos">553</span></a><span class="sd">            AssertionError: If the scaffold levels are invalid.</span>
</span><span id="ScaffoldNetwork.ffnet_dict-554"><a href="#ScaffoldNetwork.ffnet_dict-554"><span class="linenos">554</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ScaffoldNetwork.ffnet_dict-555"><a href="#ScaffoldNetwork.ffnet_dict-555"><span class="linenos">555</span></a>        <span class="n">ffnet_dict</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">ffnet_dict</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="ScaffoldNetwork.ffnet_dict-556"><a href="#ScaffoldNetwork.ffnet_dict-556"><span class="linenos">556</span></a>        <span class="n">ffnet_dict</span><span class="p">[</span><span class="s1">&#39;ffnet_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;scaffold&#39;</span>
</span><span id="ScaffoldNetwork.ffnet_dict-557"><a href="#ScaffoldNetwork.ffnet_dict-557"><span class="linenos">557</span></a>        <span class="n">ffnet_dict</span><span class="p">[</span><span class="s1">&#39;scaffold_levels&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaffold_levels</span>
</span><span id="ScaffoldNetwork.ffnet_dict-558"><a href="#ScaffoldNetwork.ffnet_dict-558"><span class="linenos">558</span></a>        <span class="n">ffnet_dict</span><span class="p">[</span><span class="s1">&#39;num_lags_out&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_lags_out</span>
</span><span id="ScaffoldNetwork.ffnet_dict-559"><a href="#ScaffoldNetwork.ffnet_dict-559"><span class="linenos">559</span></a>        <span class="k">return</span> <span class="n">ffnet_dict</span>
</span></pre></div>


            <div class="docstring"><p>Returns a dictionary of the scaffold network.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>scaffold_levels (list):</strong>  A list of scaffold levels.</li>
<li><strong>num_lags_out (int):</strong>  The number of lags out.</li>
<li><strong>**kwargs:</strong>  Additional keyword arguments.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>ffnet_dict (dict): The dictionary of the scaffold network.</p>
</blockquote>

<h6 id="raises">Raises:</h6>

<ul>
<li><strong>AssertionError:</strong>  If the scaffold levels are invalid.</li>
</ul>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt><a href="#FFnetwork">FFnetwork</a></dt>
                                <dd id="ScaffoldNetwork.layer_list" class="variable"><a href="#FFnetwork.layer_list">layer_list</a></dd>
                <dd id="ScaffoldNetwork.layer_types" class="variable"><a href="#FFnetwork.layer_types">layer_types</a></dd>
                <dd id="ScaffoldNetwork.xstim_n" class="variable"><a href="#FFnetwork.xstim_n">xstim_n</a></dd>
                <dd id="ScaffoldNetwork.ffnets_in" class="variable"><a href="#FFnetwork.ffnets_in">ffnets_in</a></dd>
                <dd id="ScaffoldNetwork.layers" class="variable"><a href="#FFnetwork.layers">layers</a></dd>
                <dd id="ScaffoldNetwork.output_dims" class="variable"><a href="#FFnetwork.output_dims">output_dims</a></dd>
                <dd id="ScaffoldNetwork.num_outputs" class="variable"><a href="#FFnetwork.num_outputs">num_outputs</a></dd>
                <dd id="ScaffoldNetwork.determine_input_dims" class="function"><a href="#FFnetwork.determine_input_dims">determine_input_dims</a></dd>
                <dd id="ScaffoldNetwork.preprocess_input" class="function"><a href="#FFnetwork.preprocess_input">preprocess_input</a></dd>
                <dd id="ScaffoldNetwork.prepare_regularization" class="function"><a href="#FFnetwork.prepare_regularization">prepare_regularization</a></dd>
                <dd id="ScaffoldNetwork.compute_reg_loss" class="function"><a href="#FFnetwork.compute_reg_loss">compute_reg_loss</a></dd>
                <dd id="ScaffoldNetwork.list_parameters" class="function"><a href="#FFnetwork.list_parameters">list_parameters</a></dd>
                <dd id="ScaffoldNetwork.set_parameters" class="function"><a href="#FFnetwork.set_parameters">set_parameters</a></dd>
                <dd id="ScaffoldNetwork.set_reg_val" class="function"><a href="#FFnetwork.set_reg_val">set_reg_val</a></dd>
                <dd id="ScaffoldNetwork.plot_filters" class="function"><a href="#FFnetwork.plot_filters">plot_filters</a></dd>
                <dd id="ScaffoldNetwork.get_weights" class="function"><a href="#FFnetwork.get_weights">get_weights</a></dd>

            </div>
            <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="ScaffoldNetwork.dump_patches" class="variable">dump_patches</dd>
                <dd id="ScaffoldNetwork.training" class="variable">training</dd>
                <dd id="ScaffoldNetwork.call_super_init" class="variable">call_super_init</dd>
                <dd id="ScaffoldNetwork.register_buffer" class="function">register_buffer</dd>
                <dd id="ScaffoldNetwork.register_parameter" class="function">register_parameter</dd>
                <dd id="ScaffoldNetwork.add_module" class="function">add_module</dd>
                <dd id="ScaffoldNetwork.register_module" class="function">register_module</dd>
                <dd id="ScaffoldNetwork.get_submodule" class="function">get_submodule</dd>
                <dd id="ScaffoldNetwork.get_parameter" class="function">get_parameter</dd>
                <dd id="ScaffoldNetwork.get_buffer" class="function">get_buffer</dd>
                <dd id="ScaffoldNetwork.get_extra_state" class="function">get_extra_state</dd>
                <dd id="ScaffoldNetwork.set_extra_state" class="function">set_extra_state</dd>
                <dd id="ScaffoldNetwork.apply" class="function">apply</dd>
                <dd id="ScaffoldNetwork.cuda" class="function">cuda</dd>
                <dd id="ScaffoldNetwork.ipu" class="function">ipu</dd>
                <dd id="ScaffoldNetwork.xpu" class="function">xpu</dd>
                <dd id="ScaffoldNetwork.cpu" class="function">cpu</dd>
                <dd id="ScaffoldNetwork.type" class="function">type</dd>
                <dd id="ScaffoldNetwork.float" class="function">float</dd>
                <dd id="ScaffoldNetwork.double" class="function">double</dd>
                <dd id="ScaffoldNetwork.half" class="function">half</dd>
                <dd id="ScaffoldNetwork.bfloat16" class="function">bfloat16</dd>
                <dd id="ScaffoldNetwork.to_empty" class="function">to_empty</dd>
                <dd id="ScaffoldNetwork.to" class="function">to</dd>
                <dd id="ScaffoldNetwork.register_full_backward_pre_hook" class="function">register_full_backward_pre_hook</dd>
                <dd id="ScaffoldNetwork.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="ScaffoldNetwork.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="ScaffoldNetwork.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="ScaffoldNetwork.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="ScaffoldNetwork.register_state_dict_pre_hook" class="function">register_state_dict_pre_hook</dd>
                <dd id="ScaffoldNetwork.state_dict" class="function">state_dict</dd>
                <dd id="ScaffoldNetwork.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="ScaffoldNetwork.load_state_dict" class="function">load_state_dict</dd>
                <dd id="ScaffoldNetwork.parameters" class="function">parameters</dd>
                <dd id="ScaffoldNetwork.named_parameters" class="function">named_parameters</dd>
                <dd id="ScaffoldNetwork.buffers" class="function">buffers</dd>
                <dd id="ScaffoldNetwork.named_buffers" class="function">named_buffers</dd>
                <dd id="ScaffoldNetwork.children" class="function">children</dd>
                <dd id="ScaffoldNetwork.named_children" class="function">named_children</dd>
                <dd id="ScaffoldNetwork.modules" class="function">modules</dd>
                <dd id="ScaffoldNetwork.named_modules" class="function">named_modules</dd>
                <dd id="ScaffoldNetwork.train" class="function">train</dd>
                <dd id="ScaffoldNetwork.eval" class="function">eval</dd>
                <dd id="ScaffoldNetwork.requires_grad_" class="function">requires_grad_</dd>
                <dd id="ScaffoldNetwork.zero_grad" class="function">zero_grad</dd>
                <dd id="ScaffoldNetwork.share_memory" class="function">share_memory</dd>
                <dd id="ScaffoldNetwork.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="ScaffoldNetwork3d">
                            <input id="ScaffoldNetwork3d-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">ScaffoldNetwork3d</span><wbr>(<span class="base"><a href="#ScaffoldNetwork">ScaffoldNetwork</a></span>):

                <label class="view-source-button" for="ScaffoldNetwork3d-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ScaffoldNetwork3d"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ScaffoldNetwork3d-563"><a href="#ScaffoldNetwork3d-563"><span class="linenos">563</span></a><span class="k">class</span> <span class="nc">ScaffoldNetwork3d</span><span class="p">(</span><span class="n">ScaffoldNetwork</span><span class="p">):</span>
</span><span id="ScaffoldNetwork3d-564"><a href="#ScaffoldNetwork3d-564"><span class="linenos">564</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ScaffoldNetwork3d-565"><a href="#ScaffoldNetwork3d-565"><span class="linenos">565</span></a><span class="sd">    Like scaffold network above, but preserves the third dimension.</span>
</span><span id="ScaffoldNetwork3d-566"><a href="#ScaffoldNetwork3d-566"><span class="linenos">566</span></a>
</span><span id="ScaffoldNetwork3d-567"><a href="#ScaffoldNetwork3d-567"><span class="linenos">567</span></a><span class="sd">    This essentially used the constructor for Point1DGaussian, with dicationary input.</span>
</span><span id="ScaffoldNetwork3d-568"><a href="#ScaffoldNetwork3d-568"><span class="linenos">568</span></a><span class="sd">    Currently there is no extra code required at the network level. I think the constructor</span>
</span><span id="ScaffoldNetwork3d-569"><a href="#ScaffoldNetwork3d-569"><span class="linenos">569</span></a><span class="sd">    can be left off entirely, but leaving in in case want to add something.</span>
</span><span id="ScaffoldNetwork3d-570"><a href="#ScaffoldNetwork3d-570"><span class="linenos">570</span></a>
</span><span id="ScaffoldNetwork3d-571"><a href="#ScaffoldNetwork3d-571"><span class="linenos">571</span></a><span class="sd">    Args:</span>
</span><span id="ScaffoldNetwork3d-572"><a href="#ScaffoldNetwork3d-572"><span class="linenos">572</span></a><span class="sd">        num_lags_out (int): The number of lags out.</span>
</span><span id="ScaffoldNetwork3d-573"><a href="#ScaffoldNetwork3d-573"><span class="linenos">573</span></a>
</span><span id="ScaffoldNetwork3d-574"><a href="#ScaffoldNetwork3d-574"><span class="linenos">574</span></a><span class="sd">    Raises:</span>
</span><span id="ScaffoldNetwork3d-575"><a href="#ScaffoldNetwork3d-575"><span class="linenos">575</span></a><span class="sd">        AssertionError: If the scaffold levels are invalid.</span>
</span><span id="ScaffoldNetwork3d-576"><a href="#ScaffoldNetwork3d-576"><span class="linenos">576</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="ScaffoldNetwork3d-577"><a href="#ScaffoldNetwork3d-577"><span class="linenos">577</span></a>
</span><span id="ScaffoldNetwork3d-578"><a href="#ScaffoldNetwork3d-578"><span class="linenos">578</span></a>    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="ScaffoldNetwork3d-579"><a href="#ScaffoldNetwork3d-579"><span class="linenos">579</span></a>        <span class="n">s</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__repr__</span><span class="p">()</span>
</span><span id="ScaffoldNetwork3d-580"><a href="#ScaffoldNetwork3d-580"><span class="linenos">580</span></a>        <span class="c1"># Add information about module to print out</span>
</span><span id="ScaffoldNetwork3d-581"><a href="#ScaffoldNetwork3d-581"><span class="linenos">581</span></a>        <span class="n">s</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
</span><span id="ScaffoldNetwork3d-582"><a href="#ScaffoldNetwork3d-582"><span class="linenos">582</span></a>        <span class="k">return</span> <span class="n">s</span>
</span><span id="ScaffoldNetwork3d-583"><a href="#ScaffoldNetwork3d-583"><span class="linenos">583</span></a>
</span><span id="ScaffoldNetwork3d-584"><a href="#ScaffoldNetwork3d-584"><span class="linenos">584</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_lags_out</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="ScaffoldNetwork3d-585"><a href="#ScaffoldNetwork3d-585"><span class="linenos">585</span></a>        <span class="k">assert</span> <span class="n">num_lags_out</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;should be using num_lags_out with the scaffold3d network&quot;</span>
</span><span id="ScaffoldNetwork3d-586"><a href="#ScaffoldNetwork3d-586"><span class="linenos">586</span></a>
</span><span id="ScaffoldNetwork3d-587"><a href="#ScaffoldNetwork3d-587"><span class="linenos">587</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="ScaffoldNetwork3d-588"><a href="#ScaffoldNetwork3d-588"><span class="linenos">588</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">network_type</span> <span class="o">=</span> <span class="s1">&#39;scaffold3d&#39;</span>
</span><span id="ScaffoldNetwork3d-589"><a href="#ScaffoldNetwork3d-589"><span class="linenos">589</span></a>
</span><span id="ScaffoldNetwork3d-590"><a href="#ScaffoldNetwork3d-590"><span class="linenos">590</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_lags_out</span> <span class="o">=</span> <span class="n">num_lags_out</span>  <span class="c1"># Makes output equal to number of lags</span>
</span><span id="ScaffoldNetwork3d-591"><a href="#ScaffoldNetwork3d-591"><span class="linenos">591</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">output_dims</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_lags_out</span>
</span><span id="ScaffoldNetwork3d-592"><a href="#ScaffoldNetwork3d-592"><span class="linenos">592</span></a>    <span class="c1"># END ScaffoldNetwork3d.__init__</span>
</span><span id="ScaffoldNetwork3d-593"><a href="#ScaffoldNetwork3d-593"><span class="linenos">593</span></a>
</span><span id="ScaffoldNetwork3d-594"><a href="#ScaffoldNetwork3d-594"><span class="linenos">594</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="ScaffoldNetwork3d-595"><a href="#ScaffoldNetwork3d-595"><span class="linenos">595</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ScaffoldNetwork3d-596"><a href="#ScaffoldNetwork3d-596"><span class="linenos">596</span></a><span class="sd">        Forward pass through the network.</span>
</span><span id="ScaffoldNetwork3d-597"><a href="#ScaffoldNetwork3d-597"><span class="linenos">597</span></a>
</span><span id="ScaffoldNetwork3d-598"><a href="#ScaffoldNetwork3d-598"><span class="linenos">598</span></a><span class="sd">        Args:</span>
</span><span id="ScaffoldNetwork3d-599"><a href="#ScaffoldNetwork3d-599"><span class="linenos">599</span></a><span class="sd">            inputs (list, torch.Tensor): The input to the network.</span>
</span><span id="ScaffoldNetwork3d-600"><a href="#ScaffoldNetwork3d-600"><span class="linenos">600</span></a>
</span><span id="ScaffoldNetwork3d-601"><a href="#ScaffoldNetwork3d-601"><span class="linenos">601</span></a><span class="sd">        Returns:</span>
</span><span id="ScaffoldNetwork3d-602"><a href="#ScaffoldNetwork3d-602"><span class="linenos">602</span></a><span class="sd">            x (torch.Tensor): The output of the network.</span>
</span><span id="ScaffoldNetwork3d-603"><a href="#ScaffoldNetwork3d-603"><span class="linenos">603</span></a><span class="sd">        </span>
</span><span id="ScaffoldNetwork3d-604"><a href="#ScaffoldNetwork3d-604"><span class="linenos">604</span></a><span class="sd">        Raises:</span>
</span><span id="ScaffoldNetwork3d-605"><a href="#ScaffoldNetwork3d-605"><span class="linenos">605</span></a><span class="sd">            ValueError: If no layers are defined.</span>
</span><span id="ScaffoldNetwork3d-606"><a href="#ScaffoldNetwork3d-606"><span class="linenos">606</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ScaffoldNetwork3d-607"><a href="#ScaffoldNetwork3d-607"><span class="linenos">607</span></a>
</span><span id="ScaffoldNetwork3d-608"><a href="#ScaffoldNetwork3d-608"><span class="linenos">608</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ScaffoldNetwork3d-609"><a href="#ScaffoldNetwork3d-609"><span class="linenos">609</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Scaffold: no layers defined.&quot;</span><span class="p">)</span>
</span><span id="ScaffoldNetwork3d-610"><a href="#ScaffoldNetwork3d-610"><span class="linenos">610</span></a>        
</span><span id="ScaffoldNetwork3d-611"><a href="#ScaffoldNetwork3d-611"><span class="linenos">611</span></a>        <span class="n">out</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># returned </span>
</span><span id="ScaffoldNetwork3d-612"><a href="#ScaffoldNetwork3d-612"><span class="linenos">612</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess_input</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="ScaffoldNetwork3d-613"><a href="#ScaffoldNetwork3d-613"><span class="linenos">613</span></a>
</span><span id="ScaffoldNetwork3d-614"><a href="#ScaffoldNetwork3d-614"><span class="linenos">614</span></a>        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
</span><span id="ScaffoldNetwork3d-615"><a href="#ScaffoldNetwork3d-615"><span class="linenos">615</span></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="ScaffoldNetwork3d-616"><a href="#ScaffoldNetwork3d-616"><span class="linenos">616</span></a>            <span class="n">nt</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ScaffoldNetwork3d-617"><a href="#ScaffoldNetwork3d-617"><span class="linenos">617</span></a>            <span class="c1">#if self.num_lags_out is None and layer.output_dims[3] &gt; 1:</span>
</span><span id="ScaffoldNetwork3d-618"><a href="#ScaffoldNetwork3d-618"><span class="linenos">618</span></a>                <span class="c1"># reshape y to combine the filters and lags in the second dimension</span>
</span><span id="ScaffoldNetwork3d-619"><a href="#ScaffoldNetwork3d-619"><span class="linenos">619</span></a>                <span class="c1"># batch x filters x (width x height) x lags</span>
</span><span id="ScaffoldNetwork3d-620"><a href="#ScaffoldNetwork3d-620"><span class="linenos">620</span></a>            <span class="c1">#    y = x.reshape([nt, layer.output_dims[0], -1, layer.output_dims[3]])</span>
</span><span id="ScaffoldNetwork3d-621"><a href="#ScaffoldNetwork3d-621"><span class="linenos">621</span></a>                <span class="c1"># move the lag dimension after the filters (batch, filter, lag, width x height)</span>
</span><span id="ScaffoldNetwork3d-622"><a href="#ScaffoldNetwork3d-622"><span class="linenos">622</span></a>            <span class="c1">#    y = y.permute(0, 1, 3, 2)</span>
</span><span id="ScaffoldNetwork3d-623"><a href="#ScaffoldNetwork3d-623"><span class="linenos">623</span></a>                <span class="c1"># flatten the filter and lag dimensions to be filters x lags</span>
</span><span id="ScaffoldNetwork3d-624"><a href="#ScaffoldNetwork3d-624"><span class="linenos">624</span></a>            <span class="c1">#    y = y.reshape([nt, -1])</span>
</span><span id="ScaffoldNetwork3d-625"><a href="#ScaffoldNetwork3d-625"><span class="linenos">625</span></a>            <span class="c1">#    out.append(y)</span>
</span><span id="ScaffoldNetwork3d-626"><a href="#ScaffoldNetwork3d-626"><span class="linenos">626</span></a>            <span class="c1">#elif self.num_lags_out is not None and layer.output_dims[3] &gt; self.num_lags_out:</span>
</span><span id="ScaffoldNetwork3d-627"><a href="#ScaffoldNetwork3d-627"><span class="linenos">627</span></a>                <span class="c1"># Need to return just first lag (lag0) -- &#39;chomp&#39;</span>
</span><span id="ScaffoldNetwork3d-628"><a href="#ScaffoldNetwork3d-628"><span class="linenos">628</span></a>            <span class="c1">#    y = x.reshape([nt, -1, layer.output_dims[3]])[..., :(self.num_lags_out)]</span>
</span><span id="ScaffoldNetwork3d-629"><a href="#ScaffoldNetwork3d-629"><span class="linenos">629</span></a>            <span class="c1">#    out.append( y.reshape((nt, -1) ))</span>
</span><span id="ScaffoldNetwork3d-630"><a href="#ScaffoldNetwork3d-630"><span class="linenos">630</span></a>            <span class="c1">#else:</span>
</span><span id="ScaffoldNetwork3d-631"><a href="#ScaffoldNetwork3d-631"><span class="linenos">631</span></a>            <span class="n">out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="ScaffoldNetwork3d-632"><a href="#ScaffoldNetwork3d-632"><span class="linenos">632</span></a>        
</span><span id="ScaffoldNetwork3d-633"><a href="#ScaffoldNetwork3d-633"><span class="linenos">633</span></a>        <span class="c1"># this concatentates across the filter dimension</span>
</span><span id="ScaffoldNetwork3d-634"><a href="#ScaffoldNetwork3d-634"><span class="linenos">634</span></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">out</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="ScaffoldNetwork3d-635"><a href="#ScaffoldNetwork3d-635"><span class="linenos">635</span></a>    <span class="c1"># END ScaffoldNetwork3d.forward()</span>
</span><span id="ScaffoldNetwork3d-636"><a href="#ScaffoldNetwork3d-636"><span class="linenos">636</span></a>
</span><span id="ScaffoldNetwork3d-637"><a href="#ScaffoldNetwork3d-637"><span class="linenos">637</span></a>    <span class="nd">@classmethod</span>
</span><span id="ScaffoldNetwork3d-638"><a href="#ScaffoldNetwork3d-638"><span class="linenos">638</span></a>    <span class="k">def</span> <span class="nf">ffnet_dict</span><span class="p">(</span> <span class="bp">cls</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="ScaffoldNetwork3d-639"><a href="#ScaffoldNetwork3d-639"><span class="linenos">639</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ScaffoldNetwork3d-640"><a href="#ScaffoldNetwork3d-640"><span class="linenos">640</span></a><span class="sd">        Returns a dictionary of the scaffold network.</span>
</span><span id="ScaffoldNetwork3d-641"><a href="#ScaffoldNetwork3d-641"><span class="linenos">641</span></a>
</span><span id="ScaffoldNetwork3d-642"><a href="#ScaffoldNetwork3d-642"><span class="linenos">642</span></a><span class="sd">        Args:</span>
</span><span id="ScaffoldNetwork3d-643"><a href="#ScaffoldNetwork3d-643"><span class="linenos">643</span></a><span class="sd">            **kwargs: Additional keyword arguments.</span>
</span><span id="ScaffoldNetwork3d-644"><a href="#ScaffoldNetwork3d-644"><span class="linenos">644</span></a>
</span><span id="ScaffoldNetwork3d-645"><a href="#ScaffoldNetwork3d-645"><span class="linenos">645</span></a><span class="sd">        Returns:</span>
</span><span id="ScaffoldNetwork3d-646"><a href="#ScaffoldNetwork3d-646"><span class="linenos">646</span></a><span class="sd">            ffnet_dict (dict): The dictionary of the scaffold network.</span>
</span><span id="ScaffoldNetwork3d-647"><a href="#ScaffoldNetwork3d-647"><span class="linenos">647</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ScaffoldNetwork3d-648"><a href="#ScaffoldNetwork3d-648"><span class="linenos">648</span></a>        <span class="n">ffnet_dict</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">ffnet_dict</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="ScaffoldNetwork3d-649"><a href="#ScaffoldNetwork3d-649"><span class="linenos">649</span></a>        <span class="n">ffnet_dict</span><span class="p">[</span><span class="s1">&#39;ffnet_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;scaffold3d&#39;</span>
</span><span id="ScaffoldNetwork3d-650"><a href="#ScaffoldNetwork3d-650"><span class="linenos">650</span></a>        <span class="k">return</span> <span class="n">ffnet_dict</span>
</span></pre></div>


            <div class="docstring"><p>Like scaffold network above, but preserves the third dimension.</p>

<p>This essentially used the constructor for Point1DGaussian, with dicationary input.
Currently there is no extra code required at the network level. I think the constructor
can be left off entirely, but leaving in in case want to add something.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>num_lags_out (int):</strong>  The number of lags out.</li>
</ul>

<h6 id="raises">Raises:</h6>

<ul>
<li><strong>AssertionError:</strong>  If the scaffold levels are invalid.</li>
</ul>
</div>


                            <div id="ScaffoldNetwork3d.__init__" class="classattr">
                                        <input id="ScaffoldNetwork3d.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">ScaffoldNetwork3d</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">num_lags_out</span><span class="o">=</span><span class="kc">None</span>, </span><span class="param"><span class="o">**</span><span class="n">kwargs</span></span>)</span>

                <label class="view-source-button" for="ScaffoldNetwork3d.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ScaffoldNetwork3d.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ScaffoldNetwork3d.__init__-584"><a href="#ScaffoldNetwork3d.__init__-584"><span class="linenos">584</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_lags_out</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="ScaffoldNetwork3d.__init__-585"><a href="#ScaffoldNetwork3d.__init__-585"><span class="linenos">585</span></a>        <span class="k">assert</span> <span class="n">num_lags_out</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;should be using num_lags_out with the scaffold3d network&quot;</span>
</span><span id="ScaffoldNetwork3d.__init__-586"><a href="#ScaffoldNetwork3d.__init__-586"><span class="linenos">586</span></a>
</span><span id="ScaffoldNetwork3d.__init__-587"><a href="#ScaffoldNetwork3d.__init__-587"><span class="linenos">587</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="ScaffoldNetwork3d.__init__-588"><a href="#ScaffoldNetwork3d.__init__-588"><span class="linenos">588</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">network_type</span> <span class="o">=</span> <span class="s1">&#39;scaffold3d&#39;</span>
</span><span id="ScaffoldNetwork3d.__init__-589"><a href="#ScaffoldNetwork3d.__init__-589"><span class="linenos">589</span></a>
</span><span id="ScaffoldNetwork3d.__init__-590"><a href="#ScaffoldNetwork3d.__init__-590"><span class="linenos">590</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">num_lags_out</span> <span class="o">=</span> <span class="n">num_lags_out</span>  <span class="c1"># Makes output equal to number of lags</span>
</span><span id="ScaffoldNetwork3d.__init__-591"><a href="#ScaffoldNetwork3d.__init__-591"><span class="linenos">591</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">output_dims</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_lags_out</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="ScaffoldNetwork3d.network_type" class="classattr">
                                <div class="attr variable">
            <span class="name">network_type</span>

        
    </div>
    <a class="headerlink" href="#ScaffoldNetwork3d.network_type"></a>
    
    

                            </div>
                            <div id="ScaffoldNetwork3d.num_lags_out" class="classattr">
                                <div class="attr variable">
            <span class="name">num_lags_out</span>

        
    </div>
    <a class="headerlink" href="#ScaffoldNetwork3d.num_lags_out"></a>
    
    

                            </div>
                            <div id="ScaffoldNetwork3d.forward" class="classattr">
                                        <input id="ScaffoldNetwork3d.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">inputs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="ScaffoldNetwork3d.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ScaffoldNetwork3d.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ScaffoldNetwork3d.forward-594"><a href="#ScaffoldNetwork3d.forward-594"><span class="linenos">594</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="ScaffoldNetwork3d.forward-595"><a href="#ScaffoldNetwork3d.forward-595"><span class="linenos">595</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ScaffoldNetwork3d.forward-596"><a href="#ScaffoldNetwork3d.forward-596"><span class="linenos">596</span></a><span class="sd">        Forward pass through the network.</span>
</span><span id="ScaffoldNetwork3d.forward-597"><a href="#ScaffoldNetwork3d.forward-597"><span class="linenos">597</span></a>
</span><span id="ScaffoldNetwork3d.forward-598"><a href="#ScaffoldNetwork3d.forward-598"><span class="linenos">598</span></a><span class="sd">        Args:</span>
</span><span id="ScaffoldNetwork3d.forward-599"><a href="#ScaffoldNetwork3d.forward-599"><span class="linenos">599</span></a><span class="sd">            inputs (list, torch.Tensor): The input to the network.</span>
</span><span id="ScaffoldNetwork3d.forward-600"><a href="#ScaffoldNetwork3d.forward-600"><span class="linenos">600</span></a>
</span><span id="ScaffoldNetwork3d.forward-601"><a href="#ScaffoldNetwork3d.forward-601"><span class="linenos">601</span></a><span class="sd">        Returns:</span>
</span><span id="ScaffoldNetwork3d.forward-602"><a href="#ScaffoldNetwork3d.forward-602"><span class="linenos">602</span></a><span class="sd">            x (torch.Tensor): The output of the network.</span>
</span><span id="ScaffoldNetwork3d.forward-603"><a href="#ScaffoldNetwork3d.forward-603"><span class="linenos">603</span></a><span class="sd">        </span>
</span><span id="ScaffoldNetwork3d.forward-604"><a href="#ScaffoldNetwork3d.forward-604"><span class="linenos">604</span></a><span class="sd">        Raises:</span>
</span><span id="ScaffoldNetwork3d.forward-605"><a href="#ScaffoldNetwork3d.forward-605"><span class="linenos">605</span></a><span class="sd">            ValueError: If no layers are defined.</span>
</span><span id="ScaffoldNetwork3d.forward-606"><a href="#ScaffoldNetwork3d.forward-606"><span class="linenos">606</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ScaffoldNetwork3d.forward-607"><a href="#ScaffoldNetwork3d.forward-607"><span class="linenos">607</span></a>
</span><span id="ScaffoldNetwork3d.forward-608"><a href="#ScaffoldNetwork3d.forward-608"><span class="linenos">608</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ScaffoldNetwork3d.forward-609"><a href="#ScaffoldNetwork3d.forward-609"><span class="linenos">609</span></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Scaffold: no layers defined.&quot;</span><span class="p">)</span>
</span><span id="ScaffoldNetwork3d.forward-610"><a href="#ScaffoldNetwork3d.forward-610"><span class="linenos">610</span></a>        
</span><span id="ScaffoldNetwork3d.forward-611"><a href="#ScaffoldNetwork3d.forward-611"><span class="linenos">611</span></a>        <span class="n">out</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># returned </span>
</span><span id="ScaffoldNetwork3d.forward-612"><a href="#ScaffoldNetwork3d.forward-612"><span class="linenos">612</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess_input</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span><span id="ScaffoldNetwork3d.forward-613"><a href="#ScaffoldNetwork3d.forward-613"><span class="linenos">613</span></a>
</span><span id="ScaffoldNetwork3d.forward-614"><a href="#ScaffoldNetwork3d.forward-614"><span class="linenos">614</span></a>        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
</span><span id="ScaffoldNetwork3d.forward-615"><a href="#ScaffoldNetwork3d.forward-615"><span class="linenos">615</span></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="ScaffoldNetwork3d.forward-616"><a href="#ScaffoldNetwork3d.forward-616"><span class="linenos">616</span></a>            <span class="n">nt</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ScaffoldNetwork3d.forward-617"><a href="#ScaffoldNetwork3d.forward-617"><span class="linenos">617</span></a>            <span class="c1">#if self.num_lags_out is None and layer.output_dims[3] &gt; 1:</span>
</span><span id="ScaffoldNetwork3d.forward-618"><a href="#ScaffoldNetwork3d.forward-618"><span class="linenos">618</span></a>                <span class="c1"># reshape y to combine the filters and lags in the second dimension</span>
</span><span id="ScaffoldNetwork3d.forward-619"><a href="#ScaffoldNetwork3d.forward-619"><span class="linenos">619</span></a>                <span class="c1"># batch x filters x (width x height) x lags</span>
</span><span id="ScaffoldNetwork3d.forward-620"><a href="#ScaffoldNetwork3d.forward-620"><span class="linenos">620</span></a>            <span class="c1">#    y = x.reshape([nt, layer.output_dims[0], -1, layer.output_dims[3]])</span>
</span><span id="ScaffoldNetwork3d.forward-621"><a href="#ScaffoldNetwork3d.forward-621"><span class="linenos">621</span></a>                <span class="c1"># move the lag dimension after the filters (batch, filter, lag, width x height)</span>
</span><span id="ScaffoldNetwork3d.forward-622"><a href="#ScaffoldNetwork3d.forward-622"><span class="linenos">622</span></a>            <span class="c1">#    y = y.permute(0, 1, 3, 2)</span>
</span><span id="ScaffoldNetwork3d.forward-623"><a href="#ScaffoldNetwork3d.forward-623"><span class="linenos">623</span></a>                <span class="c1"># flatten the filter and lag dimensions to be filters x lags</span>
</span><span id="ScaffoldNetwork3d.forward-624"><a href="#ScaffoldNetwork3d.forward-624"><span class="linenos">624</span></a>            <span class="c1">#    y = y.reshape([nt, -1])</span>
</span><span id="ScaffoldNetwork3d.forward-625"><a href="#ScaffoldNetwork3d.forward-625"><span class="linenos">625</span></a>            <span class="c1">#    out.append(y)</span>
</span><span id="ScaffoldNetwork3d.forward-626"><a href="#ScaffoldNetwork3d.forward-626"><span class="linenos">626</span></a>            <span class="c1">#elif self.num_lags_out is not None and layer.output_dims[3] &gt; self.num_lags_out:</span>
</span><span id="ScaffoldNetwork3d.forward-627"><a href="#ScaffoldNetwork3d.forward-627"><span class="linenos">627</span></a>                <span class="c1"># Need to return just first lag (lag0) -- &#39;chomp&#39;</span>
</span><span id="ScaffoldNetwork3d.forward-628"><a href="#ScaffoldNetwork3d.forward-628"><span class="linenos">628</span></a>            <span class="c1">#    y = x.reshape([nt, -1, layer.output_dims[3]])[..., :(self.num_lags_out)]</span>
</span><span id="ScaffoldNetwork3d.forward-629"><a href="#ScaffoldNetwork3d.forward-629"><span class="linenos">629</span></a>            <span class="c1">#    out.append( y.reshape((nt, -1) ))</span>
</span><span id="ScaffoldNetwork3d.forward-630"><a href="#ScaffoldNetwork3d.forward-630"><span class="linenos">630</span></a>            <span class="c1">#else:</span>
</span><span id="ScaffoldNetwork3d.forward-631"><a href="#ScaffoldNetwork3d.forward-631"><span class="linenos">631</span></a>            <span class="n">out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="ScaffoldNetwork3d.forward-632"><a href="#ScaffoldNetwork3d.forward-632"><span class="linenos">632</span></a>        
</span><span id="ScaffoldNetwork3d.forward-633"><a href="#ScaffoldNetwork3d.forward-633"><span class="linenos">633</span></a>        <span class="c1"># this concatentates across the filter dimension</span>
</span><span id="ScaffoldNetwork3d.forward-634"><a href="#ScaffoldNetwork3d.forward-634"><span class="linenos">634</span></a>        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">out</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span> <span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaffold_levels</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Forward pass through the network.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>inputs (list, torch.Tensor):</strong>  The input to the network.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>x (torch.Tensor): The output of the network.</p>
</blockquote>

<h6 id="raises">Raises:</h6>

<ul>
<li><strong>ValueError:</strong>  If no layers are defined.</li>
</ul>
</div>


                            </div>
                            <div id="ScaffoldNetwork3d.ffnet_dict" class="classattr">
                                        <input id="ScaffoldNetwork3d.ffnet_dict-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator">@classmethod</div>

        <span class="def">def</span>
        <span class="name">ffnet_dict</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">cls</span>, </span><span class="param"><span class="o">**</span><span class="n">kwargs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="ScaffoldNetwork3d.ffnet_dict-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ScaffoldNetwork3d.ffnet_dict"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ScaffoldNetwork3d.ffnet_dict-637"><a href="#ScaffoldNetwork3d.ffnet_dict-637"><span class="linenos">637</span></a>    <span class="nd">@classmethod</span>
</span><span id="ScaffoldNetwork3d.ffnet_dict-638"><a href="#ScaffoldNetwork3d.ffnet_dict-638"><span class="linenos">638</span></a>    <span class="k">def</span> <span class="nf">ffnet_dict</span><span class="p">(</span> <span class="bp">cls</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="ScaffoldNetwork3d.ffnet_dict-639"><a href="#ScaffoldNetwork3d.ffnet_dict-639"><span class="linenos">639</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ScaffoldNetwork3d.ffnet_dict-640"><a href="#ScaffoldNetwork3d.ffnet_dict-640"><span class="linenos">640</span></a><span class="sd">        Returns a dictionary of the scaffold network.</span>
</span><span id="ScaffoldNetwork3d.ffnet_dict-641"><a href="#ScaffoldNetwork3d.ffnet_dict-641"><span class="linenos">641</span></a>
</span><span id="ScaffoldNetwork3d.ffnet_dict-642"><a href="#ScaffoldNetwork3d.ffnet_dict-642"><span class="linenos">642</span></a><span class="sd">        Args:</span>
</span><span id="ScaffoldNetwork3d.ffnet_dict-643"><a href="#ScaffoldNetwork3d.ffnet_dict-643"><span class="linenos">643</span></a><span class="sd">            **kwargs: Additional keyword arguments.</span>
</span><span id="ScaffoldNetwork3d.ffnet_dict-644"><a href="#ScaffoldNetwork3d.ffnet_dict-644"><span class="linenos">644</span></a>
</span><span id="ScaffoldNetwork3d.ffnet_dict-645"><a href="#ScaffoldNetwork3d.ffnet_dict-645"><span class="linenos">645</span></a><span class="sd">        Returns:</span>
</span><span id="ScaffoldNetwork3d.ffnet_dict-646"><a href="#ScaffoldNetwork3d.ffnet_dict-646"><span class="linenos">646</span></a><span class="sd">            ffnet_dict (dict): The dictionary of the scaffold network.</span>
</span><span id="ScaffoldNetwork3d.ffnet_dict-647"><a href="#ScaffoldNetwork3d.ffnet_dict-647"><span class="linenos">647</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ScaffoldNetwork3d.ffnet_dict-648"><a href="#ScaffoldNetwork3d.ffnet_dict-648"><span class="linenos">648</span></a>        <span class="n">ffnet_dict</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">ffnet_dict</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="ScaffoldNetwork3d.ffnet_dict-649"><a href="#ScaffoldNetwork3d.ffnet_dict-649"><span class="linenos">649</span></a>        <span class="n">ffnet_dict</span><span class="p">[</span><span class="s1">&#39;ffnet_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;scaffold3d&#39;</span>
</span><span id="ScaffoldNetwork3d.ffnet_dict-650"><a href="#ScaffoldNetwork3d.ffnet_dict-650"><span class="linenos">650</span></a>        <span class="k">return</span> <span class="n">ffnet_dict</span>
</span></pre></div>


            <div class="docstring"><p>Returns a dictionary of the scaffold network.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>**kwargs:</strong>  Additional keyword arguments.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>ffnet_dict (dict): The dictionary of the scaffold network.</p>
</blockquote>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt><a href="#ScaffoldNetwork">ScaffoldNetwork</a></dt>
                                <dd id="ScaffoldNetwork3d.spatial_dims" class="variable"><a href="#ScaffoldNetwork.spatial_dims">spatial_dims</a></dd>
                <dd id="ScaffoldNetwork3d.filter_count" class="variable"><a href="#ScaffoldNetwork.filter_count">filter_count</a></dd>

            </div>
            <div><dt><a href="#FFnetwork">FFnetwork</a></dt>
                                <dd id="ScaffoldNetwork3d.layer_list" class="variable"><a href="#FFnetwork.layer_list">layer_list</a></dd>
                <dd id="ScaffoldNetwork3d.layer_types" class="variable"><a href="#FFnetwork.layer_types">layer_types</a></dd>
                <dd id="ScaffoldNetwork3d.xstim_n" class="variable"><a href="#FFnetwork.xstim_n">xstim_n</a></dd>
                <dd id="ScaffoldNetwork3d.ffnets_in" class="variable"><a href="#FFnetwork.ffnets_in">ffnets_in</a></dd>
                <dd id="ScaffoldNetwork3d.layers" class="variable"><a href="#FFnetwork.layers">layers</a></dd>
                <dd id="ScaffoldNetwork3d.output_dims" class="variable"><a href="#FFnetwork.output_dims">output_dims</a></dd>
                <dd id="ScaffoldNetwork3d.num_outputs" class="variable"><a href="#FFnetwork.num_outputs">num_outputs</a></dd>
                <dd id="ScaffoldNetwork3d.determine_input_dims" class="function"><a href="#FFnetwork.determine_input_dims">determine_input_dims</a></dd>
                <dd id="ScaffoldNetwork3d.preprocess_input" class="function"><a href="#FFnetwork.preprocess_input">preprocess_input</a></dd>
                <dd id="ScaffoldNetwork3d.prepare_regularization" class="function"><a href="#FFnetwork.prepare_regularization">prepare_regularization</a></dd>
                <dd id="ScaffoldNetwork3d.compute_reg_loss" class="function"><a href="#FFnetwork.compute_reg_loss">compute_reg_loss</a></dd>
                <dd id="ScaffoldNetwork3d.list_parameters" class="function"><a href="#FFnetwork.list_parameters">list_parameters</a></dd>
                <dd id="ScaffoldNetwork3d.set_parameters" class="function"><a href="#FFnetwork.set_parameters">set_parameters</a></dd>
                <dd id="ScaffoldNetwork3d.set_reg_val" class="function"><a href="#FFnetwork.set_reg_val">set_reg_val</a></dd>
                <dd id="ScaffoldNetwork3d.plot_filters" class="function"><a href="#FFnetwork.plot_filters">plot_filters</a></dd>
                <dd id="ScaffoldNetwork3d.get_weights" class="function"><a href="#FFnetwork.get_weights">get_weights</a></dd>

            </div>
            <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="ScaffoldNetwork3d.dump_patches" class="variable">dump_patches</dd>
                <dd id="ScaffoldNetwork3d.training" class="variable">training</dd>
                <dd id="ScaffoldNetwork3d.call_super_init" class="variable">call_super_init</dd>
                <dd id="ScaffoldNetwork3d.register_buffer" class="function">register_buffer</dd>
                <dd id="ScaffoldNetwork3d.register_parameter" class="function">register_parameter</dd>
                <dd id="ScaffoldNetwork3d.add_module" class="function">add_module</dd>
                <dd id="ScaffoldNetwork3d.register_module" class="function">register_module</dd>
                <dd id="ScaffoldNetwork3d.get_submodule" class="function">get_submodule</dd>
                <dd id="ScaffoldNetwork3d.get_parameter" class="function">get_parameter</dd>
                <dd id="ScaffoldNetwork3d.get_buffer" class="function">get_buffer</dd>
                <dd id="ScaffoldNetwork3d.get_extra_state" class="function">get_extra_state</dd>
                <dd id="ScaffoldNetwork3d.set_extra_state" class="function">set_extra_state</dd>
                <dd id="ScaffoldNetwork3d.apply" class="function">apply</dd>
                <dd id="ScaffoldNetwork3d.cuda" class="function">cuda</dd>
                <dd id="ScaffoldNetwork3d.ipu" class="function">ipu</dd>
                <dd id="ScaffoldNetwork3d.xpu" class="function">xpu</dd>
                <dd id="ScaffoldNetwork3d.cpu" class="function">cpu</dd>
                <dd id="ScaffoldNetwork3d.type" class="function">type</dd>
                <dd id="ScaffoldNetwork3d.float" class="function">float</dd>
                <dd id="ScaffoldNetwork3d.double" class="function">double</dd>
                <dd id="ScaffoldNetwork3d.half" class="function">half</dd>
                <dd id="ScaffoldNetwork3d.bfloat16" class="function">bfloat16</dd>
                <dd id="ScaffoldNetwork3d.to_empty" class="function">to_empty</dd>
                <dd id="ScaffoldNetwork3d.to" class="function">to</dd>
                <dd id="ScaffoldNetwork3d.register_full_backward_pre_hook" class="function">register_full_backward_pre_hook</dd>
                <dd id="ScaffoldNetwork3d.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="ScaffoldNetwork3d.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="ScaffoldNetwork3d.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="ScaffoldNetwork3d.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="ScaffoldNetwork3d.register_state_dict_pre_hook" class="function">register_state_dict_pre_hook</dd>
                <dd id="ScaffoldNetwork3d.state_dict" class="function">state_dict</dd>
                <dd id="ScaffoldNetwork3d.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="ScaffoldNetwork3d.load_state_dict" class="function">load_state_dict</dd>
                <dd id="ScaffoldNetwork3d.parameters" class="function">parameters</dd>
                <dd id="ScaffoldNetwork3d.named_parameters" class="function">named_parameters</dd>
                <dd id="ScaffoldNetwork3d.buffers" class="function">buffers</dd>
                <dd id="ScaffoldNetwork3d.named_buffers" class="function">named_buffers</dd>
                <dd id="ScaffoldNetwork3d.children" class="function">children</dd>
                <dd id="ScaffoldNetwork3d.named_children" class="function">named_children</dd>
                <dd id="ScaffoldNetwork3d.modules" class="function">modules</dd>
                <dd id="ScaffoldNetwork3d.named_modules" class="function">named_modules</dd>
                <dd id="ScaffoldNetwork3d.train" class="function">train</dd>
                <dd id="ScaffoldNetwork3d.eval" class="function">eval</dd>
                <dd id="ScaffoldNetwork3d.requires_grad_" class="function">requires_grad_</dd>
                <dd id="ScaffoldNetwork3d.zero_grad" class="function">zero_grad</dd>
                <dd id="ScaffoldNetwork3d.share_memory" class="function">share_memory</dd>
                <dd id="ScaffoldNetwork3d.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="ReadoutNetwork">
                            <input id="ReadoutNetwork-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">ReadoutNetwork</span><wbr>(<span class="base"><a href="#FFnetwork">FFnetwork</a></span>):

                <label class="view-source-button" for="ReadoutNetwork-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ReadoutNetwork"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ReadoutNetwork-654"><a href="#ReadoutNetwork-654"><span class="linenos">654</span></a><span class="k">class</span> <span class="nc">ReadoutNetwork</span><span class="p">(</span><span class="n">FFnetwork</span><span class="p">):</span>
</span><span id="ReadoutNetwork-655"><a href="#ReadoutNetwork-655"><span class="linenos">655</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ReadoutNetwork-656"><a href="#ReadoutNetwork-656"><span class="linenos">656</span></a><span class="sd">    A readout using a spatial transformer layer whose positions are sampled from one Gaussian per neuron. Mean</span>
</span><span id="ReadoutNetwork-657"><a href="#ReadoutNetwork-657"><span class="linenos">657</span></a><span class="sd">    and covariance of that Gaussian are learned.</span>
</span><span id="ReadoutNetwork-658"><a href="#ReadoutNetwork-658"><span class="linenos">658</span></a><span class="sd">    </span>
</span><span id="ReadoutNetwork-659"><a href="#ReadoutNetwork-659"><span class="linenos">659</span></a><span class="sd">    This essentially used the constructor for Point1DGaussian, with dicationary input.</span>
</span><span id="ReadoutNetwork-660"><a href="#ReadoutNetwork-660"><span class="linenos">660</span></a><span class="sd">    Currently there is no extra code required at the network level. I think the constructor</span>
</span><span id="ReadoutNetwork-661"><a href="#ReadoutNetwork-661"><span class="linenos">661</span></a><span class="sd">    can be left off entirely, but leaving in in case want to add something.</span>
</span><span id="ReadoutNetwork-662"><a href="#ReadoutNetwork-662"><span class="linenos">662</span></a>
</span><span id="ReadoutNetwork-663"><a href="#ReadoutNetwork-663"><span class="linenos">663</span></a><span class="sd">    Args:</span>
</span><span id="ReadoutNetwork-664"><a href="#ReadoutNetwork-664"><span class="linenos">664</span></a><span class="sd">        in_shape (list, tuple): shape of the input feature map [channels, width, height]</span>
</span><span id="ReadoutNetwork-665"><a href="#ReadoutNetwork-665"><span class="linenos">665</span></a><span class="sd">        outdims (int): number of output units</span>
</span><span id="ReadoutNetwork-666"><a href="#ReadoutNetwork-666"><span class="linenos">666</span></a><span class="sd">        bias (bool): adds a bias term</span>
</span><span id="ReadoutNetwork-667"><a href="#ReadoutNetwork-667"><span class="linenos">667</span></a><span class="sd">        init_mu_range (float): initialises the the mean with Uniform([-init_range, init_range])</span>
</span><span id="ReadoutNetwork-668"><a href="#ReadoutNetwork-668"><span class="linenos">668</span></a><span class="sd">                            [expected: positive value &lt;=1]. Default: 0.1</span>
</span><span id="ReadoutNetwork-669"><a href="#ReadoutNetwork-669"><span class="linenos">669</span></a><span class="sd">        init_sigma (float): The standard deviation of the Gaussian with `init_sigma` when `gauss_type` is</span>
</span><span id="ReadoutNetwork-670"><a href="#ReadoutNetwork-670"><span class="linenos">670</span></a><span class="sd">            &#39;isotropic&#39; or &#39;uncorrelated&#39;. When `gauss_type=&#39;full&#39;` initialize the square root of the</span>
</span><span id="ReadoutNetwork-671"><a href="#ReadoutNetwork-671"><span class="linenos">671</span></a><span class="sd">            covariance matrix with with Uniform([-init_sigma, init_sigma]). Default: 1</span>
</span><span id="ReadoutNetwork-672"><a href="#ReadoutNetwork-672"><span class="linenos">672</span></a><span class="sd">        batch_sample (bool): if True, samples a position for each image in the batch separately</span>
</span><span id="ReadoutNetwork-673"><a href="#ReadoutNetwork-673"><span class="linenos">673</span></a><span class="sd">                            [default: True as it decreases convergence time and performs just as well]</span>
</span><span id="ReadoutNetwork-674"><a href="#ReadoutNetwork-674"><span class="linenos">674</span></a><span class="sd">        align_corners (bool): Keyword agrument to gridsample for bilinear interpolation.</span>
</span><span id="ReadoutNetwork-675"><a href="#ReadoutNetwork-675"><span class="linenos">675</span></a><span class="sd">                It changed behavior in PyTorch 1.3. The default of align_corners = True is setting the</span>
</span><span id="ReadoutNetwork-676"><a href="#ReadoutNetwork-676"><span class="linenos">676</span></a><span class="sd">                behavior to pre PyTorch 1.3 functionality for comparability.</span>
</span><span id="ReadoutNetwork-677"><a href="#ReadoutNetwork-677"><span class="linenos">677</span></a><span class="sd">        gauss_type (str): Which Gaussian to use. Options are &#39;isotropic&#39;, &#39;uncorrelated&#39;, or &#39;full&#39; (default).</span>
</span><span id="ReadoutNetwork-678"><a href="#ReadoutNetwork-678"><span class="linenos">678</span></a><span class="sd">        shifter (dict): Parameters for a predictor of shfiting grid locations. Has to have a form like</span>
</span><span id="ReadoutNetwork-679"><a href="#ReadoutNetwork-679"><span class="linenos">679</span></a><span class="sd">                        {</span>
</span><span id="ReadoutNetwork-680"><a href="#ReadoutNetwork-680"><span class="linenos">680</span></a><span class="sd">                        &#39;hidden_layers&#39;:1,</span>
</span><span id="ReadoutNetwork-681"><a href="#ReadoutNetwork-681"><span class="linenos">681</span></a><span class="sd">                        &#39;hidden_features&#39;:20,</span>
</span><span id="ReadoutNetwork-682"><a href="#ReadoutNetwork-682"><span class="linenos">682</span></a><span class="sd">                        &#39;final_tanh&#39;: False,</span>
</span><span id="ReadoutNetwork-683"><a href="#ReadoutNetwork-683"><span class="linenos">683</span></a><span class="sd">                        }</span>
</span><span id="ReadoutNetwork-684"><a href="#ReadoutNetwork-684"><span class="linenos">684</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="ReadoutNetwork-685"><a href="#ReadoutNetwork-685"><span class="linenos">685</span></a>
</span><span id="ReadoutNetwork-686"><a href="#ReadoutNetwork-686"><span class="linenos">686</span></a>    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="ReadoutNetwork-687"><a href="#ReadoutNetwork-687"><span class="linenos">687</span></a>        <span class="n">s</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__repr__</span><span class="p">()</span>
</span><span id="ReadoutNetwork-688"><a href="#ReadoutNetwork-688"><span class="linenos">688</span></a>        <span class="c1"># Add information about module to print out</span>
</span><span id="ReadoutNetwork-689"><a href="#ReadoutNetwork-689"><span class="linenos">689</span></a>        <span class="n">s</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
</span><span id="ReadoutNetwork-690"><a href="#ReadoutNetwork-690"><span class="linenos">690</span></a>        <span class="k">return</span> <span class="n">s</span>
</span><span id="ReadoutNetwork-691"><a href="#ReadoutNetwork-691"><span class="linenos">691</span></a>
</span><span id="ReadoutNetwork-692"><a href="#ReadoutNetwork-692"><span class="linenos">692</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="ReadoutNetwork-693"><a href="#ReadoutNetwork-693"><span class="linenos">693</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="ReadoutNetwork-694"><a href="#ReadoutNetwork-694"><span class="linenos">694</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">network_type</span> <span class="o">=</span> <span class="s1">&#39;readout&#39;</span>
</span><span id="ReadoutNetwork-695"><a href="#ReadoutNetwork-695"><span class="linenos">695</span></a>        <span class="c1"># Make sure first type is readout: important for interpretation of input dims and potential shifter</span>
</span><span id="ReadoutNetwork-696"><a href="#ReadoutNetwork-696"><span class="linenos">696</span></a>        <span class="c1">#assert kwargs[&#39;layer_list&#39;][0][&#39;layer_type&#39;] == &#39;readout&#39;, &quot;READOUT NET: Incorrect leading layer type&quot;</span>
</span><span id="ReadoutNetwork-697"><a href="#ReadoutNetwork-697"><span class="linenos">697</span></a>
</span><span id="ReadoutNetwork-698"><a href="#ReadoutNetwork-698"><span class="linenos">698</span></a>    <span class="k">def</span> <span class="nf">determine_input_dims</span><span class="p">(</span> <span class="bp">self</span><span class="p">,</span> <span class="n">input_dims_list</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="ReadoutNetwork-699"><a href="#ReadoutNetwork-699"><span class="linenos">699</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ReadoutNetwork-700"><a href="#ReadoutNetwork-700"><span class="linenos">700</span></a><span class="sd">        Sets input_dims given network inputs. Can be overloaded depending on the network type. For this base class, there</span>
</span><span id="ReadoutNetwork-701"><a href="#ReadoutNetwork-701"><span class="linenos">701</span></a><span class="sd">        are two types of network input: external stimulus (xstim_n) or a list of internal (ffnet_in) networks:</span>
</span><span id="ReadoutNetwork-702"><a href="#ReadoutNetwork-702"><span class="linenos">702</span></a><span class="sd">            For external inputs, it just uses the passed-in input_dims</span>
</span><span id="ReadoutNetwork-703"><a href="#ReadoutNetwork-703"><span class="linenos">703</span></a><span class="sd">            For internal network inputs, it will concatenate inputs along the filter dimension, but MUST match other dims</span>
</span><span id="ReadoutNetwork-704"><a href="#ReadoutNetwork-704"><span class="linenos">704</span></a><span class="sd">        As currently designed, this can either external or internal, but not both</span>
</span><span id="ReadoutNetwork-705"><a href="#ReadoutNetwork-705"><span class="linenos">705</span></a><span class="sd">        </span>
</span><span id="ReadoutNetwork-706"><a href="#ReadoutNetwork-706"><span class="linenos">706</span></a><span class="sd">        This sets the following internal FFnetwork properties:</span>
</span><span id="ReadoutNetwork-707"><a href="#ReadoutNetwork-707"><span class="linenos">707</span></a><span class="sd">            self.input_dims</span>
</span><span id="ReadoutNetwork-708"><a href="#ReadoutNetwork-708"><span class="linenos">708</span></a><span class="sd">            self.input_dims_list</span>
</span><span id="ReadoutNetwork-709"><a href="#ReadoutNetwork-709"><span class="linenos">709</span></a><span class="sd">        and returns Boolean whether the passed in input dims are valid</span>
</span><span id="ReadoutNetwork-710"><a href="#ReadoutNetwork-710"><span class="linenos">710</span></a>
</span><span id="ReadoutNetwork-711"><a href="#ReadoutNetwork-711"><span class="linenos">711</span></a><span class="sd">        Args:</span>
</span><span id="ReadoutNetwork-712"><a href="#ReadoutNetwork-712"><span class="linenos">712</span></a><span class="sd">            input_dims_list (list): A list of input dimensions for each layer.</span>
</span><span id="ReadoutNetwork-713"><a href="#ReadoutNetwork-713"><span class="linenos">713</span></a><span class="sd">            **kwargs: Additional keyword arguments.</span>
</span><span id="ReadoutNetwork-714"><a href="#ReadoutNetwork-714"><span class="linenos">714</span></a>
</span><span id="ReadoutNetwork-715"><a href="#ReadoutNetwork-715"><span class="linenos">715</span></a><span class="sd">        Returns:</span>
</span><span id="ReadoutNetwork-716"><a href="#ReadoutNetwork-716"><span class="linenos">716</span></a><span class="sd">            valid_input_dims (bool): Whether the passed in input dims are valid.</span>
</span><span id="ReadoutNetwork-717"><a href="#ReadoutNetwork-717"><span class="linenos">717</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ReadoutNetwork-718"><a href="#ReadoutNetwork-718"><span class="linenos">718</span></a>
</span><span id="ReadoutNetwork-719"><a href="#ReadoutNetwork-719"><span class="linenos">719</span></a>        <span class="n">valid_input_dims</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="ReadoutNetwork-720"><a href="#ReadoutNetwork-720"><span class="linenos">720</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffnets_in</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ReadoutNetwork-721"><a href="#ReadoutNetwork-721"><span class="linenos">721</span></a>            <span class="c1"># then external input (assume from one source)</span>
</span><span id="ReadoutNetwork-722"><a href="#ReadoutNetwork-722"><span class="linenos">722</span></a>            <span class="n">valid_input_dims</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="ReadoutNetwork-723"><a href="#ReadoutNetwork-723"><span class="linenos">723</span></a>            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Readout layer cannot get an external input.&#39;</span><span class="p">)</span> 
</span><span id="ReadoutNetwork-724"><a href="#ReadoutNetwork-724"><span class="linenos">724</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">input_dims</span> <span class="o">=</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ReadoutNetwork-725"><a href="#ReadoutNetwork-725"><span class="linenos">725</span></a>        <span class="k">else</span><span class="p">:</span>             
</span><span id="ReadoutNetwork-726"><a href="#ReadoutNetwork-726"><span class="linenos">726</span></a>            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_dims_list</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ffnets_in</span><span class="p">),</span> <span class="s1">&#39;Internal: misspecification of input_dims for FFnetwork.&#39;</span>
</span><span id="ReadoutNetwork-727"><a href="#ReadoutNetwork-727"><span class="linenos">727</span></a>            <span class="c1"># First dimension is the input network</span>
</span><span id="ReadoutNetwork-728"><a href="#ReadoutNetwork-728"><span class="linenos">728</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">input_dims</span> <span class="o">=</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ReadoutNetwork-729"><a href="#ReadoutNetwork-729"><span class="linenos">729</span></a>            <span class="c1"># Second dimension would be </span>
</span><span id="ReadoutNetwork-730"><a href="#ReadoutNetwork-730"><span class="linenos">730</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">shifter</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ffnets_in</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span>
</span><span id="ReadoutNetwork-731"><a href="#ReadoutNetwork-731"><span class="linenos">731</span></a>
</span><span id="ReadoutNetwork-732"><a href="#ReadoutNetwork-732"><span class="linenos">732</span></a>        <span class="k">return</span> <span class="n">valid_input_dims</span>
</span><span id="ReadoutNetwork-733"><a href="#ReadoutNetwork-733"><span class="linenos">733</span></a>    <span class="c1"># END ReadoutNetwork.determine_input_dims</span>
</span><span id="ReadoutNetwork-734"><a href="#ReadoutNetwork-734"><span class="linenos">734</span></a>
</span><span id="ReadoutNetwork-735"><a href="#ReadoutNetwork-735"><span class="linenos">735</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="ReadoutNetwork-736"><a href="#ReadoutNetwork-736"><span class="linenos">736</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ReadoutNetwork-737"><a href="#ReadoutNetwork-737"><span class="linenos">737</span></a><span class="sd">        Network inputs correspond to output of conv layer, and (if it exists), a shifter.</span>
</span><span id="ReadoutNetwork-738"><a href="#ReadoutNetwork-738"><span class="linenos">738</span></a><span class="sd">        </span>
</span><span id="ReadoutNetwork-739"><a href="#ReadoutNetwork-739"><span class="linenos">739</span></a><span class="sd">        Args:</span>
</span><span id="ReadoutNetwork-740"><a href="#ReadoutNetwork-740"><span class="linenos">740</span></a><span class="sd">            inputs (list, torch.Tensor): The input to the network.</span>
</span><span id="ReadoutNetwork-741"><a href="#ReadoutNetwork-741"><span class="linenos">741</span></a>
</span><span id="ReadoutNetwork-742"><a href="#ReadoutNetwork-742"><span class="linenos">742</span></a><span class="sd">        Returns:</span>
</span><span id="ReadoutNetwork-743"><a href="#ReadoutNetwork-743"><span class="linenos">743</span></a><span class="sd">            y (torch.Tensor): The output of the network.</span>
</span><span id="ReadoutNetwork-744"><a href="#ReadoutNetwork-744"><span class="linenos">744</span></a><span class="sd">        &quot;&quot;&quot;</span> 
</span><span id="ReadoutNetwork-745"><a href="#ReadoutNetwork-745"><span class="linenos">745</span></a>
</span><span id="ReadoutNetwork-746"><a href="#ReadoutNetwork-746"><span class="linenos">746</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="ReadoutNetwork-747"><a href="#ReadoutNetwork-747"><span class="linenos">747</span></a>            <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">inputs</span><span class="p">]</span>
</span><span id="ReadoutNetwork-748"><a href="#ReadoutNetwork-748"><span class="linenos">748</span></a>
</span><span id="ReadoutNetwork-749"><a href="#ReadoutNetwork-749"><span class="linenos">749</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">shifter</span><span class="p">:</span>
</span><span id="ReadoutNetwork-750"><a href="#ReadoutNetwork-750"><span class="linenos">750</span></a>            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">shift</span><span class="o">=</span><span class="n">inputs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span><span id="ReadoutNetwork-751"><a href="#ReadoutNetwork-751"><span class="linenos">751</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="ReadoutNetwork-752"><a href="#ReadoutNetwork-752"><span class="linenos">752</span></a>            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span><span id="ReadoutNetwork-753"><a href="#ReadoutNetwork-753"><span class="linenos">753</span></a>        <span class="k">return</span> <span class="n">y</span>
</span><span id="ReadoutNetwork-754"><a href="#ReadoutNetwork-754"><span class="linenos">754</span></a>    <span class="c1"># END ReadoutNetwork.forward</span>
</span><span id="ReadoutNetwork-755"><a href="#ReadoutNetwork-755"><span class="linenos">755</span></a>
</span><span id="ReadoutNetwork-756"><a href="#ReadoutNetwork-756"><span class="linenos">756</span></a>    <span class="k">def</span> <span class="nf">get_readout_locations</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="ReadoutNetwork-757"><a href="#ReadoutNetwork-757"><span class="linenos">757</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ReadoutNetwork-758"><a href="#ReadoutNetwork-758"><span class="linenos">758</span></a><span class="sd">        Returns the readout locations.</span>
</span><span id="ReadoutNetwork-759"><a href="#ReadoutNetwork-759"><span class="linenos">759</span></a>
</span><span id="ReadoutNetwork-760"><a href="#ReadoutNetwork-760"><span class="linenos">760</span></a><span class="sd">        Args:</span>
</span><span id="ReadoutNetwork-761"><a href="#ReadoutNetwork-761"><span class="linenos">761</span></a><span class="sd">            None</span>
</span><span id="ReadoutNetwork-762"><a href="#ReadoutNetwork-762"><span class="linenos">762</span></a>
</span><span id="ReadoutNetwork-763"><a href="#ReadoutNetwork-763"><span class="linenos">763</span></a><span class="sd">        Returns:</span>
</span><span id="ReadoutNetwork-764"><a href="#ReadoutNetwork-764"><span class="linenos">764</span></a><span class="sd">            The readout locations.</span>
</span><span id="ReadoutNetwork-765"><a href="#ReadoutNetwork-765"><span class="linenos">765</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ReadoutNetwork-766"><a href="#ReadoutNetwork-766"><span class="linenos">766</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_readout_locations</span><span class="p">()</span>
</span><span id="ReadoutNetwork-767"><a href="#ReadoutNetwork-767"><span class="linenos">767</span></a>
</span><span id="ReadoutNetwork-768"><a href="#ReadoutNetwork-768"><span class="linenos">768</span></a>    <span class="k">def</span> <span class="nf">set_readout_locations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">locs</span><span class="p">):</span>
</span><span id="ReadoutNetwork-769"><a href="#ReadoutNetwork-769"><span class="linenos">769</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ReadoutNetwork-770"><a href="#ReadoutNetwork-770"><span class="linenos">770</span></a><span class="sd">        Sets the readout locations.</span>
</span><span id="ReadoutNetwork-771"><a href="#ReadoutNetwork-771"><span class="linenos">771</span></a>
</span><span id="ReadoutNetwork-772"><a href="#ReadoutNetwork-772"><span class="linenos">772</span></a><span class="sd">        Args:</span>
</span><span id="ReadoutNetwork-773"><a href="#ReadoutNetwork-773"><span class="linenos">773</span></a><span class="sd">            locs: The readout locations.</span>
</span><span id="ReadoutNetwork-774"><a href="#ReadoutNetwork-774"><span class="linenos">774</span></a>
</span><span id="ReadoutNetwork-775"><a href="#ReadoutNetwork-775"><span class="linenos">775</span></a><span class="sd">        Returns:</span>
</span><span id="ReadoutNetwork-776"><a href="#ReadoutNetwork-776"><span class="linenos">776</span></a><span class="sd">            None</span>
</span><span id="ReadoutNetwork-777"><a href="#ReadoutNetwork-777"><span class="linenos">777</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ReadoutNetwork-778"><a href="#ReadoutNetwork-778"><span class="linenos">778</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_readout_locations</span><span class="p">(</span><span class="n">locs</span><span class="p">)</span>
</span><span id="ReadoutNetwork-779"><a href="#ReadoutNetwork-779"><span class="linenos">779</span></a>
</span><span id="ReadoutNetwork-780"><a href="#ReadoutNetwork-780"><span class="linenos">780</span></a>    <span class="nd">@classmethod</span>
</span><span id="ReadoutNetwork-781"><a href="#ReadoutNetwork-781"><span class="linenos">781</span></a>    <span class="k">def</span> <span class="nf">ffnet_dict</span><span class="p">(</span> <span class="bp">cls</span><span class="p">,</span> <span class="n">ffnet_n</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="ReadoutNetwork-782"><a href="#ReadoutNetwork-782"><span class="linenos">782</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ReadoutNetwork-783"><a href="#ReadoutNetwork-783"><span class="linenos">783</span></a><span class="sd">        Returns a dictionary of the readout network.</span>
</span><span id="ReadoutNetwork-784"><a href="#ReadoutNetwork-784"><span class="linenos">784</span></a>
</span><span id="ReadoutNetwork-785"><a href="#ReadoutNetwork-785"><span class="linenos">785</span></a><span class="sd">        Args:</span>
</span><span id="ReadoutNetwork-786"><a href="#ReadoutNetwork-786"><span class="linenos">786</span></a><span class="sd">            ffnet_n (int): The feedforward network.</span>
</span><span id="ReadoutNetwork-787"><a href="#ReadoutNetwork-787"><span class="linenos">787</span></a>
</span><span id="ReadoutNetwork-788"><a href="#ReadoutNetwork-788"><span class="linenos">788</span></a><span class="sd">        Returns:</span>
</span><span id="ReadoutNetwork-789"><a href="#ReadoutNetwork-789"><span class="linenos">789</span></a><span class="sd">            ffnet_dict (dict): The dictionary of the readout network.</span>
</span><span id="ReadoutNetwork-790"><a href="#ReadoutNetwork-790"><span class="linenos">790</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ReadoutNetwork-791"><a href="#ReadoutNetwork-791"><span class="linenos">791</span></a>        <span class="n">ffnet_dict</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">ffnet_dict</span><span class="p">(</span><span class="n">xstim_n</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ffnet_n</span><span class="o">=</span><span class="n">ffnet_n</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="ReadoutNetwork-792"><a href="#ReadoutNetwork-792"><span class="linenos">792</span></a>        <span class="n">ffnet_dict</span><span class="p">[</span><span class="s1">&#39;ffnet_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;readout&#39;</span>
</span><span id="ReadoutNetwork-793"><a href="#ReadoutNetwork-793"><span class="linenos">793</span></a>        <span class="k">return</span> <span class="n">ffnet_dict</span>
</span><span id="ReadoutNetwork-794"><a href="#ReadoutNetwork-794"><span class="linenos">794</span></a>    <span class="c1"># END ReadoutNetwork</span>
</span></pre></div>


            <div class="docstring"><p>A readout using a spatial transformer layer whose positions are sampled from one Gaussian per neuron. Mean
and covariance of that Gaussian are learned.</p>

<p>This essentially used the constructor for Point1DGaussian, with dicationary input.
Currently there is no extra code required at the network level. I think the constructor
can be left off entirely, but leaving in in case want to add something.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>in_shape (list, tuple):</strong>  shape of the input feature map [channels, width, height]</li>
<li><strong>outdims (int):</strong>  number of output units</li>
<li><strong>bias (bool):</strong>  adds a bias term</li>
<li><strong>init_mu_range (float):</strong>  initialises the the mean with Uniform([-init_range, init_range])
[expected: positive value &lt;=1]. Default: 0.1</li>
<li><strong>init_sigma (float):</strong>  The standard deviation of the Gaussian with <code>init_sigma</code> when <code>gauss_type</code> is
'isotropic' or 'uncorrelated'. When <code>gauss_type='full'</code> initialize the square root of the
covariance matrix with with Uniform([-init_sigma, init_sigma]). Default: 1</li>
<li><strong>batch_sample (bool):</strong>  if True, samples a position for each image in the batch separately
[default: True as it decreases convergence time and performs just as well]</li>
<li><strong>align_corners (bool):</strong>  Keyword agrument to gridsample for bilinear interpolation.
It changed behavior in PyTorch 1.3. The default of align_corners = True is setting the
behavior to pre PyTorch 1.3 functionality for comparability.</li>
<li><strong>gauss_type (str):</strong>  Which Gaussian to use. Options are 'isotropic', 'uncorrelated', or 'full' (default).</li>
<li><strong>shifter (dict):</strong>  Parameters for a predictor of shfiting grid locations. Has to have a form like
{
'hidden_layers':1,
'hidden_features':20,
'final_tanh': False,
}</li>
</ul>
</div>


                            <div id="ReadoutNetwork.__init__" class="classattr">
                                        <input id="ReadoutNetwork.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">ReadoutNetwork</span><span class="signature pdoc-code condensed">(<span class="param"><span class="o">**</span><span class="n">kwargs</span></span>)</span>

                <label class="view-source-button" for="ReadoutNetwork.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ReadoutNetwork.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ReadoutNetwork.__init__-692"><a href="#ReadoutNetwork.__init__-692"><span class="linenos">692</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="ReadoutNetwork.__init__-693"><a href="#ReadoutNetwork.__init__-693"><span class="linenos">693</span></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="ReadoutNetwork.__init__-694"><a href="#ReadoutNetwork.__init__-694"><span class="linenos">694</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">network_type</span> <span class="o">=</span> <span class="s1">&#39;readout&#39;</span>
</span><span id="ReadoutNetwork.__init__-695"><a href="#ReadoutNetwork.__init__-695"><span class="linenos">695</span></a>        <span class="c1"># Make sure first type is readout: important for interpretation of input dims and potential shifter</span>
</span><span id="ReadoutNetwork.__init__-696"><a href="#ReadoutNetwork.__init__-696"><span class="linenos">696</span></a>        <span class="c1">#assert kwargs[&#39;layer_list&#39;][0][&#39;layer_type&#39;] == &#39;readout&#39;, &quot;READOUT NET: Incorrect leading layer type&quot;</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="ReadoutNetwork.network_type" class="classattr">
                                <div class="attr variable">
            <span class="name">network_type</span>

        
    </div>
    <a class="headerlink" href="#ReadoutNetwork.network_type"></a>
    
    

                            </div>
                            <div id="ReadoutNetwork.determine_input_dims" class="classattr">
                                        <input id="ReadoutNetwork.determine_input_dims-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">determine_input_dims</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">input_dims_list</span>, </span><span class="param"><span class="o">**</span><span class="n">kwargs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="ReadoutNetwork.determine_input_dims-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ReadoutNetwork.determine_input_dims"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ReadoutNetwork.determine_input_dims-698"><a href="#ReadoutNetwork.determine_input_dims-698"><span class="linenos">698</span></a>    <span class="k">def</span> <span class="nf">determine_input_dims</span><span class="p">(</span> <span class="bp">self</span><span class="p">,</span> <span class="n">input_dims_list</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="ReadoutNetwork.determine_input_dims-699"><a href="#ReadoutNetwork.determine_input_dims-699"><span class="linenos">699</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ReadoutNetwork.determine_input_dims-700"><a href="#ReadoutNetwork.determine_input_dims-700"><span class="linenos">700</span></a><span class="sd">        Sets input_dims given network inputs. Can be overloaded depending on the network type. For this base class, there</span>
</span><span id="ReadoutNetwork.determine_input_dims-701"><a href="#ReadoutNetwork.determine_input_dims-701"><span class="linenos">701</span></a><span class="sd">        are two types of network input: external stimulus (xstim_n) or a list of internal (ffnet_in) networks:</span>
</span><span id="ReadoutNetwork.determine_input_dims-702"><a href="#ReadoutNetwork.determine_input_dims-702"><span class="linenos">702</span></a><span class="sd">            For external inputs, it just uses the passed-in input_dims</span>
</span><span id="ReadoutNetwork.determine_input_dims-703"><a href="#ReadoutNetwork.determine_input_dims-703"><span class="linenos">703</span></a><span class="sd">            For internal network inputs, it will concatenate inputs along the filter dimension, but MUST match other dims</span>
</span><span id="ReadoutNetwork.determine_input_dims-704"><a href="#ReadoutNetwork.determine_input_dims-704"><span class="linenos">704</span></a><span class="sd">        As currently designed, this can either external or internal, but not both</span>
</span><span id="ReadoutNetwork.determine_input_dims-705"><a href="#ReadoutNetwork.determine_input_dims-705"><span class="linenos">705</span></a><span class="sd">        </span>
</span><span id="ReadoutNetwork.determine_input_dims-706"><a href="#ReadoutNetwork.determine_input_dims-706"><span class="linenos">706</span></a><span class="sd">        This sets the following internal FFnetwork properties:</span>
</span><span id="ReadoutNetwork.determine_input_dims-707"><a href="#ReadoutNetwork.determine_input_dims-707"><span class="linenos">707</span></a><span class="sd">            self.input_dims</span>
</span><span id="ReadoutNetwork.determine_input_dims-708"><a href="#ReadoutNetwork.determine_input_dims-708"><span class="linenos">708</span></a><span class="sd">            self.input_dims_list</span>
</span><span id="ReadoutNetwork.determine_input_dims-709"><a href="#ReadoutNetwork.determine_input_dims-709"><span class="linenos">709</span></a><span class="sd">        and returns Boolean whether the passed in input dims are valid</span>
</span><span id="ReadoutNetwork.determine_input_dims-710"><a href="#ReadoutNetwork.determine_input_dims-710"><span class="linenos">710</span></a>
</span><span id="ReadoutNetwork.determine_input_dims-711"><a href="#ReadoutNetwork.determine_input_dims-711"><span class="linenos">711</span></a><span class="sd">        Args:</span>
</span><span id="ReadoutNetwork.determine_input_dims-712"><a href="#ReadoutNetwork.determine_input_dims-712"><span class="linenos">712</span></a><span class="sd">            input_dims_list (list): A list of input dimensions for each layer.</span>
</span><span id="ReadoutNetwork.determine_input_dims-713"><a href="#ReadoutNetwork.determine_input_dims-713"><span class="linenos">713</span></a><span class="sd">            **kwargs: Additional keyword arguments.</span>
</span><span id="ReadoutNetwork.determine_input_dims-714"><a href="#ReadoutNetwork.determine_input_dims-714"><span class="linenos">714</span></a>
</span><span id="ReadoutNetwork.determine_input_dims-715"><a href="#ReadoutNetwork.determine_input_dims-715"><span class="linenos">715</span></a><span class="sd">        Returns:</span>
</span><span id="ReadoutNetwork.determine_input_dims-716"><a href="#ReadoutNetwork.determine_input_dims-716"><span class="linenos">716</span></a><span class="sd">            valid_input_dims (bool): Whether the passed in input dims are valid.</span>
</span><span id="ReadoutNetwork.determine_input_dims-717"><a href="#ReadoutNetwork.determine_input_dims-717"><span class="linenos">717</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ReadoutNetwork.determine_input_dims-718"><a href="#ReadoutNetwork.determine_input_dims-718"><span class="linenos">718</span></a>
</span><span id="ReadoutNetwork.determine_input_dims-719"><a href="#ReadoutNetwork.determine_input_dims-719"><span class="linenos">719</span></a>        <span class="n">valid_input_dims</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="ReadoutNetwork.determine_input_dims-720"><a href="#ReadoutNetwork.determine_input_dims-720"><span class="linenos">720</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffnets_in</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="ReadoutNetwork.determine_input_dims-721"><a href="#ReadoutNetwork.determine_input_dims-721"><span class="linenos">721</span></a>            <span class="c1"># then external input (assume from one source)</span>
</span><span id="ReadoutNetwork.determine_input_dims-722"><a href="#ReadoutNetwork.determine_input_dims-722"><span class="linenos">722</span></a>            <span class="n">valid_input_dims</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="ReadoutNetwork.determine_input_dims-723"><a href="#ReadoutNetwork.determine_input_dims-723"><span class="linenos">723</span></a>            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Readout layer cannot get an external input.&#39;</span><span class="p">)</span> 
</span><span id="ReadoutNetwork.determine_input_dims-724"><a href="#ReadoutNetwork.determine_input_dims-724"><span class="linenos">724</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">input_dims</span> <span class="o">=</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ReadoutNetwork.determine_input_dims-725"><a href="#ReadoutNetwork.determine_input_dims-725"><span class="linenos">725</span></a>        <span class="k">else</span><span class="p">:</span>             
</span><span id="ReadoutNetwork.determine_input_dims-726"><a href="#ReadoutNetwork.determine_input_dims-726"><span class="linenos">726</span></a>            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_dims_list</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ffnets_in</span><span class="p">),</span> <span class="s1">&#39;Internal: misspecification of input_dims for FFnetwork.&#39;</span>
</span><span id="ReadoutNetwork.determine_input_dims-727"><a href="#ReadoutNetwork.determine_input_dims-727"><span class="linenos">727</span></a>            <span class="c1"># First dimension is the input network</span>
</span><span id="ReadoutNetwork.determine_input_dims-728"><a href="#ReadoutNetwork.determine_input_dims-728"><span class="linenos">728</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">input_dims</span> <span class="o">=</span> <span class="n">input_dims_list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="ReadoutNetwork.determine_input_dims-729"><a href="#ReadoutNetwork.determine_input_dims-729"><span class="linenos">729</span></a>            <span class="c1"># Second dimension would be </span>
</span><span id="ReadoutNetwork.determine_input_dims-730"><a href="#ReadoutNetwork.determine_input_dims-730"><span class="linenos">730</span></a>            <span class="bp">self</span><span class="o">.</span><span class="n">shifter</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ffnets_in</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span>
</span><span id="ReadoutNetwork.determine_input_dims-731"><a href="#ReadoutNetwork.determine_input_dims-731"><span class="linenos">731</span></a>
</span><span id="ReadoutNetwork.determine_input_dims-732"><a href="#ReadoutNetwork.determine_input_dims-732"><span class="linenos">732</span></a>        <span class="k">return</span> <span class="n">valid_input_dims</span>
</span></pre></div>


            <div class="docstring"><p>Sets input_dims given network inputs. Can be overloaded depending on the network type. For this base class, there
are two types of network input: external stimulus (xstim_n) or a list of internal (ffnet_in) networks:
    For external inputs, it just uses the passed-in input_dims
    For internal network inputs, it will concatenate inputs along the filter dimension, but MUST match other dims
As currently designed, this can either external or internal, but not both</p>

<h6 id="this-sets-the-following-internal-ffnetwork-properties">This sets the following internal FFnetwork properties:</h6>

<blockquote>
  <p>self.input_dims
  self.input_dims_list</p>
</blockquote>

<p>and returns Boolean whether the passed in input dims are valid</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>input_dims_list (list):</strong>  A list of input dimensions for each layer.</li>
<li><strong>**kwargs:</strong>  Additional keyword arguments.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>valid_input_dims (bool): Whether the passed in input dims are valid.</p>
</blockquote>
</div>


                            </div>
                            <div id="ReadoutNetwork.forward" class="classattr">
                                        <input id="ReadoutNetwork.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">inputs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="ReadoutNetwork.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ReadoutNetwork.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ReadoutNetwork.forward-735"><a href="#ReadoutNetwork.forward-735"><span class="linenos">735</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="ReadoutNetwork.forward-736"><a href="#ReadoutNetwork.forward-736"><span class="linenos">736</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ReadoutNetwork.forward-737"><a href="#ReadoutNetwork.forward-737"><span class="linenos">737</span></a><span class="sd">        Network inputs correspond to output of conv layer, and (if it exists), a shifter.</span>
</span><span id="ReadoutNetwork.forward-738"><a href="#ReadoutNetwork.forward-738"><span class="linenos">738</span></a><span class="sd">        </span>
</span><span id="ReadoutNetwork.forward-739"><a href="#ReadoutNetwork.forward-739"><span class="linenos">739</span></a><span class="sd">        Args:</span>
</span><span id="ReadoutNetwork.forward-740"><a href="#ReadoutNetwork.forward-740"><span class="linenos">740</span></a><span class="sd">            inputs (list, torch.Tensor): The input to the network.</span>
</span><span id="ReadoutNetwork.forward-741"><a href="#ReadoutNetwork.forward-741"><span class="linenos">741</span></a>
</span><span id="ReadoutNetwork.forward-742"><a href="#ReadoutNetwork.forward-742"><span class="linenos">742</span></a><span class="sd">        Returns:</span>
</span><span id="ReadoutNetwork.forward-743"><a href="#ReadoutNetwork.forward-743"><span class="linenos">743</span></a><span class="sd">            y (torch.Tensor): The output of the network.</span>
</span><span id="ReadoutNetwork.forward-744"><a href="#ReadoutNetwork.forward-744"><span class="linenos">744</span></a><span class="sd">        &quot;&quot;&quot;</span> 
</span><span id="ReadoutNetwork.forward-745"><a href="#ReadoutNetwork.forward-745"><span class="linenos">745</span></a>
</span><span id="ReadoutNetwork.forward-746"><a href="#ReadoutNetwork.forward-746"><span class="linenos">746</span></a>        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
</span><span id="ReadoutNetwork.forward-747"><a href="#ReadoutNetwork.forward-747"><span class="linenos">747</span></a>            <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">inputs</span><span class="p">]</span>
</span><span id="ReadoutNetwork.forward-748"><a href="#ReadoutNetwork.forward-748"><span class="linenos">748</span></a>
</span><span id="ReadoutNetwork.forward-749"><a href="#ReadoutNetwork.forward-749"><span class="linenos">749</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">shifter</span><span class="p">:</span>
</span><span id="ReadoutNetwork.forward-750"><a href="#ReadoutNetwork.forward-750"><span class="linenos">750</span></a>            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">shift</span><span class="o">=</span><span class="n">inputs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span><span id="ReadoutNetwork.forward-751"><a href="#ReadoutNetwork.forward-751"><span class="linenos">751</span></a>        <span class="k">else</span><span class="p">:</span>
</span><span id="ReadoutNetwork.forward-752"><a href="#ReadoutNetwork.forward-752"><span class="linenos">752</span></a>            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span><span id="ReadoutNetwork.forward-753"><a href="#ReadoutNetwork.forward-753"><span class="linenos">753</span></a>        <span class="k">return</span> <span class="n">y</span>
</span></pre></div>


            <div class="docstring"><p>Network inputs correspond to output of conv layer, and (if it exists), a shifter.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>inputs (list, torch.Tensor):</strong>  The input to the network.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>y (torch.Tensor): The output of the network.</p>
</blockquote>
</div>


                            </div>
                            <div id="ReadoutNetwork.get_readout_locations" class="classattr">
                                        <input id="ReadoutNetwork.get_readout_locations-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">get_readout_locations</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="ReadoutNetwork.get_readout_locations-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ReadoutNetwork.get_readout_locations"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ReadoutNetwork.get_readout_locations-756"><a href="#ReadoutNetwork.get_readout_locations-756"><span class="linenos">756</span></a>    <span class="k">def</span> <span class="nf">get_readout_locations</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="ReadoutNetwork.get_readout_locations-757"><a href="#ReadoutNetwork.get_readout_locations-757"><span class="linenos">757</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ReadoutNetwork.get_readout_locations-758"><a href="#ReadoutNetwork.get_readout_locations-758"><span class="linenos">758</span></a><span class="sd">        Returns the readout locations.</span>
</span><span id="ReadoutNetwork.get_readout_locations-759"><a href="#ReadoutNetwork.get_readout_locations-759"><span class="linenos">759</span></a>
</span><span id="ReadoutNetwork.get_readout_locations-760"><a href="#ReadoutNetwork.get_readout_locations-760"><span class="linenos">760</span></a><span class="sd">        Args:</span>
</span><span id="ReadoutNetwork.get_readout_locations-761"><a href="#ReadoutNetwork.get_readout_locations-761"><span class="linenos">761</span></a><span class="sd">            None</span>
</span><span id="ReadoutNetwork.get_readout_locations-762"><a href="#ReadoutNetwork.get_readout_locations-762"><span class="linenos">762</span></a>
</span><span id="ReadoutNetwork.get_readout_locations-763"><a href="#ReadoutNetwork.get_readout_locations-763"><span class="linenos">763</span></a><span class="sd">        Returns:</span>
</span><span id="ReadoutNetwork.get_readout_locations-764"><a href="#ReadoutNetwork.get_readout_locations-764"><span class="linenos">764</span></a><span class="sd">            The readout locations.</span>
</span><span id="ReadoutNetwork.get_readout_locations-765"><a href="#ReadoutNetwork.get_readout_locations-765"><span class="linenos">765</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ReadoutNetwork.get_readout_locations-766"><a href="#ReadoutNetwork.get_readout_locations-766"><span class="linenos">766</span></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_readout_locations</span><span class="p">()</span>
</span></pre></div>


            <div class="docstring"><p>Returns the readout locations.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li>None</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>The readout locations.</p>
</blockquote>
</div>


                            </div>
                            <div id="ReadoutNetwork.set_readout_locations" class="classattr">
                                        <input id="ReadoutNetwork.set_readout_locations-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">set_readout_locations</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">locs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="ReadoutNetwork.set_readout_locations-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ReadoutNetwork.set_readout_locations"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ReadoutNetwork.set_readout_locations-768"><a href="#ReadoutNetwork.set_readout_locations-768"><span class="linenos">768</span></a>    <span class="k">def</span> <span class="nf">set_readout_locations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">locs</span><span class="p">):</span>
</span><span id="ReadoutNetwork.set_readout_locations-769"><a href="#ReadoutNetwork.set_readout_locations-769"><span class="linenos">769</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ReadoutNetwork.set_readout_locations-770"><a href="#ReadoutNetwork.set_readout_locations-770"><span class="linenos">770</span></a><span class="sd">        Sets the readout locations.</span>
</span><span id="ReadoutNetwork.set_readout_locations-771"><a href="#ReadoutNetwork.set_readout_locations-771"><span class="linenos">771</span></a>
</span><span id="ReadoutNetwork.set_readout_locations-772"><a href="#ReadoutNetwork.set_readout_locations-772"><span class="linenos">772</span></a><span class="sd">        Args:</span>
</span><span id="ReadoutNetwork.set_readout_locations-773"><a href="#ReadoutNetwork.set_readout_locations-773"><span class="linenos">773</span></a><span class="sd">            locs: The readout locations.</span>
</span><span id="ReadoutNetwork.set_readout_locations-774"><a href="#ReadoutNetwork.set_readout_locations-774"><span class="linenos">774</span></a>
</span><span id="ReadoutNetwork.set_readout_locations-775"><a href="#ReadoutNetwork.set_readout_locations-775"><span class="linenos">775</span></a><span class="sd">        Returns:</span>
</span><span id="ReadoutNetwork.set_readout_locations-776"><a href="#ReadoutNetwork.set_readout_locations-776"><span class="linenos">776</span></a><span class="sd">            None</span>
</span><span id="ReadoutNetwork.set_readout_locations-777"><a href="#ReadoutNetwork.set_readout_locations-777"><span class="linenos">777</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ReadoutNetwork.set_readout_locations-778"><a href="#ReadoutNetwork.set_readout_locations-778"><span class="linenos">778</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_readout_locations</span><span class="p">(</span><span class="n">locs</span><span class="p">)</span>
</span></pre></div>


            <div class="docstring"><p>Sets the readout locations.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>locs:</strong>  The readout locations.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>None</p>
</blockquote>
</div>


                            </div>
                            <div id="ReadoutNetwork.ffnet_dict" class="classattr">
                                        <input id="ReadoutNetwork.ffnet_dict-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator">@classmethod</div>

        <span class="def">def</span>
        <span class="name">ffnet_dict</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">cls</span>, </span><span class="param"><span class="n">ffnet_n</span><span class="o">=</span><span class="mi">0</span>, </span><span class="param"><span class="o">**</span><span class="n">kwargs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="ReadoutNetwork.ffnet_dict-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#ReadoutNetwork.ffnet_dict"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="ReadoutNetwork.ffnet_dict-780"><a href="#ReadoutNetwork.ffnet_dict-780"><span class="linenos">780</span></a>    <span class="nd">@classmethod</span>
</span><span id="ReadoutNetwork.ffnet_dict-781"><a href="#ReadoutNetwork.ffnet_dict-781"><span class="linenos">781</span></a>    <span class="k">def</span> <span class="nf">ffnet_dict</span><span class="p">(</span> <span class="bp">cls</span><span class="p">,</span> <span class="n">ffnet_n</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="ReadoutNetwork.ffnet_dict-782"><a href="#ReadoutNetwork.ffnet_dict-782"><span class="linenos">782</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="ReadoutNetwork.ffnet_dict-783"><a href="#ReadoutNetwork.ffnet_dict-783"><span class="linenos">783</span></a><span class="sd">        Returns a dictionary of the readout network.</span>
</span><span id="ReadoutNetwork.ffnet_dict-784"><a href="#ReadoutNetwork.ffnet_dict-784"><span class="linenos">784</span></a>
</span><span id="ReadoutNetwork.ffnet_dict-785"><a href="#ReadoutNetwork.ffnet_dict-785"><span class="linenos">785</span></a><span class="sd">        Args:</span>
</span><span id="ReadoutNetwork.ffnet_dict-786"><a href="#ReadoutNetwork.ffnet_dict-786"><span class="linenos">786</span></a><span class="sd">            ffnet_n (int): The feedforward network.</span>
</span><span id="ReadoutNetwork.ffnet_dict-787"><a href="#ReadoutNetwork.ffnet_dict-787"><span class="linenos">787</span></a>
</span><span id="ReadoutNetwork.ffnet_dict-788"><a href="#ReadoutNetwork.ffnet_dict-788"><span class="linenos">788</span></a><span class="sd">        Returns:</span>
</span><span id="ReadoutNetwork.ffnet_dict-789"><a href="#ReadoutNetwork.ffnet_dict-789"><span class="linenos">789</span></a><span class="sd">            ffnet_dict (dict): The dictionary of the readout network.</span>
</span><span id="ReadoutNetwork.ffnet_dict-790"><a href="#ReadoutNetwork.ffnet_dict-790"><span class="linenos">790</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="ReadoutNetwork.ffnet_dict-791"><a href="#ReadoutNetwork.ffnet_dict-791"><span class="linenos">791</span></a>        <span class="n">ffnet_dict</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">ffnet_dict</span><span class="p">(</span><span class="n">xstim_n</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ffnet_n</span><span class="o">=</span><span class="n">ffnet_n</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="ReadoutNetwork.ffnet_dict-792"><a href="#ReadoutNetwork.ffnet_dict-792"><span class="linenos">792</span></a>        <span class="n">ffnet_dict</span><span class="p">[</span><span class="s1">&#39;ffnet_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;readout&#39;</span>
</span><span id="ReadoutNetwork.ffnet_dict-793"><a href="#ReadoutNetwork.ffnet_dict-793"><span class="linenos">793</span></a>        <span class="k">return</span> <span class="n">ffnet_dict</span>
</span></pre></div>


            <div class="docstring"><p>Returns a dictionary of the readout network.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>ffnet_n (int):</strong>  The feedforward network.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>ffnet_dict (dict): The dictionary of the readout network.</p>
</blockquote>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt><a href="#FFnetwork">FFnetwork</a></dt>
                                <dd id="ReadoutNetwork.layer_list" class="variable"><a href="#FFnetwork.layer_list">layer_list</a></dd>
                <dd id="ReadoutNetwork.layer_types" class="variable"><a href="#FFnetwork.layer_types">layer_types</a></dd>
                <dd id="ReadoutNetwork.xstim_n" class="variable"><a href="#FFnetwork.xstim_n">xstim_n</a></dd>
                <dd id="ReadoutNetwork.ffnets_in" class="variable"><a href="#FFnetwork.ffnets_in">ffnets_in</a></dd>
                <dd id="ReadoutNetwork.layers" class="variable"><a href="#FFnetwork.layers">layers</a></dd>
                <dd id="ReadoutNetwork.output_dims" class="variable"><a href="#FFnetwork.output_dims">output_dims</a></dd>
                <dd id="ReadoutNetwork.num_outputs" class="variable"><a href="#FFnetwork.num_outputs">num_outputs</a></dd>
                <dd id="ReadoutNetwork.preprocess_input" class="function"><a href="#FFnetwork.preprocess_input">preprocess_input</a></dd>
                <dd id="ReadoutNetwork.prepare_regularization" class="function"><a href="#FFnetwork.prepare_regularization">prepare_regularization</a></dd>
                <dd id="ReadoutNetwork.compute_reg_loss" class="function"><a href="#FFnetwork.compute_reg_loss">compute_reg_loss</a></dd>
                <dd id="ReadoutNetwork.list_parameters" class="function"><a href="#FFnetwork.list_parameters">list_parameters</a></dd>
                <dd id="ReadoutNetwork.set_parameters" class="function"><a href="#FFnetwork.set_parameters">set_parameters</a></dd>
                <dd id="ReadoutNetwork.set_reg_val" class="function"><a href="#FFnetwork.set_reg_val">set_reg_val</a></dd>
                <dd id="ReadoutNetwork.plot_filters" class="function"><a href="#FFnetwork.plot_filters">plot_filters</a></dd>
                <dd id="ReadoutNetwork.get_weights" class="function"><a href="#FFnetwork.get_weights">get_weights</a></dd>

            </div>
            <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="ReadoutNetwork.dump_patches" class="variable">dump_patches</dd>
                <dd id="ReadoutNetwork.training" class="variable">training</dd>
                <dd id="ReadoutNetwork.call_super_init" class="variable">call_super_init</dd>
                <dd id="ReadoutNetwork.register_buffer" class="function">register_buffer</dd>
                <dd id="ReadoutNetwork.register_parameter" class="function">register_parameter</dd>
                <dd id="ReadoutNetwork.add_module" class="function">add_module</dd>
                <dd id="ReadoutNetwork.register_module" class="function">register_module</dd>
                <dd id="ReadoutNetwork.get_submodule" class="function">get_submodule</dd>
                <dd id="ReadoutNetwork.get_parameter" class="function">get_parameter</dd>
                <dd id="ReadoutNetwork.get_buffer" class="function">get_buffer</dd>
                <dd id="ReadoutNetwork.get_extra_state" class="function">get_extra_state</dd>
                <dd id="ReadoutNetwork.set_extra_state" class="function">set_extra_state</dd>
                <dd id="ReadoutNetwork.apply" class="function">apply</dd>
                <dd id="ReadoutNetwork.cuda" class="function">cuda</dd>
                <dd id="ReadoutNetwork.ipu" class="function">ipu</dd>
                <dd id="ReadoutNetwork.xpu" class="function">xpu</dd>
                <dd id="ReadoutNetwork.cpu" class="function">cpu</dd>
                <dd id="ReadoutNetwork.type" class="function">type</dd>
                <dd id="ReadoutNetwork.float" class="function">float</dd>
                <dd id="ReadoutNetwork.double" class="function">double</dd>
                <dd id="ReadoutNetwork.half" class="function">half</dd>
                <dd id="ReadoutNetwork.bfloat16" class="function">bfloat16</dd>
                <dd id="ReadoutNetwork.to_empty" class="function">to_empty</dd>
                <dd id="ReadoutNetwork.to" class="function">to</dd>
                <dd id="ReadoutNetwork.register_full_backward_pre_hook" class="function">register_full_backward_pre_hook</dd>
                <dd id="ReadoutNetwork.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="ReadoutNetwork.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="ReadoutNetwork.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="ReadoutNetwork.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="ReadoutNetwork.register_state_dict_pre_hook" class="function">register_state_dict_pre_hook</dd>
                <dd id="ReadoutNetwork.state_dict" class="function">state_dict</dd>
                <dd id="ReadoutNetwork.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="ReadoutNetwork.load_state_dict" class="function">load_state_dict</dd>
                <dd id="ReadoutNetwork.parameters" class="function">parameters</dd>
                <dd id="ReadoutNetwork.named_parameters" class="function">named_parameters</dd>
                <dd id="ReadoutNetwork.buffers" class="function">buffers</dd>
                <dd id="ReadoutNetwork.named_buffers" class="function">named_buffers</dd>
                <dd id="ReadoutNetwork.children" class="function">children</dd>
                <dd id="ReadoutNetwork.named_children" class="function">named_children</dd>
                <dd id="ReadoutNetwork.modules" class="function">modules</dd>
                <dd id="ReadoutNetwork.named_modules" class="function">named_modules</dd>
                <dd id="ReadoutNetwork.train" class="function">train</dd>
                <dd id="ReadoutNetwork.eval" class="function">eval</dd>
                <dd id="ReadoutNetwork.requires_grad_" class="function">requires_grad_</dd>
                <dd id="ReadoutNetwork.zero_grad" class="function">zero_grad</dd>
                <dd id="ReadoutNetwork.share_memory" class="function">share_memory</dd>
                <dd id="ReadoutNetwork.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
                <section id="FFnet_external">
                            <input id="FFnet_external-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">FFnet_external</span><wbr>(<span class="base"><a href="#FFnetwork">FFnetwork</a></span>):

                <label class="view-source-button" for="FFnet_external-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FFnet_external"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FFnet_external-797"><a href="#FFnet_external-797"><span class="linenos">797</span></a><span class="k">class</span> <span class="nc">FFnet_external</span><span class="p">(</span><span class="n">FFnetwork</span><span class="p">):</span>
</span><span id="FFnet_external-798"><a href="#FFnet_external-798"><span class="linenos">798</span></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnet_external-799"><a href="#FFnet_external-799"><span class="linenos">799</span></a><span class="sd">    This is a &#39;shell&#39; that lets an external network be plugged into the NDN. It establishes all the basics</span>
</span><span id="FFnet_external-800"><a href="#FFnet_external-800"><span class="linenos">800</span></a><span class="sd">    so that information requested to this network from other parts of the NDN will behave correctly.</span>
</span><span id="FFnet_external-801"><a href="#FFnet_external-801"><span class="linenos">801</span></a>
</span><span id="FFnet_external-802"><a href="#FFnet_external-802"><span class="linenos">802</span></a><span class="sd">    Args:</span>
</span><span id="FFnet_external-803"><a href="#FFnet_external-803"><span class="linenos">803</span></a><span class="sd">        external_module_dict (dict): A dictionary of external modules.</span>
</span><span id="FFnet_external-804"><a href="#FFnet_external-804"><span class="linenos">804</span></a><span class="sd">        external_module_name (str): The name of the external module.</span>
</span><span id="FFnet_external-805"><a href="#FFnet_external-805"><span class="linenos">805</span></a><span class="sd">        input_dims_reshape (list): A list of input dimensions to reshape.</span>
</span><span id="FFnet_external-806"><a href="#FFnet_external-806"><span class="linenos">806</span></a><span class="sd">        **kwargs: Additional keyword arguments.</span>
</span><span id="FFnet_external-807"><a href="#FFnet_external-807"><span class="linenos">807</span></a>
</span><span id="FFnet_external-808"><a href="#FFnet_external-808"><span class="linenos">808</span></a><span class="sd">    Raises:</span>
</span><span id="FFnet_external-809"><a href="#FFnet_external-809"><span class="linenos">809</span></a><span class="sd">        AssertionError: If the external module dictionary is invalid.</span>
</span><span id="FFnet_external-810"><a href="#FFnet_external-810"><span class="linenos">810</span></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="FFnet_external-811"><a href="#FFnet_external-811"><span class="linenos">811</span></a>    <span class="c1">#def __repr__(self):</span>
</span><span id="FFnet_external-812"><a href="#FFnet_external-812"><span class="linenos">812</span></a>    <span class="c1">#    s = super().__repr__()</span>
</span><span id="FFnet_external-813"><a href="#FFnet_external-813"><span class="linenos">813</span></a>    <span class="c1">#    # Add information about module to print out</span>
</span><span id="FFnet_external-814"><a href="#FFnet_external-814"><span class="linenos">814</span></a>
</span><span id="FFnet_external-815"><a href="#FFnet_external-815"><span class="linenos">815</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">external_module_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">external_module_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_dims_reshape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="FFnet_external-816"><a href="#FFnet_external-816"><span class="linenos">816</span></a>        <span class="c1"># The parent construct will make a &#39;dummy layer&#39; that will be filled in with module 0 below</span>
</span><span id="FFnet_external-817"><a href="#FFnet_external-817"><span class="linenos">817</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">FFnet_external</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="FFnet_external-818"><a href="#FFnet_external-818"><span class="linenos">818</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">network_type</span> <span class="o">=</span> <span class="s1">&#39;external&#39;</span>
</span><span id="FFnet_external-819"><a href="#FFnet_external-819"><span class="linenos">819</span></a>
</span><span id="FFnet_external-820"><a href="#FFnet_external-820"><span class="linenos">820</span></a>        <span class="c1"># Extract relevant network fom extenal_module_dict using the ffnet_params[&#39;layer_types&#39;]</span>
</span><span id="FFnet_external-821"><a href="#FFnet_external-821"><span class="linenos">821</span></a>        <span class="k">assert</span> <span class="n">external_module_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;external_module_dict cannot be None.&#39;</span>
</span><span id="FFnet_external-822"><a href="#FFnet_external-822"><span class="linenos">822</span></a>        
</span><span id="FFnet_external-823"><a href="#FFnet_external-823"><span class="linenos">823</span></a>        <span class="n">net_name</span> <span class="o">=</span> <span class="n">external_module_name</span>
</span><span id="FFnet_external-824"><a href="#FFnet_external-824"><span class="linenos">824</span></a>        <span class="k">assert</span> <span class="n">net_name</span> <span class="ow">in</span> <span class="n">external_module_dict</span><span class="p">,</span> <span class="s1">&#39;External network </span><span class="si">%s</span><span class="s1"> not found in external_modules dict.&#39;</span><span class="o">%</span><span class="n">net_name</span>
</span><span id="FFnet_external-825"><a href="#FFnet_external-825"><span class="linenos">825</span></a>
</span><span id="FFnet_external-826"><a href="#FFnet_external-826"><span class="linenos">826</span></a>        <span class="c1"># This network will be made to be a layer (so the ffnet forward is the layer forward). Now place external network here</span>
</span><span id="FFnet_external-827"><a href="#FFnet_external-827"><span class="linenos">827</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">external_network</span> <span class="o">=</span> <span class="n">external_module_dict</span><span class="p">[</span><span class="n">net_name</span><span class="p">]</span>
</span><span id="FFnet_external-828"><a href="#FFnet_external-828"><span class="linenos">828</span></a>        <span class="k">assert</span> <span class="n">input_dims_reshape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;input_dims_reshape cannot be None. Jake did not know what it is supposed to default to so he used None.&#39;</span>
</span><span id="FFnet_external-829"><a href="#FFnet_external-829"><span class="linenos">829</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">input_dims_reshape</span> <span class="o">=</span> <span class="n">input_dims_reshape</span>
</span><span id="FFnet_external-830"><a href="#FFnet_external-830"><span class="linenos">830</span></a>    <span class="c1"># END FFnet_external.__init__</span>
</span><span id="FFnet_external-831"><a href="#FFnet_external-831"><span class="linenos">831</span></a>
</span><span id="FFnet_external-832"><a href="#FFnet_external-832"><span class="linenos">832</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="FFnet_external-833"><a href="#FFnet_external-833"><span class="linenos">833</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnet_external-834"><a href="#FFnet_external-834"><span class="linenos">834</span></a><span class="sd">        Forward pass through the network.</span>
</span><span id="FFnet_external-835"><a href="#FFnet_external-835"><span class="linenos">835</span></a>
</span><span id="FFnet_external-836"><a href="#FFnet_external-836"><span class="linenos">836</span></a><span class="sd">        Args:</span>
</span><span id="FFnet_external-837"><a href="#FFnet_external-837"><span class="linenos">837</span></a><span class="sd">            inputs (list, torch.Tensor): The input to the network.</span>
</span><span id="FFnet_external-838"><a href="#FFnet_external-838"><span class="linenos">838</span></a>
</span><span id="FFnet_external-839"><a href="#FFnet_external-839"><span class="linenos">839</span></a><span class="sd">        Returns:</span>
</span><span id="FFnet_external-840"><a href="#FFnet_external-840"><span class="linenos">840</span></a><span class="sd">            y (torch.Tensor): The output of the network.</span>
</span><span id="FFnet_external-841"><a href="#FFnet_external-841"><span class="linenos">841</span></a>
</span><span id="FFnet_external-842"><a href="#FFnet_external-842"><span class="linenos">842</span></a><span class="sd">        Raises:</span>
</span><span id="FFnet_external-843"><a href="#FFnet_external-843"><span class="linenos">843</span></a><span class="sd">            ValueError: If no layers are defined.</span>
</span><span id="FFnet_external-844"><a href="#FFnet_external-844"><span class="linenos">844</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FFnet_external-845"><a href="#FFnet_external-845"><span class="linenos">845</span></a>        
</span><span id="FFnet_external-846"><a href="#FFnet_external-846"><span class="linenos">846</span></a>        <span class="c1"># Leave all heavy lifting to the external module, which is in layers[0]. But concatenate network inputs, as needed</span>
</span><span id="FFnet_external-847"><a href="#FFnet_external-847"><span class="linenos">847</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="FFnet_external-848"><a href="#FFnet_external-848"><span class="linenos">848</span></a>        <span class="k">for</span> <span class="n">mm</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)):</span>
</span><span id="FFnet_external-849"><a href="#FFnet_external-849"><span class="linenos">849</span></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">inputs</span><span class="p">[</span><span class="n">mm</span><span class="p">]),</span> <span class="mi">1</span> <span class="p">)</span>
</span><span id="FFnet_external-850"><a href="#FFnet_external-850"><span class="linenos">850</span></a>        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="FFnet_external-851"><a href="#FFnet_external-851"><span class="linenos">851</span></a>
</span><span id="FFnet_external-852"><a href="#FFnet_external-852"><span class="linenos">852</span></a>        <span class="c1"># Reshape dimensions for layer as needed</span>
</span><span id="FFnet_external-853"><a href="#FFnet_external-853"><span class="linenos">853</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_dims_reshape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FFnet_external-854"><a href="#FFnet_external-854"><span class="linenos">854</span></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span> <span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_dims_reshape</span><span class="p">)</span>
</span><span id="FFnet_external-855"><a href="#FFnet_external-855"><span class="linenos">855</span></a>        
</span><span id="FFnet_external-856"><a href="#FFnet_external-856"><span class="linenos">856</span></a>        <span class="c1"># Pass into external network</span>
</span><span id="FFnet_external-857"><a href="#FFnet_external-857"><span class="linenos">857</span></a>        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">x</span><span class="p">)</span>
</span><span id="FFnet_external-858"><a href="#FFnet_external-858"><span class="linenos">858</span></a>
</span><span id="FFnet_external-859"><a href="#FFnet_external-859"><span class="linenos">859</span></a>        <span class="c1"># Ensure that output is flattened</span>
</span><span id="FFnet_external-860"><a href="#FFnet_external-860"><span class="linenos">860</span></a>        <span class="k">return</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span><span id="FFnet_external-861"><a href="#FFnet_external-861"><span class="linenos">861</span></a>    
</span><span id="FFnet_external-862"><a href="#FFnet_external-862"><span class="linenos">862</span></a>    <span class="k">def</span> <span class="nf">compute_reg_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="FFnet_external-863"><a href="#FFnet_external-863"><span class="linenos">863</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnet_external-864"><a href="#FFnet_external-864"><span class="linenos">864</span></a><span class="sd">        Computes the regularization loss.</span>
</span><span id="FFnet_external-865"><a href="#FFnet_external-865"><span class="linenos">865</span></a>
</span><span id="FFnet_external-866"><a href="#FFnet_external-866"><span class="linenos">866</span></a><span class="sd">        Args:</span>
</span><span id="FFnet_external-867"><a href="#FFnet_external-867"><span class="linenos">867</span></a><span class="sd">            None</span>
</span><span id="FFnet_external-868"><a href="#FFnet_external-868"><span class="linenos">868</span></a>
</span><span id="FFnet_external-869"><a href="#FFnet_external-869"><span class="linenos">869</span></a><span class="sd">        Returns:</span>
</span><span id="FFnet_external-870"><a href="#FFnet_external-870"><span class="linenos">870</span></a><span class="sd">            0</span>
</span><span id="FFnet_external-871"><a href="#FFnet_external-871"><span class="linenos">871</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FFnet_external-872"><a href="#FFnet_external-872"><span class="linenos">872</span></a>        <span class="c1"># Since we do not implement regularization within the external network, this returns nothing</span>
</span><span id="FFnet_external-873"><a href="#FFnet_external-873"><span class="linenos">873</span></a>        <span class="k">return</span> <span class="mi">0</span>
</span><span id="FFnet_external-874"><a href="#FFnet_external-874"><span class="linenos">874</span></a>
</span><span id="FFnet_external-875"><a href="#FFnet_external-875"><span class="linenos">875</span></a>    <span class="k">def</span> <span class="nf">list_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer_target</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="FFnet_external-876"><a href="#FFnet_external-876"><span class="linenos">876</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnet_external-877"><a href="#FFnet_external-877"><span class="linenos">877</span></a><span class="sd">        Lists the parameters for the network.</span>
</span><span id="FFnet_external-878"><a href="#FFnet_external-878"><span class="linenos">878</span></a>
</span><span id="FFnet_external-879"><a href="#FFnet_external-879"><span class="linenos">879</span></a><span class="sd">        Args:</span>
</span><span id="FFnet_external-880"><a href="#FFnet_external-880"><span class="linenos">880</span></a><span class="sd">            layer_target (int, optional): The layer to list the parameters for. Defaults to None.</span>
</span><span id="FFnet_external-881"><a href="#FFnet_external-881"><span class="linenos">881</span></a>
</span><span id="FFnet_external-882"><a href="#FFnet_external-882"><span class="linenos">882</span></a><span class="sd">        Returns:</span>
</span><span id="FFnet_external-883"><a href="#FFnet_external-883"><span class="linenos">883</span></a><span class="sd">            None</span>
</span><span id="FFnet_external-884"><a href="#FFnet_external-884"><span class="linenos">884</span></a>
</span><span id="FFnet_external-885"><a href="#FFnet_external-885"><span class="linenos">885</span></a><span class="sd">        Raises:</span>
</span><span id="FFnet_external-886"><a href="#FFnet_external-886"><span class="linenos">886</span></a><span class="sd">            AssertionError: If the layer target is invalid.</span>
</span><span id="FFnet_external-887"><a href="#FFnet_external-887"><span class="linenos">887</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FFnet_external-888"><a href="#FFnet_external-888"><span class="linenos">888</span></a>        <span class="k">assert</span> <span class="n">layer_target</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;No ability to directly distinguish layers in the external network.&#39;</span>
</span><span id="FFnet_external-889"><a href="#FFnet_external-889"><span class="linenos">889</span></a>        <span class="k">for</span> <span class="n">nm</span><span class="p">,</span> <span class="n">pp</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">(</span><span class="n">recurse</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
</span><span id="FFnet_external-890"><a href="#FFnet_external-890"><span class="linenos">890</span></a>            <span class="k">if</span> <span class="n">pp</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
</span><span id="FFnet_external-891"><a href="#FFnet_external-891"><span class="linenos">891</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;    </span><span class="si">%s</span><span class="s2">:&quot;</span><span class="o">%</span><span class="n">nm</span><span class="p">,</span> <span class="n">pp</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</span><span id="FFnet_external-892"><a href="#FFnet_external-892"><span class="linenos">892</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="FFnet_external-893"><a href="#FFnet_external-893"><span class="linenos">893</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;    NOT FIT: </span><span class="si">%s</span><span class="s2">:&quot;</span><span class="o">%</span><span class="n">nm</span><span class="p">,</span> <span class="n">pp</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</span><span id="FFnet_external-894"><a href="#FFnet_external-894"><span class="linenos">894</span></a>
</span><span id="FFnet_external-895"><a href="#FFnet_external-895"><span class="linenos">895</span></a>    <span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer_target</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">val</span><span class="o">=</span><span class="kc">None</span> <span class="p">):</span>
</span><span id="FFnet_external-896"><a href="#FFnet_external-896"><span class="linenos">896</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnet_external-897"><a href="#FFnet_external-897"><span class="linenos">897</span></a><span class="sd">        Sets the parameters for the listed layer or for all layers.</span>
</span><span id="FFnet_external-898"><a href="#FFnet_external-898"><span class="linenos">898</span></a>
</span><span id="FFnet_external-899"><a href="#FFnet_external-899"><span class="linenos">899</span></a><span class="sd">        Args:</span>
</span><span id="FFnet_external-900"><a href="#FFnet_external-900"><span class="linenos">900</span></a><span class="sd">            layer_target (int, optional): The layer to set the parameters for. Defaults to None.</span>
</span><span id="FFnet_external-901"><a href="#FFnet_external-901"><span class="linenos">901</span></a><span class="sd">            name (str): The name of the parameter.</span>
</span><span id="FFnet_external-902"><a href="#FFnet_external-902"><span class="linenos">902</span></a><span class="sd">            val (bool): The value to set the parameter to.</span>
</span><span id="FFnet_external-903"><a href="#FFnet_external-903"><span class="linenos">903</span></a>
</span><span id="FFnet_external-904"><a href="#FFnet_external-904"><span class="linenos">904</span></a><span class="sd">        Returns:</span>
</span><span id="FFnet_external-905"><a href="#FFnet_external-905"><span class="linenos">905</span></a><span class="sd">            None</span>
</span><span id="FFnet_external-906"><a href="#FFnet_external-906"><span class="linenos">906</span></a>
</span><span id="FFnet_external-907"><a href="#FFnet_external-907"><span class="linenos">907</span></a><span class="sd">        Raises:</span>
</span><span id="FFnet_external-908"><a href="#FFnet_external-908"><span class="linenos">908</span></a><span class="sd">            AssertionError: If the layer target is invalid.</span>
</span><span id="FFnet_external-909"><a href="#FFnet_external-909"><span class="linenos">909</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FFnet_external-910"><a href="#FFnet_external-910"><span class="linenos">910</span></a>        <span class="k">assert</span> <span class="n">layer_target</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;No ability to directly distinguish layers in the external network.&#39;</span>
</span><span id="FFnet_external-911"><a href="#FFnet_external-911"><span class="linenos">911</span></a>        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="nb">bool</span><span class="p">),</span> <span class="s1">&#39;val must be set.&#39;</span>
</span><span id="FFnet_external-912"><a href="#FFnet_external-912"><span class="linenos">912</span></a>        <span class="k">for</span> <span class="n">nm</span><span class="p">,</span> <span class="n">pp</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">(</span><span class="n">recurse</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
</span><span id="FFnet_external-913"><a href="#FFnet_external-913"><span class="linenos">913</span></a>            <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FFnet_external-914"><a href="#FFnet_external-914"><span class="linenos">914</span></a>                <span class="n">pp</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="n">val</span>
</span><span id="FFnet_external-915"><a href="#FFnet_external-915"><span class="linenos">915</span></a>            <span class="k">elif</span> <span class="n">nm</span> <span class="o">==</span> <span class="n">name</span><span class="p">:</span>
</span><span id="FFnet_external-916"><a href="#FFnet_external-916"><span class="linenos">916</span></a>                <span class="n">pp</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="n">val</span>
</span><span id="FFnet_external-917"><a href="#FFnet_external-917"><span class="linenos">917</span></a>
</span><span id="FFnet_external-918"><a href="#FFnet_external-918"><span class="linenos">918</span></a>    <span class="nd">@classmethod</span>
</span><span id="FFnet_external-919"><a href="#FFnet_external-919"><span class="linenos">919</span></a>    <span class="k">def</span> <span class="nf">ffnet_dict</span><span class="p">(</span> <span class="bp">cls</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="FFnet_external-920"><a href="#FFnet_external-920"><span class="linenos">920</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnet_external-921"><a href="#FFnet_external-921"><span class="linenos">921</span></a><span class="sd">        Returns a dictionary of the external network.</span>
</span><span id="FFnet_external-922"><a href="#FFnet_external-922"><span class="linenos">922</span></a>
</span><span id="FFnet_external-923"><a href="#FFnet_external-923"><span class="linenos">923</span></a><span class="sd">        Args:</span>
</span><span id="FFnet_external-924"><a href="#FFnet_external-924"><span class="linenos">924</span></a><span class="sd">            **kwargs: Additional keyword arguments.</span>
</span><span id="FFnet_external-925"><a href="#FFnet_external-925"><span class="linenos">925</span></a>
</span><span id="FFnet_external-926"><a href="#FFnet_external-926"><span class="linenos">926</span></a><span class="sd">        Returns:</span>
</span><span id="FFnet_external-927"><a href="#FFnet_external-927"><span class="linenos">927</span></a><span class="sd">            ffnet_dict (dict): The dictionary of the external network.</span>
</span><span id="FFnet_external-928"><a href="#FFnet_external-928"><span class="linenos">928</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FFnet_external-929"><a href="#FFnet_external-929"><span class="linenos">929</span></a>        <span class="n">ffnet_dict</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">ffnet_dict</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="FFnet_external-930"><a href="#FFnet_external-930"><span class="linenos">930</span></a>        <span class="n">ffnet_dict</span><span class="p">[</span><span class="s1">&#39;ffnet_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;external&#39;</span>
</span><span id="FFnet_external-931"><a href="#FFnet_external-931"><span class="linenos">931</span></a>        <span class="k">return</span> <span class="n">ffnet_dict</span>
</span></pre></div>


            <div class="docstring"><p>This is a 'shell' that lets an external network be plugged into the NDN. It establishes all the basics
so that information requested to this network from other parts of the NDN will behave correctly.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>external_module_dict (dict):</strong>  A dictionary of external modules.</li>
<li><strong>external_module_name (str):</strong>  The name of the external module.</li>
<li><strong>input_dims_reshape (list):</strong>  A list of input dimensions to reshape.</li>
<li><strong>**kwargs:</strong>  Additional keyword arguments.</li>
</ul>

<h6 id="raises">Raises:</h6>

<ul>
<li><strong>AssertionError:</strong>  If the external module dictionary is invalid.</li>
</ul>
</div>


                            <div id="FFnet_external.__init__" class="classattr">
                                        <input id="FFnet_external.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">FFnet_external</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="n">external_module_dict</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">external_module_name</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="n">input_dims_reshape</span><span class="o">=</span><span class="kc">None</span>,</span><span class="param">	<span class="o">**</span><span class="n">kwargs</span></span>)</span>

                <label class="view-source-button" for="FFnet_external.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FFnet_external.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FFnet_external.__init__-815"><a href="#FFnet_external.__init__-815"><span class="linenos">815</span></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">external_module_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">external_module_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_dims_reshape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="FFnet_external.__init__-816"><a href="#FFnet_external.__init__-816"><span class="linenos">816</span></a>        <span class="c1"># The parent construct will make a &#39;dummy layer&#39; that will be filled in with module 0 below</span>
</span><span id="FFnet_external.__init__-817"><a href="#FFnet_external.__init__-817"><span class="linenos">817</span></a>        <span class="nb">super</span><span class="p">(</span><span class="n">FFnet_external</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="FFnet_external.__init__-818"><a href="#FFnet_external.__init__-818"><span class="linenos">818</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">network_type</span> <span class="o">=</span> <span class="s1">&#39;external&#39;</span>
</span><span id="FFnet_external.__init__-819"><a href="#FFnet_external.__init__-819"><span class="linenos">819</span></a>
</span><span id="FFnet_external.__init__-820"><a href="#FFnet_external.__init__-820"><span class="linenos">820</span></a>        <span class="c1"># Extract relevant network fom extenal_module_dict using the ffnet_params[&#39;layer_types&#39;]</span>
</span><span id="FFnet_external.__init__-821"><a href="#FFnet_external.__init__-821"><span class="linenos">821</span></a>        <span class="k">assert</span> <span class="n">external_module_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;external_module_dict cannot be None.&#39;</span>
</span><span id="FFnet_external.__init__-822"><a href="#FFnet_external.__init__-822"><span class="linenos">822</span></a>        
</span><span id="FFnet_external.__init__-823"><a href="#FFnet_external.__init__-823"><span class="linenos">823</span></a>        <span class="n">net_name</span> <span class="o">=</span> <span class="n">external_module_name</span>
</span><span id="FFnet_external.__init__-824"><a href="#FFnet_external.__init__-824"><span class="linenos">824</span></a>        <span class="k">assert</span> <span class="n">net_name</span> <span class="ow">in</span> <span class="n">external_module_dict</span><span class="p">,</span> <span class="s1">&#39;External network </span><span class="si">%s</span><span class="s1"> not found in external_modules dict.&#39;</span><span class="o">%</span><span class="n">net_name</span>
</span><span id="FFnet_external.__init__-825"><a href="#FFnet_external.__init__-825"><span class="linenos">825</span></a>
</span><span id="FFnet_external.__init__-826"><a href="#FFnet_external.__init__-826"><span class="linenos">826</span></a>        <span class="c1"># This network will be made to be a layer (so the ffnet forward is the layer forward). Now place external network here</span>
</span><span id="FFnet_external.__init__-827"><a href="#FFnet_external.__init__-827"><span class="linenos">827</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">external_network</span> <span class="o">=</span> <span class="n">external_module_dict</span><span class="p">[</span><span class="n">net_name</span><span class="p">]</span>
</span><span id="FFnet_external.__init__-828"><a href="#FFnet_external.__init__-828"><span class="linenos">828</span></a>        <span class="k">assert</span> <span class="n">input_dims_reshape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;input_dims_reshape cannot be None. Jake did not know what it is supposed to default to so he used None.&#39;</span>
</span><span id="FFnet_external.__init__-829"><a href="#FFnet_external.__init__-829"><span class="linenos">829</span></a>        <span class="bp">self</span><span class="o">.</span><span class="n">input_dims_reshape</span> <span class="o">=</span> <span class="n">input_dims_reshape</span>
</span></pre></div>


            <div class="docstring"><p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
</div>


                            </div>
                            <div id="FFnet_external.network_type" class="classattr">
                                <div class="attr variable">
            <span class="name">network_type</span>

        
    </div>
    <a class="headerlink" href="#FFnet_external.network_type"></a>
    
    

                            </div>
                            <div id="FFnet_external.input_dims_reshape" class="classattr">
                                <div class="attr variable">
            <span class="name">input_dims_reshape</span>

        
    </div>
    <a class="headerlink" href="#FFnet_external.input_dims_reshape"></a>
    
    

                            </div>
                            <div id="FFnet_external.forward" class="classattr">
                                        <input id="FFnet_external.forward-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">forward</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">inputs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="FFnet_external.forward-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FFnet_external.forward"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FFnet_external.forward-832"><a href="#FFnet_external.forward-832"><span class="linenos">832</span></a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
</span><span id="FFnet_external.forward-833"><a href="#FFnet_external.forward-833"><span class="linenos">833</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnet_external.forward-834"><a href="#FFnet_external.forward-834"><span class="linenos">834</span></a><span class="sd">        Forward pass through the network.</span>
</span><span id="FFnet_external.forward-835"><a href="#FFnet_external.forward-835"><span class="linenos">835</span></a>
</span><span id="FFnet_external.forward-836"><a href="#FFnet_external.forward-836"><span class="linenos">836</span></a><span class="sd">        Args:</span>
</span><span id="FFnet_external.forward-837"><a href="#FFnet_external.forward-837"><span class="linenos">837</span></a><span class="sd">            inputs (list, torch.Tensor): The input to the network.</span>
</span><span id="FFnet_external.forward-838"><a href="#FFnet_external.forward-838"><span class="linenos">838</span></a>
</span><span id="FFnet_external.forward-839"><a href="#FFnet_external.forward-839"><span class="linenos">839</span></a><span class="sd">        Returns:</span>
</span><span id="FFnet_external.forward-840"><a href="#FFnet_external.forward-840"><span class="linenos">840</span></a><span class="sd">            y (torch.Tensor): The output of the network.</span>
</span><span id="FFnet_external.forward-841"><a href="#FFnet_external.forward-841"><span class="linenos">841</span></a>
</span><span id="FFnet_external.forward-842"><a href="#FFnet_external.forward-842"><span class="linenos">842</span></a><span class="sd">        Raises:</span>
</span><span id="FFnet_external.forward-843"><a href="#FFnet_external.forward-843"><span class="linenos">843</span></a><span class="sd">            ValueError: If no layers are defined.</span>
</span><span id="FFnet_external.forward-844"><a href="#FFnet_external.forward-844"><span class="linenos">844</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FFnet_external.forward-845"><a href="#FFnet_external.forward-845"><span class="linenos">845</span></a>        
</span><span id="FFnet_external.forward-846"><a href="#FFnet_external.forward-846"><span class="linenos">846</span></a>        <span class="c1"># Leave all heavy lifting to the external module, which is in layers[0]. But concatenate network inputs, as needed</span>
</span><span id="FFnet_external.forward-847"><a href="#FFnet_external.forward-847"><span class="linenos">847</span></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="FFnet_external.forward-848"><a href="#FFnet_external.forward-848"><span class="linenos">848</span></a>        <span class="k">for</span> <span class="n">mm</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)):</span>
</span><span id="FFnet_external.forward-849"><a href="#FFnet_external.forward-849"><span class="linenos">849</span></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">inputs</span><span class="p">[</span><span class="n">mm</span><span class="p">]),</span> <span class="mi">1</span> <span class="p">)</span>
</span><span id="FFnet_external.forward-850"><a href="#FFnet_external.forward-850"><span class="linenos">850</span></a>        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="FFnet_external.forward-851"><a href="#FFnet_external.forward-851"><span class="linenos">851</span></a>
</span><span id="FFnet_external.forward-852"><a href="#FFnet_external.forward-852"><span class="linenos">852</span></a>        <span class="c1"># Reshape dimensions for layer as needed</span>
</span><span id="FFnet_external.forward-853"><a href="#FFnet_external.forward-853"><span class="linenos">853</span></a>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_dims_reshape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FFnet_external.forward-854"><a href="#FFnet_external.forward-854"><span class="linenos">854</span></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span> <span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_dims_reshape</span><span class="p">)</span>
</span><span id="FFnet_external.forward-855"><a href="#FFnet_external.forward-855"><span class="linenos">855</span></a>        
</span><span id="FFnet_external.forward-856"><a href="#FFnet_external.forward-856"><span class="linenos">856</span></a>        <span class="c1"># Pass into external network</span>
</span><span id="FFnet_external.forward-857"><a href="#FFnet_external.forward-857"><span class="linenos">857</span></a>        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">x</span><span class="p">)</span>
</span><span id="FFnet_external.forward-858"><a href="#FFnet_external.forward-858"><span class="linenos">858</span></a>
</span><span id="FFnet_external.forward-859"><a href="#FFnet_external.forward-859"><span class="linenos">859</span></a>        <span class="c1"># Ensure that output is flattened</span>
</span><span id="FFnet_external.forward-860"><a href="#FFnet_external.forward-860"><span class="linenos">860</span></a>        <span class="k">return</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span></pre></div>


            <div class="docstring"><p>Forward pass through the network.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>inputs (list, torch.Tensor):</strong>  The input to the network.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>y (torch.Tensor): The output of the network.</p>
</blockquote>

<h6 id="raises">Raises:</h6>

<ul>
<li><strong>ValueError:</strong>  If no layers are defined.</li>
</ul>
</div>


                            </div>
                            <div id="FFnet_external.compute_reg_loss" class="classattr">
                                        <input id="FFnet_external.compute_reg_loss-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">compute_reg_loss</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="FFnet_external.compute_reg_loss-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FFnet_external.compute_reg_loss"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FFnet_external.compute_reg_loss-862"><a href="#FFnet_external.compute_reg_loss-862"><span class="linenos">862</span></a>    <span class="k">def</span> <span class="nf">compute_reg_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="FFnet_external.compute_reg_loss-863"><a href="#FFnet_external.compute_reg_loss-863"><span class="linenos">863</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnet_external.compute_reg_loss-864"><a href="#FFnet_external.compute_reg_loss-864"><span class="linenos">864</span></a><span class="sd">        Computes the regularization loss.</span>
</span><span id="FFnet_external.compute_reg_loss-865"><a href="#FFnet_external.compute_reg_loss-865"><span class="linenos">865</span></a>
</span><span id="FFnet_external.compute_reg_loss-866"><a href="#FFnet_external.compute_reg_loss-866"><span class="linenos">866</span></a><span class="sd">        Args:</span>
</span><span id="FFnet_external.compute_reg_loss-867"><a href="#FFnet_external.compute_reg_loss-867"><span class="linenos">867</span></a><span class="sd">            None</span>
</span><span id="FFnet_external.compute_reg_loss-868"><a href="#FFnet_external.compute_reg_loss-868"><span class="linenos">868</span></a>
</span><span id="FFnet_external.compute_reg_loss-869"><a href="#FFnet_external.compute_reg_loss-869"><span class="linenos">869</span></a><span class="sd">        Returns:</span>
</span><span id="FFnet_external.compute_reg_loss-870"><a href="#FFnet_external.compute_reg_loss-870"><span class="linenos">870</span></a><span class="sd">            0</span>
</span><span id="FFnet_external.compute_reg_loss-871"><a href="#FFnet_external.compute_reg_loss-871"><span class="linenos">871</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FFnet_external.compute_reg_loss-872"><a href="#FFnet_external.compute_reg_loss-872"><span class="linenos">872</span></a>        <span class="c1"># Since we do not implement regularization within the external network, this returns nothing</span>
</span><span id="FFnet_external.compute_reg_loss-873"><a href="#FFnet_external.compute_reg_loss-873"><span class="linenos">873</span></a>        <span class="k">return</span> <span class="mi">0</span>
</span></pre></div>


            <div class="docstring"><p>Computes the regularization loss.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li>None</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>0</p>
</blockquote>
</div>


                            </div>
                            <div id="FFnet_external.list_params" class="classattr">
                                        <input id="FFnet_external.list_params-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">list_params</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">layer_target</span><span class="o">=</span><span class="kc">None</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="FFnet_external.list_params-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FFnet_external.list_params"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FFnet_external.list_params-875"><a href="#FFnet_external.list_params-875"><span class="linenos">875</span></a>    <span class="k">def</span> <span class="nf">list_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer_target</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span><span id="FFnet_external.list_params-876"><a href="#FFnet_external.list_params-876"><span class="linenos">876</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnet_external.list_params-877"><a href="#FFnet_external.list_params-877"><span class="linenos">877</span></a><span class="sd">        Lists the parameters for the network.</span>
</span><span id="FFnet_external.list_params-878"><a href="#FFnet_external.list_params-878"><span class="linenos">878</span></a>
</span><span id="FFnet_external.list_params-879"><a href="#FFnet_external.list_params-879"><span class="linenos">879</span></a><span class="sd">        Args:</span>
</span><span id="FFnet_external.list_params-880"><a href="#FFnet_external.list_params-880"><span class="linenos">880</span></a><span class="sd">            layer_target (int, optional): The layer to list the parameters for. Defaults to None.</span>
</span><span id="FFnet_external.list_params-881"><a href="#FFnet_external.list_params-881"><span class="linenos">881</span></a>
</span><span id="FFnet_external.list_params-882"><a href="#FFnet_external.list_params-882"><span class="linenos">882</span></a><span class="sd">        Returns:</span>
</span><span id="FFnet_external.list_params-883"><a href="#FFnet_external.list_params-883"><span class="linenos">883</span></a><span class="sd">            None</span>
</span><span id="FFnet_external.list_params-884"><a href="#FFnet_external.list_params-884"><span class="linenos">884</span></a>
</span><span id="FFnet_external.list_params-885"><a href="#FFnet_external.list_params-885"><span class="linenos">885</span></a><span class="sd">        Raises:</span>
</span><span id="FFnet_external.list_params-886"><a href="#FFnet_external.list_params-886"><span class="linenos">886</span></a><span class="sd">            AssertionError: If the layer target is invalid.</span>
</span><span id="FFnet_external.list_params-887"><a href="#FFnet_external.list_params-887"><span class="linenos">887</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FFnet_external.list_params-888"><a href="#FFnet_external.list_params-888"><span class="linenos">888</span></a>        <span class="k">assert</span> <span class="n">layer_target</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;No ability to directly distinguish layers in the external network.&#39;</span>
</span><span id="FFnet_external.list_params-889"><a href="#FFnet_external.list_params-889"><span class="linenos">889</span></a>        <span class="k">for</span> <span class="n">nm</span><span class="p">,</span> <span class="n">pp</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">(</span><span class="n">recurse</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
</span><span id="FFnet_external.list_params-890"><a href="#FFnet_external.list_params-890"><span class="linenos">890</span></a>            <span class="k">if</span> <span class="n">pp</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
</span><span id="FFnet_external.list_params-891"><a href="#FFnet_external.list_params-891"><span class="linenos">891</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;    </span><span class="si">%s</span><span class="s2">:&quot;</span><span class="o">%</span><span class="n">nm</span><span class="p">,</span> <span class="n">pp</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</span><span id="FFnet_external.list_params-892"><a href="#FFnet_external.list_params-892"><span class="linenos">892</span></a>            <span class="k">else</span><span class="p">:</span>
</span><span id="FFnet_external.list_params-893"><a href="#FFnet_external.list_params-893"><span class="linenos">893</span></a>                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;    NOT FIT: </span><span class="si">%s</span><span class="s2">:&quot;</span><span class="o">%</span><span class="n">nm</span><span class="p">,</span> <span class="n">pp</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</span></pre></div>


            <div class="docstring"><p>Lists the parameters for the network.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>layer_target (int, optional):</strong>  The layer to list the parameters for. Defaults to None.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>None</p>
</blockquote>

<h6 id="raises">Raises:</h6>

<ul>
<li><strong>AssertionError:</strong>  If the layer target is invalid.</li>
</ul>
</div>


                            </div>
                            <div id="FFnet_external.set_params" class="classattr">
                                        <input id="FFnet_external.set_params-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">set_params</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">layer_target</span><span class="o">=</span><span class="kc">None</span>, </span><span class="param"><span class="n">name</span><span class="o">=</span><span class="kc">None</span>, </span><span class="param"><span class="n">val</span><span class="o">=</span><span class="kc">None</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="FFnet_external.set_params-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FFnet_external.set_params"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FFnet_external.set_params-895"><a href="#FFnet_external.set_params-895"><span class="linenos">895</span></a>    <span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer_target</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">val</span><span class="o">=</span><span class="kc">None</span> <span class="p">):</span>
</span><span id="FFnet_external.set_params-896"><a href="#FFnet_external.set_params-896"><span class="linenos">896</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnet_external.set_params-897"><a href="#FFnet_external.set_params-897"><span class="linenos">897</span></a><span class="sd">        Sets the parameters for the listed layer or for all layers.</span>
</span><span id="FFnet_external.set_params-898"><a href="#FFnet_external.set_params-898"><span class="linenos">898</span></a>
</span><span id="FFnet_external.set_params-899"><a href="#FFnet_external.set_params-899"><span class="linenos">899</span></a><span class="sd">        Args:</span>
</span><span id="FFnet_external.set_params-900"><a href="#FFnet_external.set_params-900"><span class="linenos">900</span></a><span class="sd">            layer_target (int, optional): The layer to set the parameters for. Defaults to None.</span>
</span><span id="FFnet_external.set_params-901"><a href="#FFnet_external.set_params-901"><span class="linenos">901</span></a><span class="sd">            name (str): The name of the parameter.</span>
</span><span id="FFnet_external.set_params-902"><a href="#FFnet_external.set_params-902"><span class="linenos">902</span></a><span class="sd">            val (bool): The value to set the parameter to.</span>
</span><span id="FFnet_external.set_params-903"><a href="#FFnet_external.set_params-903"><span class="linenos">903</span></a>
</span><span id="FFnet_external.set_params-904"><a href="#FFnet_external.set_params-904"><span class="linenos">904</span></a><span class="sd">        Returns:</span>
</span><span id="FFnet_external.set_params-905"><a href="#FFnet_external.set_params-905"><span class="linenos">905</span></a><span class="sd">            None</span>
</span><span id="FFnet_external.set_params-906"><a href="#FFnet_external.set_params-906"><span class="linenos">906</span></a>
</span><span id="FFnet_external.set_params-907"><a href="#FFnet_external.set_params-907"><span class="linenos">907</span></a><span class="sd">        Raises:</span>
</span><span id="FFnet_external.set_params-908"><a href="#FFnet_external.set_params-908"><span class="linenos">908</span></a><span class="sd">            AssertionError: If the layer target is invalid.</span>
</span><span id="FFnet_external.set_params-909"><a href="#FFnet_external.set_params-909"><span class="linenos">909</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FFnet_external.set_params-910"><a href="#FFnet_external.set_params-910"><span class="linenos">910</span></a>        <span class="k">assert</span> <span class="n">layer_target</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;No ability to directly distinguish layers in the external network.&#39;</span>
</span><span id="FFnet_external.set_params-911"><a href="#FFnet_external.set_params-911"><span class="linenos">911</span></a>        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="nb">bool</span><span class="p">),</span> <span class="s1">&#39;val must be set.&#39;</span>
</span><span id="FFnet_external.set_params-912"><a href="#FFnet_external.set_params-912"><span class="linenos">912</span></a>        <span class="k">for</span> <span class="n">nm</span><span class="p">,</span> <span class="n">pp</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">(</span><span class="n">recurse</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
</span><span id="FFnet_external.set_params-913"><a href="#FFnet_external.set_params-913"><span class="linenos">913</span></a>            <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="FFnet_external.set_params-914"><a href="#FFnet_external.set_params-914"><span class="linenos">914</span></a>                <span class="n">pp</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="n">val</span>
</span><span id="FFnet_external.set_params-915"><a href="#FFnet_external.set_params-915"><span class="linenos">915</span></a>            <span class="k">elif</span> <span class="n">nm</span> <span class="o">==</span> <span class="n">name</span><span class="p">:</span>
</span><span id="FFnet_external.set_params-916"><a href="#FFnet_external.set_params-916"><span class="linenos">916</span></a>                <span class="n">pp</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="n">val</span>
</span></pre></div>


            <div class="docstring"><p>Sets the parameters for the listed layer or for all layers.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>layer_target (int, optional):</strong>  The layer to set the parameters for. Defaults to None.</li>
<li><strong>name (str):</strong>  The name of the parameter.</li>
<li><strong>val (bool):</strong>  The value to set the parameter to.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>None</p>
</blockquote>

<h6 id="raises">Raises:</h6>

<ul>
<li><strong>AssertionError:</strong>  If the layer target is invalid.</li>
</ul>
</div>


                            </div>
                            <div id="FFnet_external.ffnet_dict" class="classattr">
                                        <input id="FFnet_external.ffnet_dict-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator">@classmethod</div>

        <span class="def">def</span>
        <span class="name">ffnet_dict</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">cls</span>, </span><span class="param"><span class="o">**</span><span class="n">kwargs</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="FFnet_external.ffnet_dict-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#FFnet_external.ffnet_dict"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="FFnet_external.ffnet_dict-918"><a href="#FFnet_external.ffnet_dict-918"><span class="linenos">918</span></a>    <span class="nd">@classmethod</span>
</span><span id="FFnet_external.ffnet_dict-919"><a href="#FFnet_external.ffnet_dict-919"><span class="linenos">919</span></a>    <span class="k">def</span> <span class="nf">ffnet_dict</span><span class="p">(</span> <span class="bp">cls</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span><span id="FFnet_external.ffnet_dict-920"><a href="#FFnet_external.ffnet_dict-920"><span class="linenos">920</span></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="FFnet_external.ffnet_dict-921"><a href="#FFnet_external.ffnet_dict-921"><span class="linenos">921</span></a><span class="sd">        Returns a dictionary of the external network.</span>
</span><span id="FFnet_external.ffnet_dict-922"><a href="#FFnet_external.ffnet_dict-922"><span class="linenos">922</span></a>
</span><span id="FFnet_external.ffnet_dict-923"><a href="#FFnet_external.ffnet_dict-923"><span class="linenos">923</span></a><span class="sd">        Args:</span>
</span><span id="FFnet_external.ffnet_dict-924"><a href="#FFnet_external.ffnet_dict-924"><span class="linenos">924</span></a><span class="sd">            **kwargs: Additional keyword arguments.</span>
</span><span id="FFnet_external.ffnet_dict-925"><a href="#FFnet_external.ffnet_dict-925"><span class="linenos">925</span></a>
</span><span id="FFnet_external.ffnet_dict-926"><a href="#FFnet_external.ffnet_dict-926"><span class="linenos">926</span></a><span class="sd">        Returns:</span>
</span><span id="FFnet_external.ffnet_dict-927"><a href="#FFnet_external.ffnet_dict-927"><span class="linenos">927</span></a><span class="sd">            ffnet_dict (dict): The dictionary of the external network.</span>
</span><span id="FFnet_external.ffnet_dict-928"><a href="#FFnet_external.ffnet_dict-928"><span class="linenos">928</span></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="FFnet_external.ffnet_dict-929"><a href="#FFnet_external.ffnet_dict-929"><span class="linenos">929</span></a>        <span class="n">ffnet_dict</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">ffnet_dict</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span><span id="FFnet_external.ffnet_dict-930"><a href="#FFnet_external.ffnet_dict-930"><span class="linenos">930</span></a>        <span class="n">ffnet_dict</span><span class="p">[</span><span class="s1">&#39;ffnet_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;external&#39;</span>
</span><span id="FFnet_external.ffnet_dict-931"><a href="#FFnet_external.ffnet_dict-931"><span class="linenos">931</span></a>        <span class="k">return</span> <span class="n">ffnet_dict</span>
</span></pre></div>


            <div class="docstring"><p>Returns a dictionary of the external network.</p>

<h6 id="arguments">Arguments:</h6>

<ul>
<li><strong>**kwargs:</strong>  Additional keyword arguments.</li>
</ul>

<h6 id="returns">Returns:</h6>

<blockquote>
  <p>ffnet_dict (dict): The dictionary of the external network.</p>
</blockquote>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt><a href="#FFnetwork">FFnetwork</a></dt>
                                <dd id="FFnet_external.layer_list" class="variable"><a href="#FFnetwork.layer_list">layer_list</a></dd>
                <dd id="FFnet_external.layer_types" class="variable"><a href="#FFnetwork.layer_types">layer_types</a></dd>
                <dd id="FFnet_external.xstim_n" class="variable"><a href="#FFnetwork.xstim_n">xstim_n</a></dd>
                <dd id="FFnet_external.ffnets_in" class="variable"><a href="#FFnetwork.ffnets_in">ffnets_in</a></dd>
                <dd id="FFnet_external.layers" class="variable"><a href="#FFnetwork.layers">layers</a></dd>
                <dd id="FFnet_external.output_dims" class="variable"><a href="#FFnetwork.output_dims">output_dims</a></dd>
                <dd id="FFnet_external.num_outputs" class="variable"><a href="#FFnetwork.num_outputs">num_outputs</a></dd>
                <dd id="FFnet_external.determine_input_dims" class="function"><a href="#FFnetwork.determine_input_dims">determine_input_dims</a></dd>
                <dd id="FFnet_external.preprocess_input" class="function"><a href="#FFnetwork.preprocess_input">preprocess_input</a></dd>
                <dd id="FFnet_external.prepare_regularization" class="function"><a href="#FFnetwork.prepare_regularization">prepare_regularization</a></dd>
                <dd id="FFnet_external.list_parameters" class="function"><a href="#FFnetwork.list_parameters">list_parameters</a></dd>
                <dd id="FFnet_external.set_parameters" class="function"><a href="#FFnetwork.set_parameters">set_parameters</a></dd>
                <dd id="FFnet_external.set_reg_val" class="function"><a href="#FFnetwork.set_reg_val">set_reg_val</a></dd>
                <dd id="FFnet_external.plot_filters" class="function"><a href="#FFnetwork.plot_filters">plot_filters</a></dd>
                <dd id="FFnet_external.get_weights" class="function"><a href="#FFnetwork.get_weights">get_weights</a></dd>

            </div>
            <div><dt>torch.nn.modules.module.Module</dt>
                                <dd id="FFnet_external.dump_patches" class="variable">dump_patches</dd>
                <dd id="FFnet_external.training" class="variable">training</dd>
                <dd id="FFnet_external.call_super_init" class="variable">call_super_init</dd>
                <dd id="FFnet_external.register_buffer" class="function">register_buffer</dd>
                <dd id="FFnet_external.register_parameter" class="function">register_parameter</dd>
                <dd id="FFnet_external.add_module" class="function">add_module</dd>
                <dd id="FFnet_external.register_module" class="function">register_module</dd>
                <dd id="FFnet_external.get_submodule" class="function">get_submodule</dd>
                <dd id="FFnet_external.get_parameter" class="function">get_parameter</dd>
                <dd id="FFnet_external.get_buffer" class="function">get_buffer</dd>
                <dd id="FFnet_external.get_extra_state" class="function">get_extra_state</dd>
                <dd id="FFnet_external.set_extra_state" class="function">set_extra_state</dd>
                <dd id="FFnet_external.apply" class="function">apply</dd>
                <dd id="FFnet_external.cuda" class="function">cuda</dd>
                <dd id="FFnet_external.ipu" class="function">ipu</dd>
                <dd id="FFnet_external.xpu" class="function">xpu</dd>
                <dd id="FFnet_external.cpu" class="function">cpu</dd>
                <dd id="FFnet_external.type" class="function">type</dd>
                <dd id="FFnet_external.float" class="function">float</dd>
                <dd id="FFnet_external.double" class="function">double</dd>
                <dd id="FFnet_external.half" class="function">half</dd>
                <dd id="FFnet_external.bfloat16" class="function">bfloat16</dd>
                <dd id="FFnet_external.to_empty" class="function">to_empty</dd>
                <dd id="FFnet_external.to" class="function">to</dd>
                <dd id="FFnet_external.register_full_backward_pre_hook" class="function">register_full_backward_pre_hook</dd>
                <dd id="FFnet_external.register_backward_hook" class="function">register_backward_hook</dd>
                <dd id="FFnet_external.register_full_backward_hook" class="function">register_full_backward_hook</dd>
                <dd id="FFnet_external.register_forward_pre_hook" class="function">register_forward_pre_hook</dd>
                <dd id="FFnet_external.register_forward_hook" class="function">register_forward_hook</dd>
                <dd id="FFnet_external.register_state_dict_pre_hook" class="function">register_state_dict_pre_hook</dd>
                <dd id="FFnet_external.state_dict" class="function">state_dict</dd>
                <dd id="FFnet_external.register_load_state_dict_post_hook" class="function">register_load_state_dict_post_hook</dd>
                <dd id="FFnet_external.load_state_dict" class="function">load_state_dict</dd>
                <dd id="FFnet_external.parameters" class="function">parameters</dd>
                <dd id="FFnet_external.named_parameters" class="function">named_parameters</dd>
                <dd id="FFnet_external.buffers" class="function">buffers</dd>
                <dd id="FFnet_external.named_buffers" class="function">named_buffers</dd>
                <dd id="FFnet_external.children" class="function">children</dd>
                <dd id="FFnet_external.named_children" class="function">named_children</dd>
                <dd id="FFnet_external.modules" class="function">modules</dd>
                <dd id="FFnet_external.named_modules" class="function">named_modules</dd>
                <dd id="FFnet_external.train" class="function">train</dd>
                <dd id="FFnet_external.eval" class="function">eval</dd>
                <dd id="FFnet_external.requires_grad_" class="function">requires_grad_</dd>
                <dd id="FFnet_external.zero_grad" class="function">zero_grad</dd>
                <dd id="FFnet_external.share_memory" class="function">share_memory</dd>
                <dd id="FFnet_external.extra_repr" class="function">extra_repr</dd>

            </div>
                                </dl>
                            </div>
                </section>
    </main>
<script>
    function escapeHTML(html) {
        return document.createElement('div').appendChild(document.createTextNode(html)).parentNode.innerHTML;
    }

    const originalContent = document.querySelector("main.pdoc");
    let currentContent = originalContent;

    function setContent(innerHTML) {
        let elem;
        if (innerHTML) {
            elem = document.createElement("main");
            elem.classList.add("pdoc");
            elem.innerHTML = innerHTML;
        } else {
            elem = originalContent;
        }
        if (currentContent !== elem) {
            currentContent.replaceWith(elem);
            currentContent = elem;
        }
    }

    function getSearchTerm() {
        return (new URL(window.location)).searchParams.get("search");
    }

    const searchBox = document.querySelector(".pdoc input[type=search]");
    searchBox.addEventListener("input", function () {
        let url = new URL(window.location);
        if (searchBox.value.trim()) {
            url.hash = "";
            url.searchParams.set("search", searchBox.value);
        } else {
            url.searchParams.delete("search");
        }
        history.replaceState("", "", url.toString());
        onInput();
    });
    window.addEventListener("popstate", onInput);


    let search, searchErr;

    async function initialize() {
        try {
            search = await new Promise((resolve, reject) => {
                const script = document.createElement("script");
                script.type = "text/javascript";
                script.async = true;
                script.onload = () => resolve(window.pdocSearch);
                script.onerror = (e) => reject(e);
                script.src = "../search.js";
                document.getElementsByTagName("head")[0].appendChild(script);
            });
        } catch (e) {
            console.error("Cannot fetch pdoc search index");
            searchErr = "Cannot fetch search index.";
        }
        onInput();

        document.querySelector("nav.pdoc").addEventListener("click", e => {
            if (e.target.hash) {
                searchBox.value = "";
                searchBox.dispatchEvent(new Event("input"));
            }
        });
    }

    function onInput() {
        setContent((() => {
            const term = getSearchTerm();
            if (!term) {
                return null
            }
            if (searchErr) {
                return `<h3>Error: ${searchErr}</h3>`
            }
            if (!search) {
                return "<h3>Searching...</h3>"
            }

            window.scrollTo({top: 0, left: 0, behavior: 'auto'});

            const results = search(term);

            let html;
            if (results.length === 0) {
                html = `No search results for '${escapeHTML(term)}'.`
            } else {
                html = `<h4>${results.length} search result${results.length > 1 ? "s" : ""} for '${escapeHTML(term)}'.</h4>`;
            }
            for (let result of results.slice(0, 10)) {
                let doc = result.doc;
                let url = `../${doc.modulename.replaceAll(".", "/")}.html`;
                if (doc.qualname) {
                    url += `#${doc.qualname}`;
                }

                let heading;
                switch (result.doc.kind) {
                    case "function":
                        if (doc.fullname.endsWith(".__init__")) {
                            heading = `<span class="name">${doc.fullname.replace(/\.__init__$/, "")}</span>${doc.signature}`;
                        } else {
                            heading = `<span class="def">${doc.funcdef}</span> <span class="name">${doc.fullname}</span>${doc.signature}`;
                        }
                        break;
                    case "class":
                        heading = `<span class="def">class</span> <span class="name">${doc.fullname}</span>`;
                        if (doc.bases)
                            heading += `<wbr>(<span class="base">${doc.bases}</span>)`;
                        heading += `:`;
                        break;
                    case "variable":
                        heading = `<span class="name">${doc.fullname}</span>`;
                        if (doc.annotation)
                            heading += `<span class="annotation">${doc.annotation}</span>`;
                        if (doc.default_value)
                            heading += `<span class="default_value"> = ${doc.default_value}</span>`;
                        break;
                    default:
                        heading = `<span class="name">${doc.fullname}</span>`;
                        break;
                }
                html += `
                        <section class="search-result">
                        <a href="${url}" class="attr ${doc.kind}">${heading}</a>
                        <div class="docstring">${doc.doc}</div>
                        </section>
                    `;

            }
            return html;
        })());
    }

    if (getSearchTerm()) {
        initialize();
        searchBox.value = getSearchTerm();
        onInput();
    } else {
        searchBox.addEventListener("focus", initialize, {once: true});
    }

    searchBox.addEventListener("keydown", e => {
        if (["ArrowDown", "ArrowUp", "Enter"].includes(e.key)) {
            let focused = currentContent.querySelector(".search-result.focused");
            if (!focused) {
                currentContent.querySelector(".search-result").classList.add("focused");
            } else if (
                e.key === "ArrowDown"
                && focused.nextElementSibling
                && focused.nextElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.nextElementSibling.classList.add("focused");
                focused.nextElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "ArrowUp"
                && focused.previousElementSibling
                && focused.previousElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.previousElementSibling.classList.add("focused");
                focused.previousElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "Enter"
            ) {
                focused.querySelector("a").click();
            }
        }
    });
</script></body>
</html>